{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:29.706551Z",
     "start_time": "2020-05-11T13:05:29.678377Z"
    }
   },
   "outputs": [],
   "source": [
    "# setup variables\n",
    "\n",
    "import os\n",
    "import json\n",
    "import tqdm\n",
    "from s2orc.config import CURRENT_VERSION\n",
    "\n",
    "LOCAL_S2ORC_DIR = 's2orc-data'\n",
    "local_manifest_file = os.path.join(LOCAL_S2ORC_DIR, CURRENT_VERSION, 'manifest.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the corpus chunks and join with citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:29.724823Z",
     "start_time": "2020-05-11T13:05:29.708793Z"
    }
   },
   "outputs": [],
   "source": [
    "# ---- CONFIG ----- #\n",
    "\n",
    "# jsonlines https://jsonlines.readthedocs.io/en/latest/#api\n",
    "import jsonlines\n",
    "import gzip\n",
    "\n",
    "paper_dir = os.path.join(LOCAL_S2ORC_DIR, CURRENT_VERSION, 'papers')\n",
    "context_dir = os.path.join(LOCAL_S2ORC_DIR, CURRENT_VERSION, 'contexts')\n",
    "context_file_suffix = 'contexts.jsonl' # filename besides batch number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:38.013332Z",
     "start_time": "2020-05-11T13:05:29.727867Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.20s/it]\n"
     ]
    }
   ],
   "source": [
    "##### extract citation contexts and save them\n",
    "from s2orc.get_citation_contexts import get_citation_contexts\n",
    "\n",
    "start = 0\n",
    "span = 100\n",
    "\n",
    "os.makedirs(context_dir, exist_ok=True)\n",
    "batch_files = sorted(os.listdir(paper_dir), key=lambda f: int(f.split('.')[0]))[start:(start+span)]\n",
    "for batch_file in tqdm.tqdm(batch_files):\n",
    "    batch_number = batch_file.split('.')[0]\n",
    "    contexts = []\n",
    "    with gzip.open(os.path.join(paper_dir, batch_file), 'rb') as f_in:\n",
    "        papers = list(jsonlines.Reader(f_in))\n",
    "        for paper in papers:\n",
    "            citation_contexts = get_citation_contexts(paper, toks_in_context=20)\n",
    "            # remove redundant ids\n",
    "            for item in citation_contexts:\n",
    "                del item['paper_id']\n",
    "            entry = { 'paper_id': paper['paper_id'] }\n",
    "            if len(citation_contexts) > 0:\n",
    "                entry['contexts'] = citation_contexts\n",
    "            contexts.append(entry)\n",
    "    \n",
    "    out_filename = '.'.join([batch_number, context_file_suffix, 'gz'])\n",
    "    with gzip.open(os.path.join(context_dir, out_filename), mode='w') as f_out:\n",
    "        jsonlines.Writer(f_out).write_all(contexts)\n",
    "#         with jsonlines.open(os.path.join(context_dir, out_filename), mode='w') as writer:\n",
    "#             writer.write_all(contexts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:38.416782Z",
     "start_time": "2020-05-11T13:05:38.018538Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# read citation contexts\n",
    "start = 0\n",
    "span = 100\n",
    "\n",
    "contexts = {} # citation contexts by paper id\n",
    "\n",
    "batch_files = sorted(os.listdir(context_dir), key=lambda f: int(f.split('.')[0]))[start:(start+span)]\n",
    "for batch_file in tqdm.tqdm(batch_files):\n",
    "    batch_number = batch_file.split('.')[0]\n",
    "    with gzip.open(os.path.join(context_dir, batch_file)) as f_in:\n",
    "        reader = jsonlines.Reader(f_in)\n",
    "        contexts.update({item['paper_id']: item for item in reader})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find articles with full grobid parse and intersect them with the papers cited within corpus contexts to get pairs <citation_string, cited full text paper>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:38.426346Z",
     "start_time": "2020-05-11T13:05:38.421613Z"
    }
   },
   "outputs": [],
   "source": [
    "full_text_papers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:44.972557Z",
     "start_time": "2020-05-11T13:05:38.434632Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:06<00:00,  6.52s/it]\n"
     ]
    }
   ],
   "source": [
    "##### get papers with full text parse\n",
    "\n",
    "start = 0\n",
    "span = 100\n",
    "\n",
    "batch_files = sorted(os.listdir(paper_dir), key=lambda f: int(f.split('.')[0]))[start:(start+span)]\n",
    "for batch_file in tqdm.tqdm(batch_files):\n",
    "    with gzip.open(os.path.join(paper_dir, batch_file), 'rb') as f_in:\n",
    "        papers = list(jsonlines.Reader(f_in))\n",
    "        for paper in papers:\n",
    "            if paper.get('grobid_parse') is not None:\n",
    "                full_text_papers[paper['paper_id']] = paper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:45.017302Z",
     "start_time": "2020-05-11T13:05:44.977146Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2817"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_text_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:59.548459Z",
     "start_time": "2020-05-11T13:05:45.020530Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "links found: 22: 100%|██████████| 8259/8259 [00:14<00:00, 569.33it/s]\n"
     ]
    }
   ],
   "source": [
    "# intersect full text papers with paper citations\n",
    "links = []\n",
    "bar = tqdm.tqdm(list(contexts.values()))\n",
    "for paper in bar:\n",
    "    bar.set_description('links found: ' + str(len(links)))\n",
    "#     print(type(paper['paper_id']))\n",
    "#     print(paper['contexts'])\n",
    "    for context in paper.get('contexts', []):\n",
    "#         print(type(context[0]['cited_paper_id']))\n",
    "        cited_id = context['cited_paper_id']\n",
    "        if cited_id in full_text_papers:\n",
    "            links.append((context, full_text_papers[cited_id]))\n",
    "            \n",
    "# len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:05:59.569335Z",
     "start_time": "2020-05-11T13:05:59.563903Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(full_text_papers.values())\n",
    "for context, paper in links[50:100]:\n",
    "    print(context['context_string'], paper['metadata']['title'], sep='\\n', end='\\n\\n')\n",
    "# print(links[0][0])\n",
    "# print(links[0][1])\n",
    "# 17913703"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observations\n",
    "\n",
    "- embeddings will be applicable more to more \"fuzzy\" ideas and papers?\n",
    "- nominal phrases VS verbal descriptions\n",
    "- broader context of the citing paper would be useful (at least for identifying keywords from abstract)\n",
    "- unknown words must be taken into account (many neologisms, variable names and other very hermetic words in pure science papers).\n",
    "\n",
    "### todo\n",
    "- checkout sciBERT\n",
    "- checkout what kind of embeddings would be useful\n",
    "- what would be useful: extracting precise information, or just fuzzy semantic detection (e.g. topic).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-11T13:06:24.610469Z",
     "start_time": "2020-05-11T13:05:59.571365Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/22 [00:00<?, ?it/s]/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n",
      "100%|██████████| 22/22 [00:10<00:00,  2.02it/s]\n"
     ]
    }
   ],
   "source": [
    "from syntok.segmenter import split\n",
    "from syntok.tokenizer import Tokenizer\n",
    "import json\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, StackedEmbeddings, Sentence\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "links_random_order = list(links)\n",
    "np.random.seed(234243)\n",
    "np.random.shuffle(links_random_order)\n",
    "\n",
    "glove_embedding = DocumentPoolEmbeddings([WordEmbeddings('glove')])\n",
    "\n",
    "# flair_embedding = StackedEmbeddings([\n",
    "#                                         FlairEmbeddings('news-forward'),\n",
    "#                                         FlairEmbeddings('news-backward'),\n",
    "#                                        ])\n",
    "\n",
    "with open('glove_examples.txt', 'w') as f_out:\n",
    "    for context, paper in tqdm.tqdm(links_random_order):\n",
    "        # find the adequate context pair\n",
    "        glove_similarities = []\n",
    "        flair_similarities = []\n",
    "    #     next(context[''] for context in contexts[paper['paper_id']]['contexts'] if context['cited_paper_id'] == paper\n",
    "        citing_string = ''.join([context['pre_context'], context['context_string'], context['post_context']])\n",
    "        s = Sentence(citing_string, use_tokenizer=True)\n",
    "        glove_embedding.embed(s)\n",
    "        glove_citation_embedding = s.embedding.detach()\n",
    "\n",
    "    #     s = Sentence(citing_string, use_tokenizer=True)\n",
    "    #     flair_embedding.embed(s)\n",
    "    #     flair_citation_embedding = s.embedding.detach()\n",
    "        for paper_part, text_chunks in paper['grobid_parse'].items():\n",
    "            if text_chunks is not None:\n",
    "                for text_chunk in text_chunks:\n",
    "                    if isinstance(text_chunk, dict):\n",
    "                        text = text_chunk.get('text')\n",
    "                        tokenized_sents = list(split(Tokenizer().tokenize(text)))\n",
    "                        sents = [' '.join(str(token) for token in sent) for sent in tokenized_sents]\n",
    "\n",
    "                        sentences = [s for s in [Sentence(sent, use_tokenizer=True) for sent in sents] if len(s.tokens) > 0]\n",
    "                        embeddings = glove_embedding.embed(sentences)\n",
    "                        for s in sentences:\n",
    "                            e1 = s.embedding.detach()\n",
    "                            e2 = glove_citation_embedding\n",
    "                            sim = np.dot(e1, e2) / (np.sqrt(np.dot(e1, e1)) * np.sqrt(np.dot(e2, e2)))\n",
    "                            glove_similarities.append((sim, s.to_original_text()))\n",
    "\n",
    "\n",
    "    #                     sentences = [s for s in [Sentence(sent, use_tokenizer=True) for sent in sents] if len(s.tokens) > 0]\n",
    "    #                     embeddings = flair_embedding.embed(sentences)\n",
    "    #                     for s in sentences:\n",
    "    #                         e1 = s.embedding.detach()\n",
    "    #                         e2 = flair_citation_embedding\n",
    "    #                         sim = np.dot(e1, e2) / (np.sqrt(np.dot(e1, e1)) * np.sqrt(np.dot(e2, e2)))\n",
    "    #                         flair_similarities.append((sim, s.to_original_text()))\n",
    "\n",
    "                \n",
    "                print('\\n\\n\\n--- PAPER ---', '\\n', paper['metadata']['title'], file=f_out, end='\\n')\n",
    "                print('\\n\\ncontext: ', citing_string, file=f_out, end='\\n\\n')\n",
    "                print('\\n\\nsimilarities: ', file=f_out, end='\\n\\n')\n",
    "                print(*sorted(glove_similarities, key=lambda x: x[0], reverse=True)[:20], file=f_out, sep='\\n\\n')\n",
    "    #             print('FLAIR')\n",
    "    #             print(*sorted(flair_similarities, key=lambda x: x[0], reverse=True)[:10], sep='\\n\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusions\n",
    "- sometimes the context says only what an article \"does\" (not what is its content), e.g.: \"A more detailed description of the study population that participated in the autonomic measurements has been reported elsewhere (Dietrich et al., 2006)\"\n",
    "- the major problem is the citation context, and it seems glove embeddings do find some relevant sentences when the citing sentence describes accurately\n",
    "- distinction between \"nominal\" and \"verbal\" contexts would help a lot, since verbal contexts often need a large context, and the nominal sometimes need probably only 3-4 words to compare with the text.\n",
    "- sometimes, when the whole article seems to correspond to the citing sentence, in fact the task of finding relevant ones seem to be very ambiguous. We should probably see possible clusters of score distribution\n",
    "\n",
    "### TODO:\n",
    "- get flair embeddings to work (define their own metric of similarity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cogsci_python",
   "language": "python",
   "name": "cogsci_python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
