{
  "name" : "On_the_continuity_of_mind_Toward_a_dynam.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "ON THE CONTINUITY OF MIND: TOWARD A DYNAMICAL ACCOUNT OF COGNITION",
    "authors" : [ "Michael J. Spivey" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nON THE CONTINUITY OF MIND: TOWARD A DYNAMICAL ACCOUNT OF COGNITION\nMichael J. Spivey and Rick Dale\nIt should be obvious by now that this minute inflow of stimulus energy does not consist of\ndiscrete inputs—that stimulation does not consist of stimuli. The flow is continuous. There\nare, of course, episodes in the flow, but these are nested within one another and cannot be\ncut up into elementary units. Stimulation is not momentary. (J. J. Gibson, 1979).\nI. Introduction\nIn 1960, J. J. Gibson reviewed technical uses of the term stimulus and found\nthat it did not have a consistent agreed-upon definition, but instead con-\nnoted several diVerent conceptions of ‘‘stimulating’’ an organism. Most of those conceptions did, however, have a property also found in the word’s\noriginal uses: A stimulus is a temporally discrete, momentary happening in\nthe life of an organism. Challenging this intuition, Gibson’s ecological\npsychology assumes at its foundation the continuity of the stimulation in\nthe surrounding environment. What this means is that the ‘‘flowing array of\nstimulus energy,’’ as Gibson called it, is never presegmented into easily\ndefined independent chunks, or ‘‘stimuli,’’— even though we feel as though\nwe perceive it that way.\nBefore Gibson, Dewey (1986) famously made a similar point in his infl-\nuential critique of the reflex arc concept. The reflex arc concept was a\nrelatively new idea, framing the questions of psychology in terms of causal\narcs among stimulus, mental event, and response. Essentially, studying the\ncausal arcs between just the former two, or the latter two, was considered a\nlegitimate scientific enterprise in and of itself. In contrast, treating the\nTHE PSYCHOLOGY OF LEARNING Copyright 2004, Elsevier Inc.\nAND MOTIVATION, VOL. 45 87 All rights reserved. 0079-7421/04 $35.00\nU N C O R R E C T E D P R O O F\nprogression of the three components as one continuous process, which\nnaturally loops back on itself, was what Dewey influentially encouraged\n(Leahey, 1994). From his perspective, actions take place over time and they\ncontinuously alter the stimulus environment, which in turn continuously\nalters mental activity, which is continuously expressing and revising its\ninclinations to action. One of the most famous reactions to Dewey’s criti-\ncism, behaviorism, found a long-standing solution by eliminating the second\n(mental) stage. But Dewey’s critique still stands: Segmenting the natural life\nof an organism into discretely identifiable stimuli and responses is artificial\nand potentially misleading.\nAlthough originally aimed predominantly at behaviorism, Gibson and\nDewey’s critiques echo into modern cognitive psychology. Essentially, cog-\nnitive psychology replaced behaviorism’s emphasis on ‘‘stimulus and re-\nsponse’’ with an emphasis on ‘‘stimulus and interpretation’’—not really\naddressing the continuity problem. But if the environmental stimulation\nimpinging on our sensory systems is almost always partially overlapping in\nspace and continuous through time, why would our minds work in the\nstaccato fashion of a digital computer, momentarily entertaining one discrete\nstable non-overlapping representational state, and then instantaneously\nflipping to entertain another one?\nThe goal of this chapter is to challenge the notion of discrete representa-\ntional states. The mind, like Gibson’s stimulation, exists in continuity,\nmoving gradually between mental states, never standing still in time. Indeed,\nthese ‘‘mental states’’ themselves are not really static states at all, but rather\ngraded regions in mental state-space that are more or less interpretable than\nothers and are briefly visited (or perhaps merely ‘‘flirted’’ with) by the mind\nduring its continuous motion through this state-space. We oVer the ‘‘continuity of mind’’ as a rubric for a psychological framework in which internal\nperceptual-cognitive processing exhibits continuous change in the salience of\nmultiple simultaneously active representations. This framework forces one\nto rethink many representational and architectural assumptions that have\npersisted in cognitive psychology and poses as an ‘‘intervention’’ procedure\nto wean the cognitive sciences from their obsession with formal logical\ndescriptions of mental representation. The continuity of mind attempts to\nreplace the overidealized notion of discrete symbolic mental states, bor-\nrowed from antiquated artificial intelligence research, with distributed pat-\nterns of neural activation that are always partially consistent with multiple\nmental states. Most important, this framework focuses on the continuous\ntemporal dynamics of these patterns of neural activation and the resulting\nconsequences for descriptions of various perceptual-cognitive processes.\nOf course, there exist several important precedents to this line of thinking.\nKelso (1995), for example, explored how dynamic patterns in several\n88 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nperceptual and motor processes can be accounted for by the concepts of\ncoordination and self-organization imported from synergetics (Haken,\n1983). Port and Van Gelder (1995) oVered a foundational collection of papers exploring a wide range of topics in which dynamical architectures\nand equations account for a wide variety of behavior. Thelen and Smith\n(1994) marshaled these dynamic-systems concepts in the service of explain-\ning and predicting patterns in behavioral development. Even further back,\nGregson (1983) oVered a discussion of time series and recommended a radical reconceptualization of psychological explanation by invoking time\nas a crucial concern.\nThe proposal herein pushes in some of the same directions as these\npreexisting dynamical theses but takes an important, diVerent overall route. We will focus on processes at a specific time scale, perception and behavior\non the order of hundreds of milliseconds, and how these processes impor-\ntantly exemplify the continuity of mind. Mental activity at this time scale has\nbeen a battlefield of dispute between frameworks in cognitive science. For\nexample, one possible modern target for Dewey’s critique is the computer\nmetaphor of the mind. This metaphor sees stages of cognitive processing as\ntemporally discrete representational states (Dietrich & Markman, 2003).\nNot only does the approach recommend an analysis of the human mind in\nterms of temporally discrete representation, but supposes as an ontological\nmatter that the mind entertains discrete representations and states. The\nprocesses at the time scale considered here have often involved heated debate\nbetween this and other explanatory frameworks. For years this traditional\ncomputational perspective has enjoyed a firm grip over the time scale,\noVering explanations for diVerent processes in language and perception. The success of this paradigm permitted the computer metaphor to even\ntrickle down into explorations of the properties of neural processes. For\nexample, in the early years of cognitive science, there were a few who were\ninspired both by digital computing theory and by the physical processes of\nthe human brain. These researchers invested quite a bit of intellectual stock\nin the idea that populations of spiking neurons would behave more or less\nthe same as populations of digital bits (e.g., McCulloch, 1965; Von\nNeumann, 1958; Wickelgren, 1977; see also Barlow, 1972; Lettvin, 1995;\nRose, 1996).\nHowever, what we know now about real neurophysiological proces-\nses seems to suggest instead great promise for the continuity of mind\nrather than the digital computer metaphor. A great deal more has been\nlearned in the past few decades about how populations of neurons work\n(e.g., Georgopoulos, Kalaska, Caminiti, & Massey, 1982; Pouget, Dayan, &\nZemel, 2000; Sparks, Holland, & Guthrie, 1976; Tanaka, 1997; Young &\nYamane, 1992), and it is nothing at all like the instantaneous binary\nContinuity of Mind 89\nU N C O R R E C T E D P R O O F\nflip-flopping from one discrete state to another that characterizes informa-\ntion processing in digital computers. In neuroscience, the closest thing to a\nclassical mental representation is the population code. A population code is\na sparse distributed representation comprised of a group of neurons that\ncooperate and resonate in response to a familiar perceptual input. Impor-\ntantly, the individual neurons that make up a population code do not appear\nto update their states in lockstep to the beat of a single global clock.\nPopulation codes spend a substantial amount of their time in partially\ncoherent patterns of activity. And thus the brain’s state is often dynamically\ntraversing intermediate regions of a state-space that contains what could be\ndescribed as many meta-stable attractors.\nWhether these population codes end up approximating discrete represen-\ntations is an important question open to debate. The distant and tenuous\nconnection between digital symbolic computation and distributed neural\nprocessing is nevertheless an attractive idea to some (cf. Marcus, 2001).\nAccording to this perspective, the activity of populations of neurons is\nsuYciently approximated by models that use rule-based operations on logical symbols, despite the fact that real neural hardware does not quite work\nthat way.\nThere are two key properties of the representations instantiated by neural\npopulations that we argue separate them from computer-like symbolic re-\npresentations: (1) continuity in time and (2) continuity in space. Continuity in\nspace has been dealt with elsewhere in roughly two diVerent ways: (1) a contiguous high-dimensional state-space where proximity serves as similarity\nand prototypical representations exist as partially overlapping attractor\nbasins (e.g., Aleksander, 1973; Edelman, 1999; Elman, 1991; Lund &\nBurgess, 1996; Pasupathy & Connor, 2002) and (2) a two-dimensional space\nbased on sensory surfaces, in which the shape and layout of internal\nrepresentations are roughly homologous to actual physical patterns of stim-\nulation (e.g., Barsalou, 1999; Farah, 1985; Johnson-Laird, 1998; Kosslyn,\nThompson, Kim, & Alpert, 1995; Langacker, 1990; Spivey, Richardson, &\nGonzalez-Marquez, in press; Talmy, 1983). Continuity in time has also been\ndealt with elsewhere in two (at least superficially) diVerent ways: (1) the continuous temporal dynamics of the neural connectivity patterns that\nconstitute knowledge and intelligence changing over developmental time\n(e.g., Elman, Bates, KarmiloV-Smith, Parisi, & Plunkett, 1996; Spencer & Schöner, 2003; Thelen & Smith, 1994), and (2) the continuous temporal\ndynamics of representation and behavior in real-time processing (e.g., Kelso,\n1994; Port & Van Gelder, 1995; Spivey, in preparation). This latter emphasis\non continuous temporal dynamics in real-time processing is where this\nchapter will focus its arguments against digital-computational accounts of\ncognition.\nAU:1\nAU:2\nAU:3\n90 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nBy describing demonstrations, in psycholinguistics and in visual percep-\ntion, of representations that are analog (rather than digital), partially over-\nlapping, and change gradually over the course of hundreds of milliseconds,\nwe hope to convince some readers that symbolic accounts of cognition that\ndo not accommodate such continuous temporal dynamics are missing a\ncrucial aspect of an accurate description of the mind. Such graded mental\nstates appear to be more than just temporary transitions between discrete\nmental representations but instead may be the modus operandi of the mind.\nTherefore, we suggest that approximating patterns of neural activation, and\nthe continuous temporal dynamics of these patterns, with a metaphor of\ndiscrete symbolic computation, is not merely a stretched analogy, but in\nfact a misleading one. Although the conversion of a continuous trajectory\nthrough a high-dimensional state-space into a string of emitted symbols is a\npowerful mathematical concept, it faces statistical problems with regard to\nthe exact placement of symbolic partitions (Bollt, Stanford, Lai, &\nZyczkowski, 2000), it faces representational problems with regard to how a\ndiscrete perfectly repeatable logical symbol is implemented by an inherently\nnoisy and distributed neural system, and it faces architectural problems with\nregard to an unrealistic degree of modularity required of the systems to and\nfrom which these symbol strings are being sent. Instead of pretending to be\nable to chop time into chunks that are associated with individual nonover-\nlapping symbolic representations, we argue that patterns of brain and be-\nhavior inevitably exhibit temporal and representational continuity and\nthat adopting this perspective can help predict and explain a considerable\ndatabase in the study of cognition.\nII. Continuously Changing Graded Representations\nA. Probabilistic Versus Pure Mental States\nBefore evaluating support for continuity in language and vision, we present\nsome simple illustrations that may help further limn our perspective. First,\nconsider a very simple demonstration of how we might visualize continuous\nchange in neural population codes. Readers familiar with dynamical meta-\nphors will doubtless find this example highly simplistic. Nevertheless, it will\nhelp solidify the predictions about temporal dynamics that are made by the\ncontinuity of mind thesis.\nImagine you’ve taken over a sturdy stool at the bar of your favorite pub,\nawaiting a close friend. Call him Ken. He’s late. After a couple beers, you\ncontinue to keep your eye out for him, noting various faces as they enter the\npub. Imagine catching glimpses of someone you think might be Ken among\nAU:4\nContinuity of Mind 91\nU N C O R R E C T E D P R O O F\nan entering crowd. In that brief period of time, before being certain of this\nperson’s identity, your brain will exhibit patterns of activity that are partially\nconsistent with a number of alternative people. Figure 1A is a cartoon\nillustration of a 100-ms time slice of that brain state—that uncertain, fuzzy\nstate—if one were measuring a mere 14 of your cortical neurons (out of\nabout a billion).\nIn the idealized brain state in Fig. 1A, a few neurons are excited near their\nmaximum firing rate, several neurons are moderately above their resting\nlevel of activation, and several neurons are conspicuously inhibited below\ntheir resting level. (As these are firing rates and not action potentials, this\n‘‘state’’ is obviously an average over the 100-ms time slice.) Although this\npattern of neural activation can be treated as a discrete location in the space\nof possible brain states, it does not correspond to a discrete, pure, mental\nstate. That is, we have devised this demonstration such that the pattern of\nneural activity in Fig. 1A corresponds to a brain state that is partially\nconsistent with two diVerent identifiable mental states (Fig. 1B and C; the surface similarity in the two names here is irrelevant for our purposes).\nImagine we had the capacity to record previous moments in which you\nperceived Ken and another friend Kevin, and could establish which specific\nset of neurons corresponded to this identification, averaged over many\ninstances. Figures 1B and C depict the pattern of neural activity that would\nemerge in the situations, ‘‘I see Ken’’ and ‘‘I see Kevin,’’ respectively. In Fig.\n1B, one can see that neurons 1, 3, 6, 7, and 9 compose the population code of\n‘‘I see Ken.’’ Partially overlapping with this, in Fig. 1C, it becomes clear that\nneurons 1, 4, 6, 7, and 10 compose the population code ‘‘I see Kevin.’’ Due\nto the complexity of multiple sensory inputs, the nonlinear dynamics in\nneural processing, and noise in neural activity, these ‘‘pure’’ ideals of\ninterpretation (Fig. 1B and C) are practically unattainable, but they are\nregularly approximated by the brain’s actual pattern of activity.\nLet us simplify further and assume that each neuron in these population\ncodes is encoding some small feature about Ken and Kevin. Figure 2 shows\nthe same pattern of neural activity as in Fig. 1A, but with pretend inter-\npretations for what each neuron represents. Of course, individual neurons\nprobably encode far finer details than those depicted in Fig. 2. The term\nmicrofeatures has been used to refer to the properties of the sensory input to\nwhich individual neurons respond (Hinton, 1981). Often times, these indi-\nvidual microfeatures are not easily deciphered, either in artificial neural\nnetworks or in biological neural networks.\nBy comparing the actual neural pattern of microfeatures in Fig. 2 to\nvarious ‘‘pure’’ population codes (such as those in Fig. 1B and C), we can\ncalculate the actual neural pattern’s Euclidian proximity to these ‘‘pure’’\npopulation codes, normalize those proximity values so that they sum to 1.0,\n92 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nFig. 1. Idealized neural patterns that correspond to a graded brain state (A), and two\nexample ‘‘pure’’ states (B & C).\nContinuity of Mind 93\nU N C O R R E C T E D P R O O F\nand thus generate a rough probability distribution over possible interpreta-\ntions of the person who is entering the pub. See Fig. 3. In this way, a neural\npattern can be seen as a probabilistic mental state, represented in the form of\nits proximity to idealized pure (discretely interpretable) mental states, in-\nstead of mere activity levels of individual neurons. In contrast, a supposed\npure mental state refers to an ideal precise pattern of neural activation\nthat—due to the complex and noisy dynamics of a brain with billions of\nneurons and trillions of synapses—is never actually perfectly instantiated. In\nthis framework, a pure discrete (i.e., symbolic) mental state is an abstract\nconcept. It is a useful construct for theory development, but we argue that an\nactual physical instantiation of a symbolic mental state never comes into\nbeing. Rather, a fuzzy region of state-space broadly encompassing the\nspecific coordinates that correspond to a ‘‘pure’’ mental state (i.e., the basin\nof attraction that surrounds an individual attractor point), is what gets\nbriefly visited by the trajectory defining the system’s state as a function of\ntime. The precise set of coordinates corresponding to that ‘‘pure’’ mental\nstate (i.e., the idealized identifiable population code) is never quite reached.\nNonetheless, the labels attached to these ‘‘pure’’ mental states are extremely\nhelpful in understanding the probabilistic mental states (cf. Barber, Clark, &\nAnderson, 2003; Zemel, Dayan, & Pouget, 1998). Without the descriptive\nFig. 2. Idealized labels for each neuron in the graded brain state.\n94 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nconveniences of the labels along the abscissa in Fig. 3, a probabilistic mental\nstate would be essentially uninterpretable.\nOur talk of ‘‘states’’ could imply that this specific pattern of activation is\nstable for a certain period of time. The continuity of mind suggests, however,\nthat it would be continuously moving toward some interpretable population\ncodes and away from others. When the activations of these neural patterns\nare tracked over time, they change gradually and nonlinearly. In Fig. 4, a\ntime course plot of probabilities of diVerent interpretable population codes is illustrated. In the particular settling algorithm used here, it is guaranteed\nthat the probability value that starts out higher will be the eventual winner,\nbut this will not be true with all settling algorithms.\nAlthough this scenario quaintly displays the multifarious character of\ngraded mental states changing over time, its simplicity reveals theoretical\nflaws in the form of what might be called ‘‘edge eVects’’ in time. Figure 4 assumes that this process occurred in a contextual vacuum, involving no new\ninformative events while it was settling, and involved no action. It simply\ngravitated to a stable corner (attractor basin) in its state-space. In real life,\nno such event is free of some context, new information is constantly arriving,\nand we are often producing continuous motor actions during perception.\nThus, by the time your brain state has approached a location in state-space\nthat is roughly consistent with only one pure population code, such as .8\nFig. 3. An idealized pattern of normalized proximities (treated as probabilities) to various\n‘‘pure’’ states in the space of possible mental states.\nContinuity of Mind 95\nU N C O R R E C T E D P R O O F\nactivation for ‘‘I see Ken,’’ changes in the environment and your own\nbehavior will alter the brain state such that it travels back into ‘‘unlabeled’’\nregions in state-space, preparing for another near settling event where it gets\njust close enough to another pure mental state to elicit appropriate action\nand perhaps then veers oV once again. This more ecologically valid perspective of continuous change in natural behavior gives considerable bite to the\ncontinuity of mind proposal: It means that the vast majority of the mind’s\ntime is spent in between identifiable mental states rather than in them.\nIt is perhaps tempting to think of achieving one briefly relatively stable\nstate for one temporal portion of sensory stimulation (such as that in the\nlater time period of Fig. 4) as producing a symbollike representation that\ncould somehow persist in some mental arena, and that when the system then\ngravitates to other attractors in state-space this mental arena could somehow\naccumulate accurate renditions of these symbollike representations that are\nvisited in the continuous state-space (but cf. Bollt et al., 2000). This perspec-\ntive has much in common with the way a digital computer might shunt one\nsymbol into a working memory buVer and then shunt another and another, thus giving the system several complete representational entities to work\nwith at the same time. In fact, there are hybrid theoretical frameworks\nfor cognition and language that implement this kind of temporally dynamic\naccrual of activation for competing representations in a first stage, with\nthe winning symbolic representation then becoming part of a discrete\nrule-driven computational system in a second stage (e.g., Anderson &\nFig. 4. An idealized evolution of these probabilistic activations (or normalized proximities)\ndepicting a dynamic graded mental state over the course a several hundred milliseconds.\nAU:5\n96 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nLebiere, 1998; Budiu & Anderson, 2004; Stevenson, 1994; see also Hummel,\n2001; Marcus, 2001; Pinker & Ullman, 2002). Such frameworks hypothesize\na rather drastic schism between one part of the mind that functions in ways\nthat are consistent with the temporally continuous ebb and flow of neuronal\npopulation codes and another part of the mind that functions in ways that\nare substantially inconsistent with the neurophysiology.\nThis tempting notion of ‘‘accumulating symbols’’ after their attractors are\nvisited necessarily requires this problematic schism. Where else could those\naccumulated symbols be stored but in a separate additional system? If one\naccepts that this neural state-space can pose as a description of the activation\nof every neuron in the brain, then such a description would have no room for\nan additional separate system in the brain that could be a repository for such\nan accumulation of symbols. The only sense in which these semistable\npopulation codes—which may act something like fuzzy (nondiscrete) sym-\nbols—could accumulate, in this account, is if they continue to reverberate\ntheir coherent activation pattern while new population codes also become\ncoherently active. Note, however, that this still requires the coordinates\ndescribing the state of the system in this space to move away from their\noriginal location near that first attractor and now find a location that is\nroughly equidistant from the previous attractor and the new one. Thus, if\none endeavors to describe the entire state of mind as a system with one state-\nspace (and not as collection of independent noninteractive systems with\nseparate state-spaces), then one cannot accumulate complete unchanged\nsymbols as the state of the system travels from one attractor to another.\nHence, dealing with the fast and complex temporal sequence of sensory\nstimulation that occurs in normal everyday circumstances (although not\nnecessarily in the cognitive psychologist’s laboratory), and the spatiotempo-\nrally contiguous movement in state-space that this instigates, forces the\nbehavior of the system to be best described by its continuous trajectory\n(spending much of its time in intermediate unlabeled regions of state-space)\nrather than by an enumerated list of the interpretable attractors it visits.\nB. Continuity in Categorization?\nTo oVer a more substantive demonstration, we further exemplify this continuity by considering a particular realm of research in cognitive psychol-\nogy. The study of categorization has been at the core of psychology, and\nespecially cognitive psychology, for many decades (cf. Harnad, 1987).\nA continuity account, similar to that cartooned in Fig. 4, would naturally\npredict that categorization tasks often show quite diVerent results from speeded responses than from nonspeeded responses (e.g., Lamberts, 1995,\n1998, 2000; Lin & Murphy, 1997; Nosofsky & Alfonso-Reese, 1999; see also\nBrownell & Caramazza, 1978; Medin & Smith, 1981). This prediction derives\nContinuity of Mind 97\nU N C O R R E C T E D P R O O F\nfrom the idea that a speeded response forces an unsettled trajectory to select\namong multiple nearby attractors in an unsystematic fashion (e.g., perhaps\nstochastically). The results can allow one to infer partial activation ofmultiple\ncompeting ‘‘interpretations’’ of the stimulus array. Unfortunately, as noted\nby Lamberts (2000), it is still somewhat new and unusual for categorization\nstudies to give consideration to temporal dynamics. The bulk of the literature\nover the past few decades has focused almost exclusively on the outcome of\ncategorization rather than the process. This traditionmaymiss the fact that by\nexamining the continuous time course of online categorization, one can tease\napart various theoretical accounts that would never have been rigorously\ntested by outcome-based oZine experimental measures. For example, one theoretical account of the process of categorization,\nwhich is generally consistent with Lamberts’ (2000) information accu-\nmulation theory, can be idealistically demonstrated by a very simple\nneural network architecture called normalized recurrence (McRae, Spivey-\nKnowlton, & Tanenhaus, 1998; Spivey, Fitneva, Tabor, & Ajmani, 2002a;\nSpivey & Tanenhaus, 1998; Tanenhaus, Spivey-Knowlton, & Hanna, 2000).\nNormalized recurrence simulates the temporal dynamics of the competition\nthat emerges when multiple information sources weigh in on alternative\ninterpretations of a stimulus array. Like the probabilistic activations of\nidealized population codes (see Fig. 3), the architecture simply generates a\nprobability distribution over possible categories in order to track their\nevolution over time (usually corresponding to hundreds of milliseconds of\nreal-time cognitive processing).1 Figure 5 shows the diagram of a very simple\nnormalized recurrence architecture used to approximate the changing pat-\nterns of activation during the categorization of diVerent animals into their respective classes (fish, mammal, bird, and reptile). As the normalized recur-\nrence competition algorithm works, these five feature vectors (framed cir-\ncles) are normalized to sum to 1 and are then combined at the integration\nlayer (framed ovals), replacing its previous activation pattern. In this simu-\nlation, there are no diVerential weights for the five feature vectors; they simply sum together at the integration vector. The integration layer then\ndivides each of its nodes’ activation by the vector’s sum activation, thus\nmaking the integration vector simply an average of the five feature vectors.\nCumulative feedback is then sent by adding to each feature node the product\nof itself and its corresponding integration node. The next time step begins\n1 The distributed population codes of the network are simplified as localist nodes for features\nand classes, as in our first example. However, this competition algorithm does not address what\nthe localist representations are made of, nor how they developed. Despite these idealizations,\nthe architecture allows for rather sophisticated modeling of temporal processes of interpretation\nand categorization.\n98 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nwith the feature nodes normalizing themselves again (diving each node by\nthe vector’s sum), and the integration, normalization, and feedback take\nplace again. These four calculations are computed within each time step, and\nthe network continues until a criterion activation (often .95) is reached by an\nintegration node. The cyclic recurrent flow of activation between the inte-\ngration vector and the feature vectors allows strong and selective biases\nwithin certain feature vectors to coerce weak and uncertain biases in others,\nuntil the system gradually settles into a stable state.\nThis localist attractor network (inspired significantly by McClelland\nand Rumelhart’s (1981). Interactive Activation model, and Anderson,\nSilverstein, Ritz, and Jones’s (1977) Brain-State-in-a-Box model; see also\nGrainger & Jacobs, 1998; Zemel & Mozer, 2001) easily categorizes animals\nthat are typical exemplars of their taxonomic class, such as ‘‘toucan,’’\nFig. 5. Schematic diagram of a normalized recurrence simulation of the temporal dynamics\nof categorization. The repeated node labels in some of the feature vectors (circles) are necessary\nbecause each integration node (ovals) must have its own unique feature node. This allows the\nfeature vectors to function as probability distributions in their support for the appropriate\ntaxonomic class. For example, after the initial feature vector normalization step, the birth mode\nvector for a live-birth animal would pass 1.0 activation to the Mammal node and 0 activation to\nthe other taxonomic class nodes, whereas for an egg-laying animal the birth mode vector would\nsend .333 activation to the Fish, Bird, and Reptile nodes, and 0 activation to the Mammal node.\nAU:42\nAU:43\nContinuity of Mind 99\nU N C O R R E C T E D P R O O F\n‘‘goldfish,’’ and ‘‘cat’’ (see Fig. 6). However, with animals that are unusual\nmembers of their class, the network undergoes a long, drawn-out competi-\ntion due to the animal’s partial match with multiple taxonomic classes.2 The\ngradual activation curves are similar to those produced by Lamberts’ (2000)\ninformation accumulation model, and the overall typicality eVects coincide with theories of graded category structure (e.g., Rosch & Mervis, 1975;\nSmith, Shoben, & Rips, 1974). Note how, in Fig. 6, the simulations for\n‘‘seal,’’ ‘‘whale,’’ ‘‘penguin,’’ ‘‘turtle’’ and ‘‘platypus’’ exhibit slow rises to\ncriterion for the correct classification, and even then their asymptotes are\nsubstantially below 1.0. In the end, the model concludes that a whale is .6 a\nmammal and .4 a fish. And, in fact, during its first few time steps of\nprocessing, the model briefly conceives of a whale as slightly more a fish\nthan a mammal. A similar crossing of curves is seen with a turtle.\nThis simulation serves as a simple existence proof of how graded temporal\ndynamics can be realized in a system of neural population codes. Admitted-\nly, even if the model’s predictions were to fit human data perfectly, we would\nnot contend that the mechanism matches the brain’s own. But could these\ncurves really be anything at all like what a human mind does when it\ncategorizes animals? During the early moments of settling on a categoriza-\ntion for an animal, do people simultaneously partially consider multiple\ncategories? And do those partially active representations compete over time\nin order for a cognitive trajectory to settle into eliciting a unique motor\noutput?\nUsing the method of eye tracking, Nederhouser and Spivey (2004) con-\nducted a pilot experiment that supports this speculation. Although, as\ndescribed, comparing speeded instinctive responses to slow contemplative\nresponses (e.g., Lin & Murphy, 1997) is a good start for measuring this kind\nof time course question, a semicontinuous measure may be more revealing\nby demonstrating accruing activation that supports diVerent interpretations. Because eye movements occur about 2–3 times per and are largely unaVected by deliberative strategies, they can provide a stream of multiple honest\n‘‘proto-actions’’ over the course of the few seconds required to produce a\nsingle overt verbal or manual action.\nIn the pilot study, the eye movements of 17 participants were recorded\nwhile they categorized small plastic toy animals (about 200 300) into either of 2 In fact, in this rather small and oversimplified simulation, since the Principal Limbs and\nEnvironment feature vectors for ‘‘bat’’ uniquely support the ‘‘bird’’ category, and only the Birth\nMode feature vector uniquely supports the mammal category, there actually winds up being\nmore overall support for incorrectly categorizing a bat as a bird (asymptote at .8) than as a\nmammal (asymptote at .2). Expansion of the model to include more features, more classes, and\nperhaps diVerential weights for the feature vectors, would be necessary to eradicate errors like\nthis.\n100 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\ntwo bins. Participants were first shown a set of animals (half from one\ntaxonomic class, half from another), and then were presented each animal\none at a time. It was observed that animals that are atypical members of\ntheir taxonomic classes, like turtles, penguins, seals, and whales, took longer\nto categorize than more typical animals (cf. Glass & Meany, 1978; Rips,\nShoben, & Smith, 1973), and they also elicited quite a bit of vacillation in eye\nmovements between the two category bins. When participants categorized\nFig. 6. Activation curves from the simulation of the temporal dynamics of catregori-\nzation. Feature nodes that received 1.0 activation at start, for the five input vectors, were\nthe following: CAT (legs, land, warm, air, live), SEAL (fins, water, warm, air, live), WHALE\n(fins, water, warm, air, live), TOUCAN (wings, sky, warm, air, eggs), DUCK (wings–legs, water–\nland–sky, warm, air, eggs), PENGUIN (wings, land–water, warm, air, eggs), LIZARD\n(legs, land, cold, air, eggs), GOLDFISH (fins, water, cold, water, eggs), EEL (all limbs, water,\ncold,water, eggs), TURTLE (legs,water, cold, air, eggs),WATERSNAKE (all limbs, land–water,\ncold, air, eggs), and PLATYPUS (legs, land–water, warm, air, eggs).\nAU:44\nContinuity of Mind 101\nU N C O R R E C T E D P R O O F\nan atypical member of a category, they often fixated both bins multiple times\nbefore settling on the correct bin and dropping the animal into it. Crucially,\nwhen one looks again at the records of eye position over time, one can plot\nfixation curves based on the proportion of fixations at each time slice (Fig. 6),\nthat resemble somewhat the activation curves from the network simulations\n(Fig. 7). The curves in Fig. 6 show, for each 33-ms time slice, the proportion\nof trials in which the subjects were fixating the correct category bin or the\nincorrect category bin, following their first saccade away from the toy\nanimal that was placed in front of them. Note how, in the case of penguins,\nseals, and whales, some subjects continued to fixate the incorrect bin for the\nfull 2 s shown; in some cases, they even placed the whale in the fish bin.\nThis comparison of pilot simulation and pilot data provides a glimpse into\nthe beginning stages of how wemight better understand the temporal dynam-\nics of real-time categorization. The demonstration is intended to illustrate\nhow one can begin to visualize the fuzzy and graded representations that\nchange over time during categorization, both in a localist attractor network\nand in a semicontinuous record of cognitive processing. And perhaps some of\nthe more static, formal approaches to concepts and categorizationmight have\ntrouble accommodating such evidence that, during a categorization event, the\nmind spends so much of its time in graded, rather than discrete, mental states.\nThe important point to be made here is that these very specific locations in\nstate-space that seem to have easily labeled identities, these pure mental\nstates of ‘‘I see Ken’’ or ‘‘I see a mammal’’ can only be approximated by\nthe actual neural system for which this state-space is an abstracted mathe-\nmatical description. That is not to say those pure mental states are irrelevant\nor nonexistent. They do exist, as possible locations in the neural system’s\nstate-space. The neural population codes get suYciently activated (i.e., the system approaches close enough to a frequently visited and identifiable\nattractor basin) to convince one phenomenologically that these pure mental\nstates have been perfectly instantiated. We would argue instead that they\nhave an infinitesimally small likelihood of ever happening.\nWith these simple examples to help guide our path, we now discuss\nlanguage and vision, and the rather impressive support each brings to this\nperspective that cognition inherently consists of continuity.\nIII. Continuity in Language Processing\nHere we consider language comprehension in real time as a particularly\nevocative example of continuous sensory input producing continuous cogni-\ntive processing—in spite of our clumsy metalinguistic introspection that we\nperceive one word and then silence and then another word. We argue that\n102 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nthis process, at its various levels of complexity, is driven by graded and\npartially active information. We present these processes at increasing time\nscales, beginning with speech perception (hundredths of seconds), word rec-\nognition (tenths of seconds), and concluding with sentence processing (sec-\nonds). Despite these diVerent time scales, each exhibits the continuity ofmind.\nA. Speech Perception\nHumans are wont to carve up their world into seemingly very discrete\ncategories. These categories are often imposed even within variation among\nthe things being categorized. Categorical perception describes the general\nFig. 7. Eye-fixation curves from Nederhouser and Spivey (2004). Animals that are atypical\nexamples of their taxonomic class elicited considerable vacillation in eye movements during the\nearly moments of categorization.\nContinuity of Mind 103\nU N C O R R E C T E D P R O O F\ntendency to cut a fine line along a gradient of variation; any inputs that fall\nto the left or right of this line will be part of one or the other category.\nDespite its name, ‘‘categorical’’ perception of speech sounds can be made\nconsistent with more temporally dynamic approaches to categorization (e.g.,\nAnderson et al., 1977; Dailey, Cottrell, Padget, & Adolphs, 2002; Lamberts,\n2000; Pisoni & Tash, 1974; Tuller, Case, Ding & Kelso, 1994; see also Cree,\nMcRae, & McNorgan, 1999). Indeed, the previous sections would suggest\nthat categorical speech perception does not just consist in graded patterns of\nneural activation, but might exhibit such gradation in behavior when we use\ncontinuous-time measures to investigate its finer temporal structure (rather\nthan simply observe explicit identification of a speech sound).\nIn pursuit of this, McMurray and Spivey (1999) tracked participants’ eye\nmovements while they performed the standard categorical identification\ntask. This task involves categorizing diVerent versions of ‘‘pah’’ and ‘‘bah’’ sounds, lying along the voice-onset time (VOT) dimension that distinguishes\nthem, by clicking /ba/ and /pa/ icons on a computer screen. Thus, in addition\nto recording the participants’ explicit choice, there was also a semicontin-\nuous record of how the eyes tended toward one or the other response icon\nduring categorization. With ‘‘pah’’ or ‘‘bah’’ sounds near their categorical\nboundary, eye movements clearly exhibited conspicuous vacillation between\nthe /ba/ and /pa/ icons. Figure 8 shows two typical eye-fixation-over-time\nplots during the speech categorization process for a clear ‘‘pah’’ stimulus\n(panel A) and for a sound that was near the category boundary but was\nnonetheless identified (by mouse click) as /pa/ 95% of the time (panel B). The\neye position records depicted here came only from trials in which the /pa/\nicon was indeed clicked at the end of the trial. Despite the identification\noutcome being identical in this subset of trials (all categorized as /pa/), the\npattern of eye movements reveals substantially more time spent fixating the /\nba/ icon (dashed area in panel B) when the speech stimulus was near the VOT\ncategory boundary; thus indicating a clear eVect of perceptual gradations in speech sounds.\nIn fact, these temporary phonemic ambiguities, as tested with VOT con-\ntinua and eye movement records, exhibit their eVects not just in phoneme identification tasks but also in spoken word recognition tasks (McMurray,\nTanenhaus, & Aslin, 2002; McMurray, Tanenhaus, Aslin, & Spivey, 2003).\nFor example, within-category variation of VOT does not aVect the final outcome of recognizing bear versus pear; however, it does aVect the eye movement records of participants looking at and clicking the corresponding\nimages on the computer screen (McMurray et al., 2002). A particularly\ncompelling way to visualize these eye movement data for the phoneme\nidentification task is to convert them into identification functions for early,\nintermediate, and late periods of time during the identification process.\n104 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nFigure 9 shows an example of the proportion of time the eyes spent fixating\nthe /pa/ icon as a function of VOT. The later period of the identification\nprocess (1201–1500 ms) reveals an eye movement identification function that\nlooks just like the typical discrete categorical identification function pro-\nduced by button press responses. However, the earlier periods of the iden-\ntification process (i.e., 0–300 ms, 301–600 ms, and even 601–900 ms) look\nsignificantly more probabilistic and are graded in a way that reveals some\nsensitivity to the continuous variation in VOT.\nAs done in the previous exploration of categorization, it can be illuminat-\ning to simulate the graded temporal dynamics of ‘‘categorical’’ speech per-\nception with a localist attractor network. This practice helps to visualize the\ncontinuous changes taking place in the patterns of activation corresponding\nto competing ‘‘graded category’’ states. Figure 10 illustrates the architecture\nof a normalized recurrence simulation that integrates a speech vector (that\npits ‘‘bah’’-like sounds against ‘‘pah’’-like sounds) and a visual vector\n(that compares fixation probabilities to a /ba/ icon, a /pa/ icon, and the\ncentral fixation dot). The speech vector is given a pattern of input\ncorresponding to a speech sound somewhere along the VOT continuum.\nFor example, a rather unambiguous ‘‘pah’’ sound might get a starting\nactivation of (.1 0 .9) for those three nodes, whereas a borderline ‘‘bah’’\nsound might get (.6 0 .4). The visual vector always starts at (.33 .33 .33),\ntreating each visual object as equally worthy of attracting an eye movement.\nFig. 8. Proportion of trials in which participants were fixating the /ba/ or the /pa/ icons,\ntime slice by time slice, after hearing an unmistakable ‘‘pah’’ from the VOT continuum (panel\nA) and after hearing a speech sound near the category boundary (panel B). The hatched region\nin the panel B indicates the degree to which within-category variation (in contrast to panel A)\naVected eye movements to the competitor icon /ba/, even for just those trials that were identified\nas /pa/ (adapted from McMurray et al., 2003).\nContinuity of Mind 105\nU N C O R R E C T E D P R O O F\nAs in the previous section, these two vectors simply sum at the integration\nlayer, which then normalizes itself and sends feedback to the feature vectors.\nIn this simulation, we can sample the proportion of fixations from the\nvisual vector, and thus watch the simulated eye movement patterns move\naway from fixating the central dot and toward one or the other response\nFig. 9. When proportion of eye movements to /ba/ and /pa/ are treated like an identification\nresponse across the stimuli of the VOT continuum, the later periods of time after presentation\n(1201–1500 ms) exhibit the typical step-function of categorical perception, but the early periods\nof time (301–600 ms) exhibit a substantially more graded transition between ‘‘ba’’-like states\nand ‘‘pa’’-like states (adapted from McMurray & Spivey, 1999).\nFig. 10. A simple normalized recurrence localist attractor simulation of speech input from a\nVOT continuum and visual input from a set of response icons. See text for details.\n106 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nicon. Figure 11 shows the activation curves over time for the /pa/ visual node\nand the /ba/ visual node. Panel A plots these curves for a rather clear ‘‘pah’’\nspeech input (.2 0 .8), and panel B plots these curves for a ‘‘pah’’ speech\ninput that is near the category boundary (.4 0 .6). These activation curves\nfrom the visual vector mimic the proportion of fixations at each time slice\n(Fig. 8) in the results of McMurray and Spivey (1999); and McMurray et al.\n(2002, 2003).\nWhen this simulation is run for all 11 speech tokens along the VOT\ncontinuum, it is possible to calculate the proportion of time the model\nspends ‘‘fixating’’ the /pa/ icon versus the /ba/ icon, and thus plot a categori-\ncal identification function. Crucially, this can be done for early periods of\ntime during the network’s settling process, as well as for intermediate and\nlate periods of time—just as was done in Fig. 9. The resulting graph is shown\nin Fig. 12.\nIn both the normalized recurrence and human cases, the identification\nfunction starts out rather unbiased and gradually approaches the classic\nstep-function profile by continuously increasing one-half of the curve and\ndecreasing the other half of the curve over time. Thus, if the identification\nfunction is to be interpreted as a kind of signature of the internal pattern of\nactivation favoring the perception of ‘‘bah’’ or ‘‘pah,’’ then this signature at\nthose early moments in time looks decidedly more continuous than the\nlegendary step function that motivated the aphorism, ‘‘speech is special’’\n(cf. Liberman, 1982).\nFig. 11. Activation over time of the /ba/ and /pa/ visual nodes after an unmistakable ‘‘pah’’\n(panel A) and after a speech sound near the category boundary (panel B). The hatched region in\npanel B shows portion of /ba/ node activation over and above that in panel A. (Compare to\nFig. 8.)\nAU:6\nContinuity of Mind 107\nU N C O R R E C T E D P R O O F\nB. Spoken Word Recognition\nEven those readers wary of the continuity of mind must admit that the\nspeech signal for word recognition is continuous. Individual phonemes do\nnot occur discretely, as categorical perception described might suggest;\ninstead, individual sounds, so to speak, smoothly blend into each other in\nnatural speech. Speech is indeed quite exemplary of Gibson’s continuous\n‘‘flowing array of stimulus energy.’’\nIn a classic set of experiments, Marslen-Wilson and colleagues demon-\nstrated that, to a first approximation, complete recognition of a word occurs\nshortly after the auditory input uniquely specifies a lexical candidate (for\nreview, seeMarslen-Wilson, 1987). Forwords ofmany syllables, this canoccur\nprior to the end of the word. For example, the word elephant would be\nrecognized shortly after the sound /f/. Prior to that, the auditory input would\nbe consistent with the beginnings of several words, including elephant, elegant,\neloquent and elevator. Thus, recognition of a spoken word is strongly infl-\nuenced by the words to which it is phonetically similar, especially those words\nthat share initial phonemes. Marslen-Wilson referred to the set of lexical\ncandidates that is activated in the same phonetic environment as a ‘‘cohort.’’\nEvidence from several experimental paradigms indicates that these candi-\ndates are partially activated as a word is being processed (not unlike the\nFig. 12. Relative proportion of the /ba/ and /pa/ visual node activations (excluding ‘‘center’’\nnode) across diVerent stimulus gradations between ‘‘ba’’ and ‘‘pa’’ at diVerent cycles of\ncompetition in normalized recurrence.\n108 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\npartial activations over time for the mental states in Fig. 4). For example,\ncross-modal lexical priming experiments demonstrate that semantic infor-\nmation associated with cohort members is temporarily activated as a word\nunfolds (Zwitserlood, 1989). The prior context of the utterance and\nsubsequent input provide evidence that is used to evaluate the competing\nalternatives. While current models diVer in how they account for these data, nearly all models incorporate the idea that the time it takes to recognize a\nword depends on a set of potential lexical candidates (see Cutler, 1995, for\na review).\nProviding concrete evidence for the activation of multiple alternative\nlexical items during recognition of a spoken word, Spivey-Knowlton, Sedivy,\nEberhard, and Tanenhaus (1994) reported cohort eVects in eye movement patterns by having subjects follow instructions to manipulate real objects.\nParticipants sat in front of a table containing a central fixation cross and\nvarious objects around it (e.g., a fork, a mug, a candle). In some trials,\nobjects whose names had similar initial phonemes were present on the table,\navailable for manipulation (e.g., a bag of candy and a candle). For this\n‘‘cohort competitor present’’ condition, Fig. 13 shows the proportion of\ntrials, at each time slice, in which the participants’ eyes were fixating each\nof the various objects. The probability of looking at the cohort object, (e.g.,\nthe candy, when instructed to ‘‘Pick up the candle’’), rose just as quickly as\nFig. 13. Proportion of fixations of various objects across time as the target word unfolds\n(e.g., about 300 ms for the word candle). Note the conspicuous rise of eye movements to the\ncohort competitor object (filled triangles; from Spivey-Knowlton & Allopenna, 1997).\nContinuity of Mind 109\nU N C O R R E C T E D P R O O F\nthe probability of looking at the target object, for a period of about 200 ms\naround the tail end of the spoken word. And even when the two curves\ndiverge, the proportion of fixations of the cohort object still persists for a few\nhundred milliseconds. This salience of the cohort object conspicuously at-\ntracting eye movements is indicative of the competing lexical representation\nbeing partially active during, and perhaps shortly after, delivery of the\nspoken word.\nHeadband-mounted eye-tracking studies like this have demons-\ntrated this real-time lexical competition using computer-displayed objects\n(Allopenna, Magnuson, & Tanenhaus, 1998), using artificial lexicons\n(Magnuson, Tanenhaus, Aslin, & Dahan, 2003), with young children\n(Fernald, Swingley, & Pinto, 2001), and even across two languages in\nbilingual participants (Marian & Spivey, 2003; Spivey & Marian, 1999).\nMarslen-Wilson’s (1987) cohort theory naturally predicts findings like\nthese, and McClelland and Elman’s (1986) TRACE model can quantitative-\nly simulate them. In the TRACE model of word recognition, activation is\npassed forward and backward between a layer of phonetic feature nodes, a\nlayer of phoneme nodes, and a layer of word nodes. As the network receives\nphonetic feature activation corresponding to early speech information, it\ngradually settles toward a state of exhibiting activation for only the words\nthat are consistent with the current speech input. In this way, TRACE can\nexplicitly implement the cohort eVect described in the Marslen-Wilson’s cohort theory. In fact, by integrating TRACE with the normalized recur-\nrence architecture previously described, to impose the visual constraints\non which objects and lexical items accrue significant activation, quite accu-\nrate predictions about eye movement dynamics can be made (Spivey, in\npreparation).\nThe TRACE network also makes a prediction that diverges from\nMarslen-Wilson’s cohort theory. Since TRACE has only positive connec-\ntions between layers (and only inhibitory connections within layers), it\ndoes not prevent, and will in fact induce, the activation of lexical items\nthat rhyme with the word being spoken. Therefore, TRACE predicts that\nwhen instructed to ‘‘Pick up the candle,’’ a person should conspicuously\nfixate a handle in the display, whereas the standard version of the cohort\ntheory would not predict this. Indeed, TRACE’s prediction holds true.\nListeners will briefly look at an object whose name rhymes with the spoken\nword more so than unrelated control objects (Allopenna et al., 1998).\nAllopenna et al., showed that the activations of the lexical nodes in TRACE\n(once scaled by an exponential and normalized) closely mimic the probabili-\nty-of-fixation functions from these eye-tracking experiments (compare\nFigs. 13 & 14).\n110 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nC. Sentence Processing\nIn the 1970s, a ‘‘clausal processing theory’’ emerged in psycholinguistics,\narguing that most of the syntactic and semantic processing of a sentence\ntook place at the ends of its clauses rather than continuously throughout the\nsentence (e.g., Bever & Hurtig, 1975). The impetus for this theory largely\nderived from two sources. One was to maintain some level of consonance\nbetween psycholinguistic investigation and linguistic theories that incor-\nporated a unique syntactic level of processing. The second, interestingly,\nwas largely induced by Marslen-Wilson’s famous shadowing experiments\n(Marslen-Wilson, 1973). In these experiments, participants verbally followed\na spoken passage played to them and tried to repeat it out loud as quickly as\npossible. This close speech-shadowing task revealed that mistakes made by\nparticipants were largely grammatically and semantically appropriate\namidst their previous and subsequent repetition. This suggested that syntax\nand semantics are in fact being processed together continuously during\nsentence processing. Clausal processing theory aimed to counter these results\nand bring psycholinguistics closer to contemporary syntactic theories in\nlinguistics.\nSubsequent theories of sentence processing often urged the continuous\nnature of syntactic and semantic computations on linguistic input, but\nFig. 14. Activations of the lexical nodes in McClelland and Elman’s (1986) TRACE model\nof speech processing, scaled by an exponent and normalized (from Spivey-Knowlton &\nAllopenna, 1997). (Compare to Fig. 13.)\nContinuity of Mind 111\nU N C O R R E C T E D P R O O F\nassailed the interactive aspect of Marslen-Wilson’s (1973; Tyler & Marslen-\nWilson, 1977) framework. Frazier and Fodor (1978) proposed a set of\nsyntactic structuring heuristics for real-time sentence processing that oVered an account of certain errors and hence misunderstandings in parsing a\nsentence. Frazier and colleagues argued that a syntactic parsing module in\nthe mind automatically attaches each new incoming word in such a way that\nminimizes the number of branches in a syntactic tree structure. With sen-\ntences like that in (1), taken from Bever (1970), which contain temporary\nsyntactic ambiguities, the particular tree-structuring format that Frazier\nemployed posited fewer branching nodes if the verb ‘‘raced’’ was integrated\nas part of the sentence’s main verb rather than as a relative clause describing\n‘‘horse.’’ This ‘‘minimal attachment’’ hypothesis predicted that a reader or\nlistener will build the syntactic structure consistent with the horse doing the\nracing (rather than being raced by someone), and this would essentially lead\ncomprehension ‘‘down a garden path’’ that will not work with the\nsubsequent words. The result is that by the end of the sentence, the verb fell\nhas nowhere to attach and thus cannot easily be grammatically integrated\ninto the sentence.\n(1) The horse raced past the barn fell.\nThroughout the 1980s, Frazier and colleagues recorded eye movements\nduring reading tasks and concluded that sentence processing did not involve\nreal-time interaction between syntax and meaning because semantic and\ndiscourse context did not appear to prevent the all-important syntactic\nheuristics from generating garden path eVects (e.g., Ferreira & Clifton, 1986; Rayner, Carlson, & Frazier, 1983). In addition, in opposition to\nclausal processing theory, they argued that sentence processing involved\ncontinuous flow of information (or at least word-by-word incremental\nflow) because the eVects of the syntactic heuristics are detectable in the eye movement data (as increases in reading times) the moment the reader fixates\nthe critical word disambiguating the sentence, regardless of where any\nclauses begin or end (Frazier, 1998; Frazier & Clifton, 1989; Frazier &\nRayner, 1982). This work constituted more than a decade of research\ncharacterizing comprehension as an incremental word-by-word (not\nclause-by-clause) process in which syntax alone was processed in an early\nstage of the system, and then semantics and other contextual constraints\nwere consulted in a later stage of the system, in the event of anomalies like\ngarden path eVects. There remains ongoing debate about the interactive nature of sentence\nprocessing. To illustrate, consider sentence (2) (from Tanenhaus & Trueswell,\n1995). It has exactly the same structure as (1) but does not induce a garden\npath eVect. (2) The land mine buried in the sand exploded.\n112 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nIf syntax were sovereign in this situation, it should be equally diYcult to process sentences (1) and (2). The semantic constraints imposed by the lexical\nitems in (2), ‘‘landmine’’ and ‘‘buried,’’ seem to steer the reader away from\nthe garden path, implicating a more interactive perspective on sentence\nprocessing. MacDonald, Pearlmutter, and Seidenberg (1994) argued that\nexamples like these illustrate that structural biases during parsing emerge\nout of the interaction of both syntactic and semantic constraints. They\nreport extensive experimental evidence in support of this perspective.\nThe theoretical upshot from MacDonald et al. was to propose that mul-\ntiple constraints are marshaled in the service of sentence processing. These\nconstraints (lexical, semantic, pragmatic) act simultaneously to influence\nonline interpretation of sentences. Indeed, when these various factors\nare controlled for their relative contribution, the accumulating evidence\noverwhelmingly supports an interactive perspective on sentence processing\n(e.g., Altmann, Garnham & Dennis, 1992; Altmann & Steedman, 1988;\nFarrar & Kawamoto, 1993; Pearlmutter & MacDonald, 1995; McRae\net al., 1998; Spivey & Tanenhuas, 1998; Spivey-Knowlton & Sedivy, 1995;\nTrueswell & Kim, 1998; Trueswell, Tanenhaus, & Garnsey, 1994;\nvan Berkum, Brown, & Hagoort, 1999).3\nOne way of demonstrating the power of these contextual eVects is through the semicontinuous record of eye movements during spoken sentence com-\nprehension. For example, when presented with a real 3-D display containing\nan apple on a towel, another towel, and an empty box, and then instructed to\n‘‘Put the apple on the towel in the box,’’ participants often look briefly at the\nirrelevant lone towel near the end of the spoken instruction before returning\ntheir gaze to the apple, grasping it, and then placing it inside the box (Spivey,\nTanenhaus, Eberhard, & Sedivy, 2002b; Tanenhaus, Spivey-Knowlton,\nEberhard, & Sedivy, 1995). (With unambiguous control sentences, such as\n‘‘Put the apple that’s on the towel in the box,’’ they almost never look at the\nirrelevant lone towel). In this case, the syntax is ambiguous as to whether the\nprepositional phrase on the towel is attached to the verb put (as a movement\ndestination) or to the noun apple (as a modifier). Given the actions aVorded by the display, the latter syntactic structure is the correct one. However,\npeople tend to have a bias toward interpreting an ambiguous prepositional\nphrase as attached to the verb (Rayner, Carlson, & Frazier, 1983), at least\nAU:8\nAU:9\nAU:7\n3 In fact, at this point in the literature, the debate has largely shifted to determining how the\nsyntactic alternatives of an ambiguity, supported by their various constraints, are adjudicated;\nwith some researchers advocating a temporally dynamic competition process (e.g., McRae et al.,\n1998; Spivey & Tanenhaus, 1998; Spivey, Fitneva, Tabor & Ajmani, 2002a; Stevenson, 1994;\nTabor & Tanenhaus, 1999; Tanenhaus et al., 2002) and others describing an immediate winner-\ntake-all framework (e.g., Jurafsky, 1996; van Gompel, Pickering, & Traxler, 2001).\nContinuity of Mind 113\nU N C O R R E C T E D P R O O F\nwhen it is an action verb like put (cf. Spivey-Knowlton & Sedivy, 1995).\nThus, the brief fixation of the irrelevant lone towel indicates a temporary\npartially activated incorrect parse of the sentence. To demonstrate the\ninfluence of visual context on this syntactic ambiguity resolution process,\nthe display was slightly altered to include a second apple (resting on a\nnapkin). In this case, the visual copresence (in Herb Clark’s, 1992, words)\nof the two potential referents for the phrase the apple should encourage\nthe listener to interpret the ambiguous prepositional phrase on the towel as\na modifier (in order to determine which apple is being referred to) rather\nthan as a movement destination (cf. Altmann & Steedman, 1988; Crain\n& Steedman, 1985; Spivey & Tanenhaus, 1998). And, indeed, with this\ndisplay, participants rarely fixated the irrelevant lone towel, indicating that\nvisual context had exerted an immediate influence on the incremental syn-\ntactic parsing of the spoken sentence (Spivey et al., 2002b; Tanenhaus et al.,\n1995; see also Knoeferle, Crocker, Scheepers, & Pickering, 2003).\nThe current state of aVairs in the field of sentence processing is at a consensus with regard to the continuity of information flow and has been\ngradually approaching consensus with regard to the rapid integration of\nsyntax, semantics, and pragmatic context. Just as the processing of speech\nsounds, at the scale of tens of milliseconds, appears to be characterized by\nmultiple partially active phonemic representations competing over time\n(McMurray et al., 2002, 2003), and the comprehension of spoken words,\nat the scale of hundreds of milliseconds, appears to be characterized\nby multiple partially active lexical representations competing over time\n(Allopenna et al., 1998; Marslen-Wilson, 1987; McClelland & Elman,\n1986), so does the resolution of syntactic ambiguity, at the scale of seconds,\nappear to be characterized by multiple partially active syntactic representa-\ntions competing over time (MacDonald et al., 1994; Spivey & Tanenhaus,\n1998; Stevenson, 1994; Tabor & Tanenhaus, 1999).\nIV. Continuity in Visual Perception\nAs speech enters the sensory system through time, it is perhaps an obvious\ncase where continuous temporal dynamics would be prominent in the result-\ning perceptual-cognitive processing. Visual input, however, is often delivered\nto the sensory system in an instantaneous fashion (in the laboratory, at\nleast). Does the internal processing of an instantaneously presented visual\nstimulus exhibit any interesting temporal dynamics? In this section, we\ndescribe a number of findings and demonstrations of continuous accrual of\nactivation during visual processing.\n114 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nA. Object and Face Recognition\nAs vision is a modality in which we share much in common with nonhuman\nprimates, it has been studied in-depth with neurophysiologically invasive real-\ntime measures that, indeed, quite richly illustrate the temporal dynamics of\nthe resulting perceptual-cognitive processing. Vision research is replete with\nexamples of temporal continuity in real-time perception. The gradual settling\n(or pattern completion) of a neuronal population code, over the course of\nhundreds of milliseconds, is a common way to think about how the visual\nsystem recognizes objects and faces. Compelling visualizations of the contin-\nuous manner in which sensory input gradually produces a percept can easily\nbe found in visual neuroscience. For example, Rolls and Tovee (1995) re-\ncorded from multiple neurons in the inferotemporal cortex of the macaque\nmonkey and found that it takes a few hundred milliseconds for the right\npopulation of cells to achieve their appropriate firing rates for fully identifying\na fixated object or face. The cumulative information (in bits) provided by an\ninferotemporal neuron in the service of recognizing a face or object accrues\ncontinuously (though nonlinearly) over the course of about 350 ms (see\nFig. 15). About 80 ms after the presentation of the visual stimulus, these cells\nbegin firing, and during the first 70 ms of firing, about 50% of the total\ninformation to be encoded is already accumulated. Thus, very quickly,\nthe inferotemporal network is able to project itself into the correct ‘‘neigh-\nborhood’’ in its state-space. (This allows some coarse gistlike visual discrimi-\nnations to actually be made with 100 ms or less of stimulus presentation\ntime; e.g., Potter, 1976, 1993; Van Rullen & Thorpe, 2001.) However, over\nthe next 200 ms or so, the process of object or face recognition is still\nin progress, during which the remaining 50% of the information to be\nrepresented by the distributed population code is gradually accumulated.\nPerrett, Oram, and Ashbridge (1998) report further patterns of gradual\naccumulation of neuronal evidence for face recognition. When an object or\nface is partly rotated away from a canonical or frontal view, recognition or\nmatching will generally take longer as a function of how far it is rotated (e.g.,\nCooper & Shepard, 1973; Jolicoeur, 1985; Shepard & Metzler, 1971; see also\nGeorgopoulos, Lurito, Petrides, Schwartz, & Massey, 1989). Perrett et al.\n(1998) describe recordings from cells in the monkey temporal cortex during\nviewing of frontal, three-fourth profile, profile, and one-fourth profile sche-\nmatic faces. When the accumulated action potentials are plotted over time,\nthese curves rise at diVerent rates as a function of how canonical the face orientation is. Figure 16 depicts the continuous nonlinear rise in accumu-\nlated neuronal spikes over the course of several hundred milliseconds as\nrecognition takes place. As these curves plot accumulated spikes, rather than\nContinuity of Mind 115\nU N C O R R E C T E D P R O O F\nFig. 15. Average cumulative information accrued over milliseconds by inferotemporal cells\nrepresenting objects and faces (adapted from Rolls & Tovee, 1995).\nFig. 16. The accumulation over time of neuronal spikes (over and above the baseline spike\nrate) from cells responding to faces at various rotations around the vertical axis (adapted from\nPerrett et al., 1998).\n116 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\ninformation-theoretic bits per neuron, they asymptote somewhat later in\ntime than the curve in Fig. 15. Note again how these curves reach their half\nheight relatively early on, yet still spend several hundred milliseconds grad-\nually approaching their respective asymptotes (except for the back-of-head\nview, which asymptotes rather low within a few hundred milliseconds).\nA few (or even several) hundred milliseconds for a population code to be\n‘‘in transit’’ on the way toward achieving its potentially stable asymptotic\nstate might initially seem like a rather small amount of time to get excited\nabout. Are these transition periods perhaps just interesting curiosities, while\nthe important observation is that a stable state is eventually reached, and is it\nthat on which discrete mental computations might be performed? We think\nnot. It is our hypothesis that in more complex visual (as well as auditory,\nsomatosensory, etc.) environments, the proportion of time spent in these\nunstable regions of state-space—that is, in the process of traveling toward an\nattractor basin, but not in one yet—is actually much greater than the\nproportion of time spent in relatively stable regions of state-space.\nThis gradual accrual of the information comprising a population code\n(Figs. 15 and 16) has powerful consequences for how we conceptualize what\nthe brain is doing when we go about our business of naturally perceiving the\nworld around us. Consider how your eyes move around a complex scene like\nthe one in front of you right now. Your eyes rest, with the two foveas fixating\na particular location in the visual field, for about 300–400 ms on average (cf.\nRayner, 1998). They then make a fast, ballistic, jump (lasting a few dozen\nmilliseconds or so) away from that location to fixate another location in the\nvisual field. After resting there for another 300–400 ms, they jump yet again\nto another location. Each new fixation brings a new word, object, or object\npart into the high-resolution view of your foveas for little more than one-\nthird of a second. Now, if it takes almost half a second for the appropriate\npopulation code to get fully settled in recognizing a fixated object (Figs. 15 &\n16), but your eyes normally move to a new object every one-third of a\nsecond, how can the brain possibly achieve a genuinely stable asymptotic\nstate (or temporally discrete representation) for any object recognition\nevent?\nB. Visual Search\nThe same kind of gradual accumulation of perceptual evidence can be\nobserved when multiple objects are competing for attention during visual\nsearch. The field of visual search has generally been driven by two opposing\ntreatments of attention. The serial-processing perspective holds that the\nobserver allocates attentional resources wholly and discretely to individual\nobjects, one at a time (e.g., Treisman, 1988; Treisman & Gelade, 1980). The\nContinuity of Mind 117\nU N C O R R E C T E D P R O O F\nparallel-processing perspective holds that attention is best characterized\nas comprised of partially active representations of objects simultaneously\ncompeting for probabilistic mappings onto motor output (e.g., Desimone &\nDuncan, 1995; Reynolds & Desimone, 2001).\nIn a conjunction search task, the target object is defined by a conjunction\nof features, and reaction time increases linearly with the number of distrac-\ntors, often in the range of 15–25 ms per item (Duncan & Humphreys, 1989;\nTreisman & Gelade, 1980; Wolfe, 1994). These linearly increasing reaction\ntimes as a function of set size were originally interpreted as evidence for serial\nprocessing of the objects in the display and contrasted with the near flat\nfunction of reaction time by set size observed with feature search displays,\nwhere a single feature is suYcient to identify the target object. It was argued that the early stages of the visual system process individual features indepen-\ndently and in parallel (Livingstone & Hubel, 1988), allowing the target object\nto ‘‘pop out’’ in the display if it is discriminable by a single feature, but\nrequiring application of an attentional window to the individual objects, one\nat a time, if the target object is discriminable only by a conjunction of\nfeatures (Treisman & Gelade, 1980).\nHowever, several studies have discovered particular conjunctions of fea-\ntures that do not produce steeply sloped reaction-time functions by set size\n(McLeod, Driver & Crisp, 1988; Nakayama & Silverman, 1986; Theeuwes &\nKooi, 1994). Moreover, it has been argued that steeply sloped reaction-time\nfunctions may not reflect serial processing of objects in the display, but\nrather noise in the human visual system (Eckstein, 1998; Palmer, Verghese,\n& Pavel, 2000; see also McElree & Carrasco, 1999). Overall, a wide range of\nstudies have suggested that the distinction between putatively ‘‘serial’’ and\n‘‘parallel’’ search functions is continuous rather than discrete and should\nbe considered extremes on a continuum of search diYculty (Duncan & Humphreys, 1989; Nakayama & Joseph, 1998; Olds, Cowan, & Joliceur,\n2000; Wolfe, 1998; see also Spivey, Tyler, Eberhard, & Tanenhaus, 2001).\nDesimone and Duncan (1995; see also Reynolds & Desimone, 2001)\ndescribe a theory of ‘‘biased competition’’ in which multiple representations\nof objects are simultaneously partially active and compete for the privilege of\ndriving motor output (e.g., pressing the ‘‘target present’’ button, reaching to\ngrasp the attended object, or turning to shoot the computer-generated avatar\nof your opponent in a video game). Experimenter instructions, goal-oriented\nplans, and contextual constraints also provide some of the ‘‘bias’’ for this\ncompetition process.\nThe following normalized recurrence simulation serves as a kind of\nabstract implementation of a ‘‘biased competition’’ account of visual\nsearch (see Humphreys & Müller, 1993; Phaf, Van der Heijden, & Hudson,\n1990, for somewhat similar models). In this simulation, one feature vector\nAU:10\n118 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nrepresents the likelihood of each object being the target based solely on it\nexhibiting the target property of redness, and the other feature vector repre-\nsents the likelihood of each object being the target based solely on it\nexhibiting the target property of verticalness. The integration vector serves\nas a measure of each object’s overall likelihood of being the target. Figure 17\nshows a schematic diagram of this normalized recurrence network with input\nvalues corresponding to a target-present conjunction search for a red vertical\nbar with a set size of seven (i.e., one red vertical, three red nonverticals, and\nthree nonred verticals).\nWithin each cycle of competition, the two feature vectors are normalized,\nthen averaged at the integration layer,4 and the integration vector then sends\npointwise multiplicative cumulative feedback to those feature vectors. As\ncycles of competition continue, the integration node corresponding to the\ntarget object (exhibiting both redness and verticalness) increases in activa-\ntion while the other nodes decrease in activation. Competition continues\nuntil an integration node exceeds a .95 activation criterion.\nThis normalized recurrence competition algorithm produces a nearly\nperfectly linear slope of settling time as a function of set size; r2 ¼ .9955 (see Fig. 18). This basic result out of such a simple localist attractor network\nis noteworthy. One of the field’s landmark findings that has traditionally\nbeen taken as evidence for a serial fixed-duration template-matching of each\nobject one at a time, that is linear search functions, is exactly mimicked by a\nparallel competitive architecture where the only ‘‘capacity limitations’’ are\nthat its representations share a probability density function.\nInitially, it is not necessarily obvious why normalized recurrence should\nproduce this linear increase in search time as a function of set size. As set size\nincreases linearly, the initial activation of the target object’s integration node\ndecreases nonlinearly. In addition, as competition takes place within a given\ntrial, that target integration node’s activation value increases nonlinearly\nover time. In fact, this nonlinear increase over time exactly compensates for\nthe nonlinear diVerences in starting activation across set size. For example, as shown in Fig. 19, competition increases the target integration node’s\nactivation with an asymmetric sigmoid function over time. Thus, although\nthe initial activation values vary nonlinearly with set size (i.e., .415, .225,\n.155, .118, .095, for set sizes 4, 8, 12, 16, and 20), their nonlinear rise over\nAU:11\n4 The Bayesian approach to this feedforward integration process would be to multiply these\nprobabilities and then normalize them, but with binary feature vectors that would of course\neliminate any temporal dynamics, as the target integration node would achieve 1.0 activation on\nthe first time step. 5 Moreover, it is clearly not simply operating within a linear portion of an otherwise\nnonlinear function. All the way to a set size of 300, in steps of 10, the slope function produced\nby normalized recurrence is perfectly linear, r2 ¼ 1:0:\nContinuity of Mind 119\nU N C O R R E C T E D P R O O F\nFig. 17. Schematic diagram of a normalized recurrence simulation of visual conjunction\nsearch.\nFig. 18. Settling times for normalized recurrence during a conjunction search with diVerent\nset sizes.\n120 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\ntime causes them to achieve a criterion of activation at approximately linear\nintervals in time (Spivey-Knowlton, 1996). In a sense, two nonlinearities\nmake a linearity.\nA key observation from this little simulation is the fact that the represen-\ntations of the various objects are all processed simultaneously, their activa-\ntions updated in tandem. Despite this parallel processing of all object\nrepresentations, the network produces linearly increasing settling times, as\na function of set size, which were previously interpreted as evidence for serial\nprocessing. Thus, the simulation stands as an existence proof that linear\nfunctions can come out of a system in which multiple partially active\nrepresentations are competing simultaneously, and an object’s ‘‘targethood’’\ngradually emerges over the course of hundreds of milliseconds during visual\nsearch.\nC. Perceptual Decisions\nOur final example of continuous temporal dynamics in visual processing\ncomes from work by Gold and Shadlen (2000) examining decision processes\nin the frontal eye field (FEF) of the macaque. A common task in visual\npsychophysics involves presenting a display of quasi-randomly moving dots.\nAs the experimenter increases the proportion of dots that move in a roughly\nFig. 19. In normalized recurrence, the winning node’s activation rises with a sigmoid\nfunction, but this curve shifts linearly in time as set size increases.\nAU:12\nContinuity of Mind 121\nU N C O R R E C T E D P R O O F\nconsistent direction, the perception of a coherent direction of flow amidst the\ndots becomes more apparent (Britten, Shadlen, Newsome, &Movshon 1992).\nGold and Shadlen presented such displays foveally to monkeys and trained\nthem to indicate the perceived direction of dot flow, upon oVset of the stimulus, by making an eye movement to one peripheral location or an\nopposite one. Then they found a region of FEF in which electrical micro-\nstimulation produced an involuntary saccade that was perpendicular to the\ntwo voluntary response saccades. On some of the direction-of-flow judgment\ntrials, this region of FEF was microstimulated immediately after the moving\ndot display disappeared, that is, exactly when the monkey was supposed to\nproduce a voluntary eyemovement that would indicate his response regarding\nthe perceived direction of flow of the dots.\nPerhaps not surprisingly, the evoked involuntary saccade was executed\nfirst, and a corrective saccade typically redirected the eyes to the voluntarily\nchosen response location. However, the evoked saccade was not bereft of\ninfluence from the burgeoning perceptual decision. In fact, when the per-\ncentage of coherent motion was greater and (more importantly, for our\nargument) when viewing time was longer, more perceptual evidence appar-\nently accrued to induce greater deviation of that initial involuntary saccade\nin the direction of the voluntary response.\nEssentially, by incrementally increasing viewing time, the experimenters\ncould observe the gradual increase in ‘‘strength’’ or ‘‘confidence’’ of the\nperceptual decision over time, as indicated by the degree to which that\nvoluntary decision ‘‘leaked into’’ the execution of the FEF-microstimulated\nevoked saccade. Thus, the population of cells that—once some of them were\nmicrostimulated—produced the evoked saccade were already somewhere in\nthe process of settling on a pattern of activation that would produce the\nvoluntary response saccade. If the microstimulation took place early on in\nthis decision process, rather little eVect of the voluntary response would be apparent in the evoked saccade, but if the miscrostimulation took place later\non in the decision process, a significant amount of the voluntary response\nwould be apparent in the evoked saccade. These results suggest that decision\nprocesses themselves may be coextensive with the gradual settling of partial-\nly active and competing neural representations in motor areas of cortex\n(Gold & Shadlen, 2001; Schall, 2000; see also Georgopoulos, 1995).\nOverall, this brief selection of observations in visual processing is consis-\ntent with a general view of perception, cognition, and action in which\npartially active mental representations compete over time until one (or in\nsome cases an amalgam of more than one) wins the privilege to execute its\nassociated motor output. Whether the visual system is recognizing a face,\nsearching among a cluttered array for a ‘‘target’’ object, or deciding on what\noculomotor signal to send to the eye muscles, the population code\nAU:13\n122 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\ncorresponding to the representation that will get to drive behavior (or even\njust constitute an internal monolog) spends a considerable amount of\ntime approaching that status, and (in natural complex real-time interactive\nenvironments) rather little time enjoying it.\nV. Continuity in Complexity\nWe have so far argued that our cognitive system consists of partially active\nand gradually emerging information, the ‘‘states’’ of which are more or less\ninterpretable regions of the state-space in which a system lives. As described\nin many previous studies, this continuity ‘‘resides’’ in the neural substrate of\nthe brain—vast arrays of networks blending into each other, sometimes\nmoderately functionally specific (Zeki, 1993), and other times highly redun-\ndant across regions (Haxby et al., 2001). We would argue that continuity is\nitself a consequence of this inevitable complexity of the brain. Patterns of\nactivity emerge gradually through local interaction of individual neurons,\nthemselves composing more global connectivity. There is, therefore, organi-\nzation within the system at varying time scales, from local neural influences\nto larger and larger organization, within regions and across them. Several\ntheorists in the past 20 years have suggested that such a state of aVairs admits of particular dynamics, regardless of the specific subject matter. For\nexample, dynamic analyses of earthquakes (Bak & Tang, 1989), radioactive\ndecay (Prestwich, Kenneth, & Pepper, 1986), and even traYc flow (Choi & Lee, 1995) suggest that complex systems of this kind exhibit certain global\npatterns (for an excellent review of this and related phenomena, see Ward,\n2002).\nIf human cognition is indeed a complex dynamic system of the kind we are\narguing, then similar patterns should be observable in this domain. In this\nsection, we oVer a review showing that behavior related to the previous sections, language and vision, also exhibits dynamic properties of complex\nsystems.\nA. Pink Noise\nAmong these properties, pink noise has perhaps invited the most investiga-\ntion and speculation (Ward, 2002). Indeed, it is its apparent violation of a\nbasic intuition about experimental procedures and inferential statistics that\nhas likely engendered such interest (Gilden, 2001). According to this tradi-\ntional intuition, pure experimental error should generate a random noise\nsignal. When such a noisy signal is subjected to a fast-Fourier transform, it\nexhibits equal energy across its component frequencies (Press, Flannery,AU:14\nContinuity of Mind 123\nU N C O R R E C T E D P R O O F\nTeukolsky, & Vetterling, 1992). Pink noise, instead, is error or noise that is\ncorrelated with the frequency components contributing to it. The most\ncommon kind of model to describe correlated noise is that of colored noise:\nPowerðfreqÞ / 1 freq\nPink noise is usually referred to as a pattern of noise whose power\nspectrum has a value of approximately 1 for , also known as 1/f noise (see Fig. 20). Vast ranges of natural phenomena exhibit this kind of\nnoise. Another form of colored noise, brown noise, is often illustrated using\nBrownian motion and is generated by a random walk process (i.e., a small\nrandom process that cumulatively adds or subtracts from a moving scalar\ntime series). Brown noise has a power spectrum 1/f2. Pink noise is the most\nthoroughly investigated in psychological data and generally considered more\ninteresting in other physical systems as well.\nGilden, Thornton, and Mallon (1995) sparked the recent spate of interest\nin pink noise in human brain and behavior. By the time these authors\npublished their well-known results, others had already investigated pink\nnoise in other areas (e.g., Voss and Clarke, 1975, oVer a now famous\nFig. 20. Top row: the power spectrum (left panel) for pink noise (right panel) is correlated\nnegatively with frequency. Bottom row: white noise has a power spectrum that is not correlated\nwith frequency.\n124 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\ndemonstration in musical structure and speech). Gilden et al.’s results dem-\nonstrate that certain human behaviors also exhibit this general property of\ncomplex systems. Their experiments primarily demonstrate that judgments,\nsuch as of time or space, have error in time that reveals a pink power\nspectrum. However, in an experiment involving reaction time to a simple\ndiscriminative stimulus, no such pink noise was found. The authors specu-\nlate that 1/f noise emerges as a consequence of mental judgments. Clayton\nand Frey (1997) soon after demonstrated that pink noise can emerge in\nreaction time measurements in experiments with a memory load. Three\ndiVerent response-time tasks were presented to subjects. In the easiest, subjects responded to a stimulus immediately. In another task of intermedi-\nate diYculty, they responded to the sameness of two subsequent stimuli; in the most diYcult, subjects pressed a key if the stimulus was the same as presented two trials back in the experiment. All conditions produced colored\nnoise in time series analyses of the reaction times, indicating that reaction\ntimes also display pink noise. In fact, the authors demonstrated that the\nharder the task, the more whitened the power spectrum becomes.\nIn an extensive series of experiments, Gilden (1997) demonstrated pink\nnoise in a wide variety of decision tasks. In reaction times for both mental\nrotation and lexical decision, pink noise was observed in the time course of\nfluctuations from the mean. More recently, further evidence has surfaced\nthat the visual system also reveals these patterns. Aks and Sprott (2003)\nrevealed that perspective shifts in Necker cube interpretation exhibit pink\nnoise eVects. In an earlier paper, Aks, Zelinsky, and Sprott (2002) demonstrated that visual search performance shows both pink and brown noise.\nVariation in absolute eye position exhibits 1/f2 noise, resembling the random\nwalk pattern of brown noise. However, variation in saccade amplitude\ngenerates a highly pink signal, indicating that long-term correlations emerge\nout of diVerences in eye position. Several simple mathematical models can be devised to generate a pink\nsignal (for a review, see Ward, 2002). Also, theories about coordinated time\nscales across brain regions have been oVered (e.g., Chen, Ding, & Kelso, 1997; Ding, Chen, & Kelso, 2002; Gilden 2001; Gilden et al., 1995; Ward,\n2002). Most recently, Van Orden, Holden, and Turvey (2003) lament the\nconcoction of these relatively simplistic models, sometimes just to capture\ndata from a few experiments. The authors oVer experiments demonstrating that relatively automatic processes (e.g., word naming) can generate pink\nnoise, despite the suggestion by some that this should not happen in such\nautomatic processes (e.g., Gilden, 2001). Given their results and extensive\ntheoretical discussion, Van Orden et al. suggest that pink noise ‘‘is not the\nproduct of a particular component of the mind or body. It appears to\nillustrate something general about human behavior’’ (p. 345). To Van Orden\nContinuity of Mind 125\nU N C O R R E C T E D P R O O F\net al., pink noise may be a by-product of interaction-dominant dynamics,\ndynamics dependent upon the activity of large numbers of interactive com-\nponents (see also Usher, Stemmler, & Olami, 1995). Indeed, this perspective\nis highly consonant with our own. As discussed, such neural complexity\nbegetting 1/f noise would also be responsible for the temporal continuity of\ncognitive processes.\nB. Stochastic Resonance\nStochastic resonance is a phenomenon of nonlinear systems in which a weak\nperiodic signal is amplified by ‘‘optimal’’ noise. As mentioned in the previous\nsection, noise is generally considered troublesome from a traditional per-\nspective, yet the discovery of stochastic resonance in the 1980’s has resulted\nin entire conferences and textbooks on the topic, from statistical theory\nto applications (e.g., Ando & Graziani, 2000). The simplest way of pictur-\ning stochastic resonance, as it is traditionally introduced (Gammaitoni,\nHaenggi, Jung, & Marchesoni, 1998), is a bistable symmetric nonlinear\nsystem: a double-well potential. With the addition of noise, if past a certain\nthreshold of average amplitude, the system will ‘‘hop’’ between the two\nstates. Consider then subjecting this double-well potential to a weak sinusoi-\ndal, periodic signal that can bias or shift the probability distribution in\nthe system wherein one potential becomes a favored absolute minimum\nfor the system by having the hopping synchronize with the weak signal.\nThe hopping will result in a stable state while this resonating of noise\nFig. 21. When a weak sinusoid is added to an equibiased stochastic process, resonance can\nproduce a significantly biased stochastic process.\n126 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nand sinusoid occurs (see Fig. 21). Stochastic resonance was initially\nproposed as the explanation for the ice ages due to synchronization between\nthe ‘‘weak signal’’ of climate change due to orbital situation of the earth,\nand a ‘‘Gaussian’’ noise signal from smaller-scale temperature fluctuations\n(Benzi, Sutera, & Vulpiani 1981; Nicolis, 1982). It was then experimentally\ndemonstrated in simple devices, such as electronic logic gates and lasers.\nWard (2002) paints an interesting portrait of the relevance of stochastic\nresonance by describing the life of a crayfish. Its ‘‘watery world of a rippling\nbrook’’ (p. 183) is terribly dangerous. The crayfish is preyed upon by other\ncreatures, such as larger fish, that can quickly spring upon this species, if it\nwere not for stochastic resonance in uniquely tuned hair cells on the crayfish.\nThese cells can detect the specific frequency of the crayfish’s predators,\nhelping the animal escape. It functions highly eYciently in its ‘‘watery world’’ due to the ambient noise in the watery environment and having\nthat noise amplify the weak signal generated by an oncoming predator.\nDouglass, Wilkens, Pantazelou, and Moss (1993) demonstrated this experi-\nmentally in the crayfish by generating the relevant noise and weak predatory\nsignal in an experimental chamber.\nThis is one of the simplest demonstrations of the potential biological\nbenefit of cells that can take advantage of this statistical eVect. It has also been demonstrated, for example, in the visual system of the cat. Noisy jitter\ninduced by micro-ocular tremor may actually enhance visual acuity to a\nstimulus. By generating noise in a visual stimulus by producing motion jitter\nof diVerent amplitudes, Hennig, Kerscher, Funke, and Woergoetter (2002) demonstrated that certain cells in cortical areas 17 and 18 of the cat increase\nresponding to a moving oriented bar at intermediate levels of noise. Other\nanimals may make use of stochastic resonance as well, including crickets,\ntoads, and rats (see Ward, 2002, for a review).\nIn humans, Simonotto and colleagues (Simonotto, Riani, Seife, Roberts,\nTwitty, & Moss, 1997; Simonotto et al., 1999) have demonstrated the role of\nstochastic resonance in both human psychophysical and neuro-physiological\nrecordings. Simonotto et al. (1997) exposed subjects to contrast gratings of\nvariable spatial frequency under diVerent noise conditions and asked them to report where their sensitivity to spatial frequency ceased. An inter-\nmediate amount of noise reduced perceptive threshold considerably lower\nthan when the stimulus was noise-free. Simonotto et al. (1999) extended\nthese results to the human brain through imaging. Results of fMRI demon-\nstrated that visual regions of the brain contained more activity by volume\nunder optimal noise conditions. These kinds of experiments have been\nextended to audition (Ward, Moss, Desai, & Rootman, 2001; Zeng, Fu, &\nMorse, 2000) and tactile stimulation (Richardson, ImhoV, Grigg, & Collins, 1998).\nContinuity of Mind 127\nU N C O R R E C T E D P R O O F\nAs with pink noise, very simple systems can also be devised to model\nstochastic resonance. For example, as mentioned, a simple double-well\npotential can exhibit it. Also, it can be modeled with a relatively simple\nthreshold mechanism (Ward, 2002). However, much as we discussed in\nthe context of pink noise, these simplistic models may belie the interactive\ncomplexity through which stochastic resonance emerges in the human brain.\nThough these simple models may serve as useful mathematical predictors,\nthe means by which the human brain shows stochastic resonance may be\nconsiderably more complex. In a sophisticated neural model, Stemmler,\nUsher, and Neibur (1995) simulated lateral neural interaction in V1 that\ncan benefit from internal noise. A large 20,000-node artificial neural net-\nwork, consisting of half excitatory neurons and half inhibitory neurons,\nserved to model receptive fields (with these receptive fields having varied\nsensitivities organized in a spatially distributed manner across the large\nnetwork). Connections among these neurons served to model spatial excit-\natory and inhibitory input: Inhibitory inputs were sparsely distributed,\ncoming from throughout the visual cortex, and excitatory input more closely\npacked. The model actually enhances a weak signal to a receptive field\nby having noise-induced input from inhibitory surround neurons. The model\nillustrates that patterns of stochastic resonance (among other patterns\nthe model can fit, such as visual search pop-out), can emerge from the\ninteraction of large numbers of small units.\nC. Recurrence in Time\nRecurrence quantification analysis (RQA) is a novel method of investigating\nthe time course of complex systems (Webber & Zbilut, 1994; Zbilut &\nWebber, 1992). RQA permits its users to establish both global and local\nmeasures of regularity or even randomness in a system. RQA exemplifies the\nbenefit of these dynamical analyses, showing how human brain and behavior\nare highly amenable to analysis of the global properties of very complex\nsystems.\nRQA is the quantification of a recurrence plot (RP), introduced by\nEckmann, Kamphorst, and Ruelle (1987), and related to the correlation\nintegral of dynamic systems mathematics (Takens, 1985). An RP is produced\nby measuring at regular intervals some scalar quantity generated by a\nsystem. For example, one might measure the temperature in a certain region\nor error generated by a neural network. Any scalar quantity in any kind of\nsystem will do, provided the measurements are at regular intervals. This time\nseries is then embedded in multiple dimensions by overlaying the time series\nwith temporally staggered versions of itself. Figure 22 illustrates this process.\nRoughly, the columns of this embedded time series have a time index\n128 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nthemselves and can be compared to column vectors of other time indices.\nWhen two such columns are compared, we can compute the distance bet-\nween them. For any two vectors, at index i and j, say, we draw a point on\nthe RP (i, j) if their distance satisfies a certain threshold. In this way, periodi-\ncities in the system result in undulating streaks of points in the RP (see\nFig. 23). RQA directly quantifies the pattern of points on the RP (for a clear\nand concise introduction, see Riley, Balasubramaniam, & Turvey, 1999).\nA particularly fruitful area in which RQA has been applied is the study of\npostural control. The studies of Riley, Balasubramaniam, and Turvey (1999)\nand Balasubramaniam, Riley, and Turvey (2000) primarily used RQA to\nstudy the variables controlling minor adjustments in our center of pressure\n(COP) during standstill (see also Riley & Clark, 2003). Riley et al. had\nsubjects look at depth gratings while standing on a device that could monitor\nminor changes in their postural control (along the two axes of control,\nantero-posterior, [AP] and medio-lateral [ML]). Subjects performed trials\nin diVerent conditions, including eyes—open versus closed, and looking straight-on versus looking to the right. The time series generated by record-\ning postural control, generally regarded as nonstationary and fluctuating,\nFig. 22. An example of embedding a time series using, for example, three dimensions and a\nlag of 1. (See text for details.)\nContinuity of Mind 129\nU N C O R R E C T E D P R O O F\npermitted the authors to make the tentative observation that COP dynamics\nare more ‘‘complex’’ when the eyes are closed. Also, postural sway was not\nentirely random in that the RQA measure of determinism was fairly high for\nthe various COP time series. However, nonstationarity obviously present in\nthe RP analysis indicated that postural control may be a coupled dynamic\nbetween stochastic processes and more deterministic controlled processes\n(e.g., closing the eyes resulted in more deterministic, controlled patterns in\nthe RP).\nIn an interesting pair of experiments, Balasubramaniam et al. (2000) used\nRQA to explore the conditions of fluctuation of COP in a precision task:\nmaintaining a laser pointer on a target at a certain distance. Once again,\nmeasurements along the same two axes were compared. They used RQA to\nmeasure, for example, determinism, recurrence, entropy, and trend in the\ntime series of these axes (these are values RQA generates from the RP; see\nBalasubramaniam et al., 2000). The authors demonstrated that the axis\nrelevant to the task, such as the ML axis for holding the laser straight on\n(for accuracy), and the AP axis for across your body to the side toward the\ntarget, exhibited higher values of these measures, especially as task diYculty increased. The overall analyses indicate that there is a level of independence\nbetween these two sources of postural sway.\nFig. 23. In this very simple example of a recurrence plot, a series of sine values with some\nnoise added was subjected to embedding. The diagonal is the line of identity, where i ¼ j, and one can observe further diagonal structure emerging at other time indices, indicating some\nperiodicity in the noisy sinusoidal time series.\n130 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nIn a similar application, Shockley, Santana, andFowler (2003) usedRP and\nRQA to analyze postural shifts during conversational interaction. Partici-\npants engaged in discussion about cartoon images in diVerent conditions, depending on whether they were conversing with each other or confederates\noutside the experimental area andwhether theywere facing each other or away\nfrom each other during interaction. The authors measured postural shifts by\nmeasuring changes in the location of the head and waist during conversation.\nParticipants talking to each other, rather than a silent confederate, always\nexhibited more recurrence (a simple RQAmeasure) in a cross-recurrence plot\nof their postural sway (i.e., an RP generated by comparing two separate,\nembedded time series). Current related work is showing that cross-recurrence\nin eyemovements of a speaker and a listener predicts accuracy on comprehen-\nsion questions (Richardson & Dale, 2004) and that recurrence of linguistic\nforms in novel contexts characterizes the acquisition of various syntactic\ncategories in children’s language learning (Dale & Spivey, submitted).\nImportantly, as related to our above discussion, the crucial aspect of RP\nand RQA is that they visualize processes that change in time, whether\nstationary or nonstationary, highly periodic or random. The fact that human\nbehavior—such as visual–postural interaction, postural control during con-\nversation, and eye movements during instruction and comprehension—is\namenable to this analysis at least indirectly supports the perspective of\ncontinuity (see also Marwan & Meinke, 2004, for an application of RQA\nto event-related potentials). In summary, all the previous phenomena, espe-\ncially when taken together, suggest that cognition is based in a complex\nsystem composed of interaction-dominant subcomponents blending at mul-\ntiple time scales, thus generating continuity in behavioral outcomes. Indeed,\nall these properties of complexity substantiate our highlighted time scale (of\nhundreds of milliseconds), since both noise and recurrence seem implicated\nin real-time visual and linguistic processes.\nVI. Conclusion\nIn this chapter, we have strolled briskly through a number of diVerent examples of using continuous (or semicontinuous) measures of perceptual-\ncognitive processing to reveal various mental phenomena as composed of\nmultiple partially active representations that compete over time. However, it\ncan sometimes seem that whenever a mental process is shown to exhibit such\ncontinuous temporal dynamics (or to rely on distributed representations),\nthen the process in question is relegated to ‘‘part of perception, not\ncognition,’’ where analog processing is not surprising. In Sections I–V, we\ntouched on evidence for, and simulations of, the temporal continuity of\nAU:15\nContinuity of Mind 131\nU N C O R R E C T E D P R O O F\nrepresentational dynamics in categorization, speech perception, spoken\nword recognition, sentence processing, object and face recognition, visual\nattention, and perceptual decisions, as well as correlational cross-talk be-\ntween rather diVerent time scales of task performance. If all of these mental phenomena were to be expunged from the domain of cognition on the\ngrounds that they do not rely on discrete temporally static symbolic repre-\nsentations, then scant little would remain in that vaunted realm—perhaps\nonly problem solving and reasoning. (And, just to warn you, the movement\nhas its eyes on those processes as well; cf. Townsend & Busemeyer, 1995).\nRather than imputing to cognitive processes the unrealistic property of\nfunctioning in a discretely symbolic way that real biological neural hardware\nis incapable of implementing, perhaps we can instead welcome a smooth\nmerging of perception, cognition, and action as encouraged by Dewey\n(1986). Environmental stimulation continuously flows into perceptual areas\nof the brain, but since those areas receive some degree of feedback from\nmore cognitive areas of the brain, they’re really processing a combination of\naVerent sensory patterns of activation and reentrant cognitive patterns of activation. These blended patterns of activation cascade to ‘‘higher’’ areas\nof the brain where the relative concentrations of cognitive-like versus per-\nceptual-like components in the patterns may shift toward the cognitive end.\nAnd soon, as these patterns of activation continuously travel toward motor\nareas of the brain, in preparation for influencing behavior, the distributed\npatterns begin to exhibit a significant degree of actionlike components as\nwell. For example, action representations themselves may be predominantly\ndefined in terms of their anticipated perceptual outcomes (cf. Prinz &\nHommel, 2002, for an excellent collection of reviews). And don’t forget\nDewey and Gibson’s reminder that relatively continuous motor output\ndramatically alters the patterns of continuous sensory stimulation, thus\nlooping the entire system back onto itself. There simply does not appear to\nbe, nor should there actually need to be, an internal stage in which the\ngraded, distributed patterns of activation are converted into single unitary\nsymbols with logical truth values. After all, they would only have to be\nreconverted right back into the graded, distributed patterns of activation\nthat we know occur in the motor cortices (e.g., Georgopoulos, 1995).\nAlthough it is comforting to think of cognition in terms of multiple\ndiVerent easily labeled interpretations of individuated stimuli having nonoverlapping symbolic descriptions (e.g., Dietrich & Markman, 2003; Fodor\n& Pylyshyn, 1988), the fact of the matter is that the brain spends most of\nits time in regions of state-space that do not allow discrete symbolic descrip-\ntions. Thus, rather than being the digital computational intermediary be-\ntween analog perception and action, whose job is to collapse the\nprobabilistic distributions into discrete symbols, cognition is perhaps just\n132 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nas analog and graded as the sensory and motor systems themselves. And the\nmuch awaited collapsing of those distributed multifarious representational\npatterns does not actually take place until motor movement is executed (and\neven then it sometimes comes out as an amalgam of two motor programs,\ne.g, Gold & Shadlen, 2001).\nFinally, we should acknowledge that, in our eVort to speak to the traditional cognitive psychologist, it is possible that we have focused too\nmuch on the dynamics of internal cognitive processing and not enough on\nthe dynamics of larger systems such as that of a human coupled with its\nenvironment (e.g., A. Clark, 2003; Gibson, 1979; O’Regan & Nöe, 2001;\nSpivey,Richardson,&Fitneva, 2004; Turvey;&Carello, 1981) ormultiple hu-\nmans interacting with one another (e.g., Knoblich & Jordan, 2003; Schmidt,\nCarello, &Turvey, 1990; Sebanz, Knoblich& Prinz, 2003; Shockley, Santana,\n& Fowler, 2003). However, in describing and supporting the continuity of\nmind for an audience of cognitive psychologists, showing how internal\nperceptual-cognitive processing exhibits continuous change in the salience\nof multiple simultaneously active representations is perhaps the crucial first\nstep in steering the field away from its digital computer metaphor for\ncognition. By first replacing the concept of discrete representations in\nthe mind with multifarious patterns of neural activation that change\ncontinuously over time, we can set the stage for exploring a reconsideration\nof exactly how ‘‘representation-like’’ these continuous trajectories in state-\nspace really are (regardless of whether we’re talking about a neural\nstate-space or an organism-environment state-space). In this way, we hope\nthat the cognitive sciences can eventually find a responsible and coherent\nintegration of the useful, lasting insights that came from cognitive psycholo-\ngy and from connectionism, and those that are coming from neuroscience,\necological psychology, and dynamic systems theory.\nAcknowledgments\nWe are grateful to Brian Ross for extremely helpful comments on a previous version of this\nmanuscript, and to Paul Allopenna, Catharine Carlin, Eric Dietrich, Shimon Edelman, Günther\nKnoblich, Ken Kurtz, Art Markman, Bob McMurray, Ulric Neisser, Daniel Richardson, Mike\nTanenhaus, Michael Turvey, Melinda Tyler, and Guy Van Orden for helpful discussions of\nthese topics. The first author’s work on this chapter was supported by NIMH grant R01-63961.\nReferences\nAks, D. J., & Sprott, J. C. (2003). The role of depth and 1/f dynamics in perceiving reversible\nfigures. Nonlinear Dynamics, Psychology, and Life Sciences, 7, 161–180.\nAks, D. J., Zelinsky, G. J., & Sprott, J. C. (2002). Memory across eye-movements: 1/f dynamic\nin visual search. Nonlinear Dynamics, Psychology, and Life Sciences, 6, 1–25.\nContinuity of Mind 133\nU N C O R R E C T E D P R O O F\nAleksander, I. (1973). Random logic nets: Stability and adaptation. International Journal of Man\nMachine Studies, 5, 115–131.\nAllopenna, P. D., Magnuson, J. S., & Tanenhaus, M. K. (1998). Tracking the time course of\nspoken word recognition using eye movements: Evidence for continuous mapping models.\nJournal of Memory and Language, 38, 419–439.\nAltmann, G., Garnham, A., & Dennis, Y. (1992). Avoiding the garden-path: Eye movements in\ncontext. Journal of Memory and Language, 31, 685–712.\nAltmann, G., & Steedman, M. (1988). Interaction with context during human sentence proces-\nsing. Cognition, 30, 191–238.\nAnderson, J. A., Silverstein, J. W., Ritz, S. A., & Jones, R. S. (1977). Distinctive features,\ncategorical perception, and probability learning: Some applications of a neural model.\nPsychological Review, 84, 413–451.\nAnderson, J. R., & Lebiere, C. (1998). The atomic components of thought. Erlbaum: Mahwah,\nNJ.\nAndo, B., & Graziani, S. (2000). Stochastic resonance: Theory and applications. Kluwer.\nBak, P., & Tang, C. (1989). Earthquakes as a self-organized critical. Geophysics Research—\nSolar. Earth Planet, 94, 15635–15637.\nBalasubramaniam, R., Riley, M. A., & Turvey, M. T. (2000). Specificity of postural sway to the\ndemands of a precision task. Gait and Posture, 11, 12–24.\nBarber, M., Clark, J., & Anderson, C. (2003). Neural representation of probabilistic informa-\ntion. Neural Computation, 15, 1843–1846.\nBarlow, H. (1972). Single units and sensation: A neuron doctrine for perceptual psychology.\nPerception, 1, 371–394.\nBarsalou, L. W. (1999). Perceptual symbol systems. Behavioral and Brain Sciences, 22, 577–660.\nBenzi, R., Sutera, A., & Vulpiani, A. (1981). The mechanism of stochastic resonance. Journal of\nPhysics A: Mathematical and General, 14, 453.\nBever, T. (1970). The cognitive basis for linguistic structures. In J. Hayes (Ed.), Cognition and\nthe Development of Language. New York: Wiley.\nBever, T. G., & Hurtig, R. R. (1975). Detection of a nonlinguistic stimulus is poorest at the end\nof a clause. Journal of Psycholinguistic Research, 4, 1–7.\nBollt, E., Stanford, T., Lai, Y., & Zyczkowski, K. (2000). Validity of threshold crossing analysis\nof symbolic dynamics from chaotic time series. Physical Review Letters, 85, 3524–3527.\nBritten, K., Shadlen, M., Newsome, W., & Movshon, J. (1992). The analysis of visual motion:\nA comparison of neuronal and psychophysical performance. Journal of Neuroscience, 12,\n4745–4767.\nBrownell, H. H., & Caramazza, A. (1978). Categorizing with overlapping categories. Memory\nand Cognition, 6, 481–490.\nBudiu, R., & Anderson, J. R. (2004). Interpretation-based processing: A unified theory of\nsemantic sentence comprehension. Cognitive Science, 28, 1–44.\nChen, Y., Ding, M., & Kelso, J. A. S. (1997). Long memory processes (1/f type) in human\ncoordination. Physical Review Letters, 79, 4501–4504.\nChoi, M. Y., & Lee, H. Y. (1995). TraYc flow and 1/f fluctuations. Physical Review E, 52,\n5979–5984.\nClark, A. (2003). Natural-born cyborgs. Oxford University Press.\nClark, H. (1992). Arenas of language use. Chicago: University of Chicago Press.\nClayton, K., & Frey, B. B. (1997). Studies of mental ‘‘noise.’’ Nonlinear Dynamics, Psychology,\nand Life Sciences, 1, 173–181.\nCooper, L. A., & Shepard, R. N. (1973). The time required to prepare for a rotated stimulus.\nMemory and Cognition, 1, 246–250.\nAU:16\nAU:17\n134 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nCrain, S., & Steedman, M. (1985). On not being led up the garden path. In Dowty, Kartunnen,\nand Zwicky (Eds.), Natural language parsing. Cambridge, MA: Cambridge University\nPress.\nCree, G. S., McRae, K., & McNorgan, C. (1999). An attractor model of lexical conceptual\nprocessing: Simulating semantic priming. Cognitive Science, 23, 371–414.\nCutler, A. (1995) Spoken word recognition and production. In J. L. Miller and P. D. Eimas\n(Eds.), Speech, language, and communication. Handbook of perception and cognition. (2nd\ned., Vol. 11, pp. 97–136). San Diego, CA: Academic Press.\nDailey, M. N., Cottrell, G. W., Padgett, C., & Adolphs, R. (2002). EMPATH: A neural network\nthat categorizes facial expressions. Journal of Cognitive Neuroscience, 14, 1158–1173.\nDale, R., & Spivey, M.J. (submitted). Data visualization of complex behavioral structure across\ntime. Manuscript submitted for publication.\nDesimone, R., & Duncan, J. (1995). Neural mechanisms of selective visual attention. Annual\nReview of Neuroscience, 18, 193–222.\nDewey, J. (1986). The reflex arc concept in psychology. Psychological Review, 3, 357–370.\nDietrich, E., & Markman, A. B. (2003). Discrete thoughts: Why cognition must use discrete\nrepresentations. Mind and Language, 18, 95–119.\nDing, M., Chen, Y., & Kelso, J. A. S. (2002). Statistical analysis of timing errors. Brain and\nCognition, 48, 98–106.\nDouglass, J. K., Wilkens, L., Pantazelou, E., & Moss, F. (1993). Noise enhancement of the\ninformation transfer in crayfish mechanoreceptors by stochastic resonance. Nature, 365,\n337–340.\nDuncan, J., & Humphreys, G. (1989). Visual search and stimulus similarity. Psychological\nReview, 96, 433–458.\nEckmann, J.-P., Kamphorst, S. O., & Ruelle, D. (1987). Recurrence lots of dynamical systems.\nEurophysics Letters, 5, 973–977.\nEckstein, M. P. (1998). The lower visual search eYciency for conjunctions is due to noise and\nnot serial attentional processing. Psychological Science, 9, 111–118.\nEdelman, S. (1999). Representation and recognition in vision. Cambridge, MA: MIT Press.\nElman, J. L. (1991). Distributed representations, simple recurrent networks, and grammatical\nstructure. Machine Learning, 7, 195–224.\nElman, J. L., Bates, E. A., Johnson, M. H., KarmiloV-Smith, A., Parisi, D., & Plunkett, K.\n(1996). Rethinking innateness: A connectionist perspective on development. Cambridge, MA:\nMIT Press.\nFarah, M. J. (1985). Psychophysical evidence for a shared representational medium for mental\nimages and percepts. Journal of Experimental Psychology, 114, 91–103.\nFarrar, W. T., & Kawamoto, A. H. (1993). The return of ‘‘visiting relatives’’: Pragmatic eVects\nin sentence processingQuarterly Journal of Experimental Psychology: Human Experimental\nPsychology, 46A, 463–487.\nFernald, A., Swingley, D., & Pinto, J. P. (2001). When half a word is enough: Infants can\nrecognize spoken words using partial phonetic information. Child Development, 72,\n1003–1015.\nFerreira, F., & Clifton, . (1986). The independence of syntactic processing. Journal of Memory\nand Language, 25, 348–368.\nFodor, J. A., & Pylyshyn, Z. W. (1988). Connectionism and cognitive architecture: A critical\nanalysis. Cognition, 28, 3–71.\nFrazier, L., & Clifton, C. (1989). Successive cyclicity in the grammar and the parser. Language\nand Cognitive Processes, 4, 93–126.\nFrazier, L. (1998). Getting there (slowly). Journal of Psycholinguistic Research, 27, 123–146.\nAU:18\nAU:19\nAU:20\nAU:21\nContinuity of Mind 135\nU N C O R R E C T E D P R O O F\nFrazier, L., & Fodor, J. D. (1978). The sausage machine: A new two-stage parsing model.\nCognition, 6, 291–325.\nFrazier, L., & Rayner, K. (1982). Making and correcting errors during sentence comprehension:\nEye movements in the analysis of structurally ambiguous sentences. Cognitive Psychology,\n14, 178–210.\nGammaitoni, L., Haenggi, P., Jung, P., & Marchesoni, F. (1998). Stochastic resonance. Reviews\nof Modern Physics, 70, 223–287.\nGeorgopoulos, A. (1995). Motor cortex and cognitive processing. In M. Gazzaniga (Ed.), The\ncognitive neurosciences. Cambridge, MAM: MIT Press.\nGeorgopoulos, A. P., Kalaska, J. F., Caminiti, R., & Massey, J. T. (1982). On the relations\nbetween the direction of two dimensional arm movements and cell discharge in primate\nmotor cortex. Journal of Neuroscience, 2, 1527–1537.\nGeorgopoulos, A. P., Lurito, J. T., Petrides, M., Schwartz, A. B., &Massey, J. T. (1989). Mental\nrotation of the neuronal population vector. Science, 243, 234–236.\nGibson, J. J. (1979). The ecological approach to visual perception. Boston: Houghton MiZin.\nGilden, D. L. (1997). Fluctuations in the time required for elementary decisions. Psychological\nScience, 8, 296–301.\nGilden, D. L. (2001). Cognitive emissions of 1/f noise. Psychological Review, 108, 33–56.\nGilden, D. L., Thornton, T., & Mallon, M. W. (1995). 1/f noise in human cognition. Science,\n267, 1837–1839.\nGlass, A. L., & Meany, P. J. (1978). Evidence for two kinds of low-typical instances in a\ncategorization task. Memory and Cognition, 6, 622–628.\nGold, J. I., & Shadlen, M. N. (2000). Representation of a perceptual decision in developing\noculomotor commands. Nature, 404, 390–394.\nGrainger, J. and Jacobs, A (Eds.), Localist connectionist approaches to human cognition.\nMahwah, NJ: Erlbaum.\nGregson, R. A. M. (Ed.), Time series in psychology. Hillsdale, NJ: Erlbaum.\nHaken, H. (Ed.), Synergetics: An introduction. Berlin: Springer-Verlag.\nHarnad, S. (Ed.), Categorical perception: The groundwork of cognition. New York: Cambridge\nUniversity Press.\nHaxby, J. V., Gobbini, M. I., Furey, M. L., Ishai, A., Schouten, J. L., & Pietrini, P. (2001).\nDistributed and overlapping representations of faces and objects in ventral temporal\ncortex. Science, 293, 2425–2430.\nHennig, M. H., Kerscher, N. J., Funke, K., & Woergoetter, F. (2002). Stochastic resonance in\nvisual cortical neurons: Does the eye-tremor actually improve visual acuity?Neurocomput-\ning, 44–46, 115–120.\nHinton, G. (1981). Implementing semantic networks in parallel hardware. In G. Hinton and\nJ. Anderson (Eds.), Parallel models of associative memory. Hillsdale, NJ: Erlbaum.\nHummel, J. E. (2001). Complementary solutions to the binding problem in vision: Implications\nfor shape perception and object recognition. Visual Cognition, 8, 489–517.\nHumphreys, G., & Müller, H. (1993). SEarch via Recursive Rejection (SERR): A connectionist\nmodel of visual search. Cognitive Psychology, 25, 43–110.\nJohnson-Laird, P. N. (1998). Imagery, visualization, and thinking. In J. Hochberg (Ed.),\nPerception and cognition at century’s end. Handbook of perception and cognition. (2nd ed.,\npp. 441–467). San Diego, CA: Academic Press.\nJolicoeur, P. (1985). The time to name disoriented natural objects. Memory and Cognition, 13,\n289–303.\nJurafsky, D. (1996). A probabilistic model of lexical and syntactic access and disambiguation.\nCognitive Science, 20, 137–194.\nAU:22\nAU:23\n136 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nKelso, J. A. S. (1995). Dynamic patterns: The self organization of brain and behavior. Cambridge,\nMA: MIT Press.\nKnoblich, G., & Jordan, J. S. (2003). Action coordination in groups and individuals: Learning\nanticipatory control. Journal of Experimental Psychology: Learning, Memory, and Cogni-\ntion, 29, 1006–1016.\nKnoeferle, P., Crocker, M., Scheepers, C., & Pickering, M. (2003). Actions and Roles: Using\ndepicted events for disambiguation and reinterpretation in German and English. Proceed-\nings of the 25th Annual Meeting of the Cognitive Science Society.\nKosslyn, S. M., Thompson, W. L., Kim, I. J., & Alpert, N. M. (1995). Topographical repre-\nsentations of mental images in primary visual cortex. Nature, 378, 496–498.\nLamberts, K. (1995). Categorization under time pressure. Journal of Experimental Psychology:\nGeneral, 124, 161–180.\nLamberts, K. (1998). The time course of categorization. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 24, 695–711.\nLamberts, K. (2000). Information-accumulation theory of speeded categorization. Psychological\nReview, 107, 227–260.\nLangacker, R. W. (1990). Foundations of cognitive grammar. Descriptive Applications prere-\nquisites, 2, Stanford, CA: Stanford University Press.\nLeahey, T. H. (1994). A history of modern psychology (2nd ed.). Upper Saddle River, NJ:\nPrentice Hall.\nLettvin, J. Y. (1995). J. Y. Lettvin on grandmother cells. In M. Gazzaniga (Ed.), The cognitive\nneurosciences (pp. 434–435). Cambridge, MA: MIT Press.\nLiberman, A. M., Harris, K. S., HoVman, H. S., & GriYth, B. C. (1957). The discrimination of\nspeech sounds within and across phoneme boundaries. Journal of Experimental Psychology,\n54, 358–368.\nLin, E., & Murphy, G. L. (1997). EVects of background knowledge on object categorization and\npart detection. Journal of Experimental Psychology: Human Perception and Performance,\n23, 1153–1169.\nLivingstone, M., & Hubel, D. (1988). Segregation of form, color, movement, and depth:\nAnatomy, physiology, and perception. Science, 240, 740–749.\nLund, K., & Burgess, C. (1996). Producing high dimensional semantic spaces from lexical co\noccurrence. Behavior Research Methods, Instruments and Computers, 28, 203–208.\nMacDonald, M., Pearlmutter, N., & Seidenberg, M. (1994). The lexical nature of syntactic\nambiguity resolution. Psychological Review, 101, 676–703.\nMagnuson, J. S., Tanenhaus, M. K., Aslin, R. N., & Dahan, D. (2003). The time course of\nspoken word learning and recognition: Studies with artificial lexicons. Journal of Experi-\nmental Psychology: General, 132, 202–227.\nMarcus, G. F. (2001). The algebraic mind: Integrating connectionism and cognitive science.\nCambridge, MA: MIT Press.\nMarian, V., & Spivey, M. (2003). Bilingual and monolingual processing of competing lexical\nitems. Applied Psycholinguistics, 24, 173–193.\nMarslen-Wilson, W. (1973). Linguistic structure and speech shadowing at very short latencies.\nNature, 244, 522–523.\nMarslen-Wilson, W. (1987). Functional parallelism in spoken word recognition. Cognition, 25,\n71–102.\nMarwan, N., &Meinke, A. (2004). Extended recurrence plot analysis and its application to ERP\ndata. International Journal of Bifurcation and Chaos 14.\nMcClelland, J., & Elman, J. (1986). The TRACE model of speech perception. Cognitive\nPsychology, 18, 1–86.\nAU:24\nAU:25\nAU:26\nContinuity of Mind 137\nU N C O R R E C T E D P R O O F\nMcClelland, J., & Rumelhart, D. (1981). An interactive activation model of context eVects in\nletter perception: Part 1. An account of basic findings. Psychological Review, 88, 375–407.\nMcCulloch, W. (1965). Embodiments of mind. Cambirdge, MA: MIT Press.\nMcElree, B., & Carrasco, M. (1999). The temporal dynamics of visual search: Evidence for\nparallel processing in feature and conjunction searches. Journal of Experimental Psycholo-\ngy: Human Perception and Performance, 25, 1517–1539.\nMcLeod, P., Driver, J., & Crisp, J. (1988). Visual search for conjunctions of movement in visual\nsearch. Nature, 332, 154–155.\nMcMurray, R., & Spivey, M. (1999). The categorical perception of consonants: The interaction\nof learning and processing. In Proceedings of the Chicago Linguistic Society.\nMcMurray, B., Tanenhaus, M. K., & Aslin, R. N. (2002). Gradient eVects of within-category\nphonetic variation on lexical access. Cognition, 86, B33–B42.\nMcMurray, B., Tanenhaus, M. K., Aslin, R. N., & Spivey, M. J. (2003). Probabilistic constraint\nsatisfaction at the lexical/phonetic interface: Evidence for gradient eVects of within category\nVOT on lexical access. Journal of Psycholinguistic Research, 32, 77–97.\nMcRae, K., Spivey-Knowlton, M., & Tanenhaus, M. (1998). Modeling the eVects of thematic fit\n(and other constraints) in on-line sentence comprehension. Journal of Memory and Lan-\nguage, 37, 283–312.\nMedin, D. L., & Smith, E. E. (1981). Strategies and classification learning. Journal of Experi-\nmental Psychology: Human Learning and Memory, 7, 241–253.\nNakayama, K., & Joseph, J. (1998). Attention, pattern recognition, and pop-out in visual\nsearch. In R. Parasuraman (Ed.), The attentive brain (pp. 279–298). Cambridge, MA:\nMIT Press.\nNakayama, K., & Silverman, G. (1986). Serial and parallel processing of visual feature con-\njunctions. Nature, 320, 264–265.\nNederhouser, M., & Spivey, M. (2004). Eye-tracking and simulating the temporal dynamics of\ncategorization. Proceedings of the 26th Annual Meeting of the Cognitive Science Society.\nNicolis, C. (1982). Stochastic aspects of climatic transitions—response to a periodic forcing.\nTellus, 34, 1.\nNosofsky, R. M., & Alfonso-Reese, L. A. (1999). EVects of similarity and practice on speeded\nclassification response times and accuracies: Further tests of an exemplar-retrieval model.\nMemory and Cognition, 27, 78–93.\nO’Regan, J. K., & Noe, A. (2001). A sensorimotor account of vision and visual consciousness.\nBehavioral and Brain Sciences, 24, 939–1031.\nOlds, E. S., Cowan, W., & Jolicoeur, P. (2000). The time-course of pop-out search. Vision\nResearch, 40, 891–912.\nPalmer, J., Verghese, P., & Pavel, M. (2000). The psychophysics of visual search. Vision\nResearch, 40, 1227–1268.\nPasupathy, A., & Connor, C. E. (2002). Population coding of shape in area V4. Nature\nNeuroscience, 5, 1332–1338.\nPearlmutter, N. J., & MacDonald, M. C. (1995). Individual diVerences and probabilistic con-\nstraints in syntactic ambiguity resolution. Journal of Memory and Language, 34, 521–542.\nPerrett, D. I., Oram, M. W., & Ashbridge, E. (1998). Evidence accumulation in cell populations\nresponsive to faces: An account of generalisation of recognition without mental transfor-\nmations. Cognition, 67, 111–145.\nPhaf, R. H., Van der Heijden, A. H., & Hudson, P. T. (1990). SLAM: A connectionist model for\nattention in visual selection tasks. Cognitive Psychology, 22, 273–341.\nPinker, S., & llman, M. T. (2002). The past and future of the past tense. Trends in Cognitive\nSciences, 6, 456–463.\nAU:27\nAU:28\nAU:29\n138 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nPisoni, D. B., & Tash, J. (1974). Reaction times to comparisons within and across phonetic\ncategories. Perception and Psychophysics, 15, 285–290.\nPort, R. F. and van Gelder, T. (Eds.),Mind as motion: Explorations in the dynamics of cognition.\nCambridge, MA: MIT Press.\nPotter, M. C. (1976). Short-term conceptual memory for pictures. Journal of Experimental\nPsychology: Human Learning and Memory, 2, 509–522.\nPotter, M. C. (1993). Very short-term conceptual memory.Memory and Cognition, 21, 156–161.\nPouget, A., Dayan, P., & Zemel, R. S. (2000). Inference and computation with population\ncodes. Annual Review of Neuroscience, 26, 381–410.\nPress, W. H., Teykolsky, S. A., Vetterling, W. T., & Flannery, B. P. (1992). Numerical recipes in\nC: The art of scientific computing. New York: Cambridge University Press.\nPrestwich, W. V., Kenneth, T. J., & Pepper, G. T. (1986). Search for 1/f fluctuations in alpha\ndecay. Physical Review A, 34, 5132–5134.\nPrinz, W., & Hommel, B. (2002). Common mechanisms in perception and action: Attention and\nPerformance, XIX. Oxford England: Oxford University Press.\nRayner, K. (1998). Eye movements in reading and information processing: 20 years of research.\nPsychological Bulletin, 124, 372–422.\nRayner, K., Carlson, M., & Frazier, L. (1983). The interaction of syntax and semantics during\nsentence processing: Eye movements in the analysis of semantically biased sentences.\nJournal of Verbal Learning and Verbal Behavior, 22, 358–374.\n2nd ed.Reynolds, J. H., & Desimone, R. (2001). Neural mechanisms of attentional selection. In\nJ. Braun and C. Koch (Eds.), Visual attention and cortical circuits (pp. 121–135).\nCambridge, MA: MIT Press.\nRichardson, D. C., & Dale, R. (2004). Looking to understand: The coupling between speakers’\nand listeners’ eye movements and its relationship to discourse comprehension. Proceedings\nof the 26th Annual Meeting of the Cognitive Science Society.\nRichardson, K. A., ImhoV, T. T., Grigg, P., & Collins, J. J. (1998). Using electrical noise to\nenhance the ability of humans to detect subthreshold mechanical cutaneous stimuli. Chaos,\n8, 599–603.\nRiley, M. A., Balasubramaniam, R., & Turvey, M. T. (1999). Recurrence quantification analysis\nof postural fluctuations. Gait and Posture, 9, 65–78.\nRiley, M. A., & Clark, S. (2003). Recurrence analysis of human postural sway during the\nsensory organization test. Neuroscience Letters, 342, 45–48.\nRips, L. J., Shoben, E. J., & Smith, E. E. (1973). Semantic distance and the verification of\nsemantic relations. Journal of Verbal Learning and Verbal Behavior, 12, 1–20.\nRolls, E. T., & Tovee, M. J. (1995). Sparseness of the neuronal representation of stimuli in the\nprimate temporal visual cortex. Journal of Neurophysiology, 73, 713–726.\nRosch, E., & Mervis, C. B. (1975). Family resemblances: Studies in the internal structure of\ncategories. Cognitive Psychology, 7, 573–605.\nRose, D. (1996). Some reflections on (or by?) grandmother cellsPerception, 25, 881–886.\nSchall, J. D. (2000). Decision making: From sensory evidence to a motor command. Current\nBiology, 10, R404–R406.\nSchmidt, R. C., Carello, C., & Turvey, M. T. (1990). Phase transitions and critical fluctuations\nin the visual coordination of rhythmic movements between people. Journal of Experimental\nPsychology: Human Perception and Performance, 16, 227–247.\nSebanz, N., Knoblich, G., & Prinz, W. (2003). Representing others’ actions: Just like one’s\nown?Cognition, 88, B11–B21.\nShepard, R. N., &Metzler, J. (1971). Mental rotation of three-dimensional objects. Science, 171,\n701–703.\nAU:30\nAU:31\nContinuity of Mind 139\nU N C O R R E C T E D P R O O F\nShockley, K., Santana, M. V., & Fowler, C. A. (2003). Mutual interpersonal postural con-\nstraints are involved in cooperative conversation. Journal of Experimental Psychology:\nHuman Perception and Performance, 29, 326–332.\nSimonotto, E., Riani, M., Seife, C., Roberts, M., Twitty, J., & Moss, F. (1997). Visual percep-\ntion of stochastic resonance. Physical Review Letters, 78, 1186–1189.\nSimonotto, E., Spano, F., Riani, M., Ferrari, A., & Levrero, Pilot (1999). fMRI studies of visual\ncortical activity during noise stimulation. Neurocomputing, 26–27, 511–516.\nSmith, E. E., Shoben, E. J., & Rips, L. J. (1974). Structure and process in semantic memory:\nA featural model for semantic decisions. Psychological Review, 81, 214–241.\nSparks, D. L., Holland, R., & Guthrie, B. L. (1976). Size and distribution of movement fields in\nthe monkey superior colliculus. Brain Research, 113, 21–34.\nSpencer, J. P., & Schöner, G. (2003). Bridging the representational gap in the dynamic systems\napproach to development. Developmental Science, 6, 392–412.\nSpivey, M. J. (in preparation). The continuity of mind. Oxford University Press.\nSpivey,M., Fitneva, S., Tabor,W., &Ajmani, S. (2002a). The timecourse of information integra-\ntion in sentence processing. In P.Merlo and S. Stevenson (Eds.), The lexical basis of sentence\nprocessing: Formal, computational, and experimental issues (pp. 207–232). Benjamins.\nSpivey, M., & Tanenhaus, M. (1998). Syntactic ambiguity resolution in discourse: Modeling the\neVects of referential context and lexical frequency. Journal of Experimental Psychology:\nLearning, Memory, and Cognition, 24, 1521–1543.\nSpivey, M., Richardson, D., & Fitneva, S. (2004). Thinking outside the brain: Spatial indices to\nlinguistic and visual information. In J. Henderson and F. Ferreira (Eds.), The interaction of\nvision, language, and action. San Diego, CA: Academic Press.\nSpivey, M., Richardson, D., & Gonzalez Marquez, M. (in press). On the spatial and image\nschematic underpinnings of real-time language processing. In R. Zwaan &D. Pecher (Eds.),\nThe grounding of cognition: The role of perception and action in memory, language, and\nthinking. Cambridge University Press.\nSpivey, M. J., & Marian, V. (1999). Cross talk between native and second languages: Partial\nactivation of an irrelevant lexicon. Psychological Science, 10, 281–284.\nSpivey, M., Tanenhaus, M., Eberhard, K., & Sedivy, J. (2002b). Eye movements and spoken\nlanguage comprehension: EVects of visual context on syntactic ambiguity resolution.\nCognitive Psychology, 45, 447–481.\nSpivey, M., Tyler, M., Eberhard, K., & Tanenhaus, M. (2001). Linguistically mediated visual\nsearch. Psychological Science, 12, 282–286.\nSpivey-Knowlton, M. J., & Allopenna, P. D. (1997). A computational account of the integration\nof linguistic and visual information during spoken word recognition. Paper presented at the\nComputational Psycholinguistics Conference, Berkeley, CA.\nSpivey-Knowlton, M., & Sedivy, J. (1995). Resolving attachment ambiguities with multiple\nconstraints. Cognition, 55, 227–267.\nSpivey-Knowlton, M., Sedivy, J., Eberhard, K., & Tanenhaus, M. (1994). Psycholinguistic study\nof the interaction between language and vision. In AAAI-94 workshop proceedings on the\nintegration of natural language and vision processing. Menlo Park, CA: AAAI Press.\nStemmler, M., Usher, M., & Niebur, E. (1995). Lateral interactions in primary visual cortex:\nA model bridging physiology and psychophysics. Science, 269, 1877–1880.\nStevenson, S. (1994). Competition and recency in a hybrid network model of syntactic disam-\nbiguation. Journal of Psycholinguistic Research, 23, 295–322.\nTabor, W., & Tanenhaus, M. K. (1999). Dynamical models of sentence processing. Cognitive\nScience, 23, 491–515.\nTakens, F. (1985). On the numerical determination of the dimension of an attractor. Lecture\nNotes in Mathematics: Dynamical Systems and Bifurcations, 1125, 99.\nAU:32\nAU:33\nAU:34\nAU:36\nAU:35\nAU:37\n140 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "U N C O R R E C T E D P R O O F\nTalmy, L. (1983). How language structures space. In H. Pick and L. Acredolo (Eds.), Spatial\norientation: Theory, research and application. Plenum Press.\nTanaka, K. (1997). Mechanisms of visual object recognition: Monkey and human studies.\nCurrent Opinion in Neurobiology, 7, 523–429.\nTanenhaus, M., Spivey-Knowlton, M., Eberhard, K., & Sedivy, J. (1995). Integration of visual\nand linguistic information during spoken language comprehension. Science, 268, 1632–1634.\nTanenhaus, M., Spivey-Knowlton, M., & Hanna, J. (2000). Modeling the eVects of discourse\nand thematic fit in syntactic ambiguity resolution. In M. Crocker, M. Pickering, and C.\nClifton (Eds.), Architectures and mechanisms for language processing (pp. 90–118).\nCambridge, England: Cambridge University Press.\nTanenhaus, M., & Trueswell, J. (1995). Sentence comprehension. In J. Miller and P. Eimas\n(Eds.), Handbook of cognition and perception. Academic Press.\nTheeuwes, J., & Kooi, K. L. (1994). Parallel search for a conjunction of contrast polarity and\nshape. Vision Research, 34, 3013.\nThelen, E., & Smith, L. B. (1994). A dynamic systems approach to the development of cognition\nand action. Cambridge, MA: MIT Press.\nTownsend, J. T., & Busemeyer, J. R. (1995). Dynamic representation of decision making. In\nR. F. Port and T. van Gelder (Eds.), Mind as motion. Cambridge, MA: MIT Press.\nTreisman, A. (1988). Features and objects: The Fourteenth Bartlett Memorial Lecture. Quar-\nterly Journal of Experimental Psychology, 40A, 201–237.\nTreisman, A., & Gelade, G. (1980). A feature integration theory of attention. Cognitive Psy-\nchology, 12, 97–136.\nTrueswell, J., & Kim, A. (1998). How to prune a garden path by nipping it in the bud: Fast\npriming of verb argument structure. Journal of Memory and Language, 39(1), 102–123July.\nTrueswell, J., Tanenhaus, M., & Garnsey, S. (1994). Semantic influences on parsing: Use of\nthematic role information in syntactic disambiguation. Journal of Memory and Language,\n33, 285–318.\nTuller, B., Case, P., Ding, M., & Kelso, J. A. (1994). The nonlinear dynamics of speech\ncategorization. Journal of Experimental Psychology: Human Perception and Performance,\n20, 3–16.\nTurvey, M. T., & Carello, C. (1981). Cognition: The view from ecological realism. Cognition, 10,\n313–321.\nTyler, L. K., & Marslen-Wilson, W. D. (1977). The on-line eVects of semantic context on\nsyntactic processing. Journal of Verbal Learning and Verbal Behavior, 16, 683–692.\nUsher, M., Stemmler, M., & Olami, Z. (1995). Dynamic pattern formation leads to 1/f noise in\nneural populations. Physical Review Letters, 74, 326–329.\nVan Berkum, J. J. A., Brown, C. M., & Hagoort, P. (1999). Early referential context eVects in\nsentence processing: Evidence from event-related brain potentials. Journal of Memory and\nLanguage, 41, 147–182.\nVan Gompel, R. P. G., Pickering, M. J., & Traxler, M. J. (2001). Reanalysis in sentence\nprocessing: Evidence against current constraint-based and two-stage models. Journal of\nMemory and Language, 45, 225–258.\nVan Orden, G. C., Holden, J. G., & Turvey, M. T. (2003). Self organization of cognitive\nperformance. Journal of Experimental Psychology: General, 132, 331–350.\nVan Neumann, J. (1958). The computer and the brain. Oxford, England: Yale University Press.\nVan Rullen, R., & Thorpe, S. (2001). Is it a bird? Is it a plane? Ultra-rapid categorization of\nnatural and artificial objects. Perception, 30, 655–668.\nVoss, R. F., & Clarke, J. (1975). 1/f noise in music and speech. Nature, 258, 317–318.\nWard, L. (2002). Dynamical cognitive science. Cambridge, MA: MIT Press.\nAU:38\nAU:39\nAU:40\nAU:41\nContinuity of Mind 141\nU N C O R R E C T E D P R O O F\nWard, L., Moss, F., Desai, S., & Rootman, D. (2001). Stochastic resonance in detection of\nauditory beats by humans. Unpublished manuscript: University of British Columbia.\nWebber, C. L., Jr., & Zbilut, J. P. (1994). Dynamical assessment of physiological systems and\nstates using recurrence plot strategies. Journal of Applied Physiology, 76, 965–973.\nWickelgren, W. A. (1977). Concept neurons: A proposed developmental study. Bulletin of the\nPsychonomic Society, 10, 232–234.\nWolfe, J. M. (1994). Guided Search 2.0: A revised mode of visual search. Psychonomic Bulletin &\nReview, 1, 202–238.\nWolfe, J. M. (1998). What can 1 million trials tell us about visual search?Psychological Science,\n9, 33–39.\nYoung, M. P., & Yamane, S. (1992). Sparse population coding of faces in the inferotemporal\ncortex. Science, 256, 1327–1331.\nZbilut, J. P., & Webber, C. L., Jr. (1992). Embeddings and delays as derived from quantification\nof recurrence plots. Physics Letters A, 171, 199–203.\nZeki, S. (1993). A vision of the brain. Oxford, England: Blackwell Scientific.\nZemel, R., Dayan, P., & Pouget, A. (1998). Probabilistic interpretation of population codes.\nNeural Computation, 10, 403–430.\nZemel, R., & Mozer, M. (2001). Localist attractor networks. Neural Computation, 13,\n1045–1064.\nZeng, F. G., Fu, Q. J., & Morse, R. (2000). Human hearing enhanced by noise. Brain Research,\n869, 251–255.\nZwitserlood, P. (1989). The locus of the eVects of sentential-semantic context in spoken-word\nprocessing. Cognition, 32, 25–64.\n142 Spivey and Dale"
    }, {
      "heading" : null,
      "text" : "Author Query Form\nJournal: The Psychology of Learning and Motivation, 45\nArticle No.: Chapter 3\n_____________________________________________________\nDear Author,\nDuring the preparation of your manuscript for typesetting some questions have arisen. These are listed below. Please check your typeset proof carefully and mark any corrections in the margin of the proof or compile them as a separate list. This form should then be returned with your marked proof/list of corrections to Elsevier Science.\nDisk use\nIn some instances we may be unable to process the electronic file of your article and/or artwork. In that case we have, for efficiency reasons, proceeded by using the hard copy of your manuscript. If this is the case the reasons are indicated below:\n¤ Disk damaged ¤ Incompatible file format ¤ LaTeX file for nonLaTeX journal\n¤ Virus infected ¤ Discrepancies between electronic file and (peer-reviewed, therefore definitive) hard copy.\n¤ Other: ...................................................\nWe have proceeded as follows:\n¤ Manuscript scanned ¤ Manuscript keyed in ¤ Artwork scanned\n¤ Files only partly used (parts processed differently:........................................................)\nBibliography\nIf discrepancies were noted between the literature list and the text references, the following may apply:\n¤ The references listed below were noted in the text but appear to be missing from your literature list. Please complete the list or remove the references from the text.\nUncited references: This section comprises references which occur in the reference list but not in the body of the text. Please position each reference in the text or, alternatively, delete it. Any reference not dealt with will be retained in this section.\nQuery Refs. Details Required Author’s response\nAU1 Update?\nAU2 1995?\nAU3 Update?\nAU4 Ok?\nAU5 Ok?\nAU6 Not in Refs.\nAU7 Not in refs.\nAU8 Ok?\nAU9 Not in Refs.\nAU10 Not in Refs.\nAU11 OK?\nAU12 Not in refs.\nAU13 Ok?\nAU14 Order ok?\nAU15 Update?\nAU16 City?\nAU17 City?\nAU18 initials?\nAU19 OK?\nAU20 pp?\nAU21 date?\nAU22 pp?\nAU23 pp?\nAU24 1994?\nAU25 city? pub?\nAU26 pp?\nAU27 pp? city? pub?\nAU28 pp?\nAU29 city? pub?\nAU30 order ok?\nAU31 City? pub? pp?\nAU32 Update? City?\nAU33 City?\nAU34 pp? OK?\nAU35 update? City?\nAU36 Month.\nAU37 pp?\nAU38 city?\nAU39 pp?\nAU40 pp?\nAU41 Ok?\nAU42 Ok?\nAU43 Ok?\nAU44 Caps needed?"
    }, {
      "heading" : null,
      "text" : "Typesetter Query\nAttention authors: Please address every typesetter query below. Failure to do so may result in references being deleted from your proofs. Thanks for your cooperation.\nQuery Refs. Details Required Author’s response\n1. The following references are not included in the reference list. Please advise. Gibson & Dewey, 1896. Von Neumann, 1958. Kelso, 1994. Liberman, 1982. MacDonald & Pearlmutter, 1995. Tanenhaws et al., 2002. Herb Clarks, 1992. Cooper & Shepard, 1973 Duncan & Desimone, 1995 Spivey-Knowlton, 1996. Gold & Shadlen, 2001. Ding, Chen, & Kelso, 2001. Dewey (1896).\n2. For the following references we have changed the order of author names in order to match with the Reference list. 1. Duncan & Desimone (1995) to Desimone & Duncan (1995) (Page 118, 1st para top of 3rd line, and 3rd para last of 12th line) 2. MacDonald & Pearlmutter (1995 ) t o Pea r lmu t te r & MacDonald (1995) (Page 113, 1st para top of 16th line)\n3. The following references are not cited in the text. Please advise. 1. Liberman (1957) 2. Van Neumann (1958).\n4. The year of the following reference in text citation has been matched with reference list. (i) Dewey (1896) to Dewey (1986) (page 87, 2nd para last of 6th line and page 132, 2nd para, 14th line). (ii) Ding (2001) to Ding (2002) (page 125, last para of 10th line)\n5. Please check and confirm the page range for the following reference Tanaka, 1997."
    } ],
    "references" : [ ],
    "referenceMentions" : [ ],
    "year" : 2005,
    "abstractText" : "In 1960, J. J. Gibson reviewed technical uses of the term stimulus and found that it did not have a consistent agreed-upon definition, but instead connoted several diVerent conceptions of ‘‘stimulating’’ an organism. Most of those conceptions did, however, have a property also found in the word’s original uses: A stimulus is a temporally discrete, momentary happening in the life of an organism. Challenging this intuition, Gibson’s ecological psychology assumes at its foundation the continuity of the stimulation in the surrounding environment. What this means is that the ‘‘flowing array of stimulus energy,’’ as Gibson called it, is never presegmented into easily defined independent chunks, or ‘‘stimuli,’’— even though we feel as though we perceive it that way. Before Gibson, Dewey (1986) famously made a similar point in his influential critique of the reflex arc concept. The reflex arc concept was a relatively new idea, framing the questions of psychology in terms of causal arcs among stimulus, mental event, and response. Essentially, studying the causal arcs between just the former two, or the latter two, was considered a legitimate scientific enterprise in and of itself. In contrast, treating the",
    "creator" : "PScript5.dll Version 5.2"
  }
}