{
  "name" : "Reference-Aware Language Models.pdf",
  "metadata" : {
    "source" : "CRF",
    "title" : "Reference-Aware Language Models",
    "authors" : [ "Zichao Yang", "Phil Blunsom", "Chris Dyer", "Wang Ling" ],
    "emails" : [ "zichaoy@cs.cmu.edu,", "pblunsom@google.com", "cdyer@google.com", "lingwang@google.com" ],
    "sections" : [ {
      "heading" : "1 Introduction",
      "text" : "Referring expressions (REs) in natural language are noun phrases (proper nouns, common nouns, and pronouns) that identify objects, entities, and events in an environment. REs occur frequently and they play a key role in communicating information efficiently. While REs are common in natural language, most previous work does not model them explicitly, either treating REs as ordinary words in the model or replacing them with special tokens that are filled in with a post processing step (Wen et al., 2015; Luong et al., 2015). Here we propose a language modeling framework that explicitly incorporates reference decisions. In part, this is based on the principle of pointer networks in which copies are made from another source (Gülçehre et al., 2016; Gu et al., 2016; Ling et al.,\n∗Work completed at DeepMind.\n2016; Vinyals et al., 2015; Ahn et al., 2016; Merity et al., 2016). However, in the full version of our model, we go beyond simple copying and enable coreferent mentions to have different forms, a key characteristic of natural language reference.\nFigure 1 depicts examples of REs in the context of the three tasks that we consider in this work. First, many models need to refer to a list of items (Kiddon et al., 2016; Wen et al., 2015). In the task of recipe generation from a list of ingredients (Kiddon et al., 2016), the generation of the recipe will frequently refer to these items. As shown in Figure 1, in the recipe “Blend soy milk and . . . ”, soy milk refers to the ingredient summaries. Second, reference to a database is crucial in many applications. One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016). Here we consider the domain of restaurant recommendation where a system refers to restaurants (name) and their attributes (address, phone number etc) in its responses. When the system ar X iv :1 61 1.\n01 62\n8v 5\n[ cs\n.C L\n] 9\nA ug\n2 01\n7\nsays “the nirala is a nice restaurant”, it refers to the restaurant name the nirala from the database. Finally, we address references within a document (Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015), as the generation of words will often refer to previously generated words. For instance the same entity will often be referred to throughout a document. In Figure 1, the entity you refers to I in a previous utterance. In this case, copying is insufficient– although the referent is the same, the form of the mention is different.\nIn this work we develop a language model that has a specific module for generating REs. A series of decisions (should I generate a RE? If yes, which entity in the context should I refer to? How should the RE be rendered?) augment a traditional recurrent neural network language model and the two components are combined as a mixture model. Selecting an entity in context is similar to familiar models of attention (Bahdanau et al., 2014), but rather than being a soft decision that reweights representations of elements in the context, it is treated as a hard decision over contextual elements which are stochastically selected and then copied or, if the task warrants it, transformed (e.g., a pronoun rather than a proper name is produced as output). In cases when the stochastic decision is not available in training, we treat it as a latent variable and marginalize it out. For each of the three tasks, we pick one representative application and demonstrate our reference aware model’s efficacy in evaluations against models that do not explicitly include a reference operation.\nOur contributions are as follows:\n• We propose a general framework to model reference in language. We consider reference to entries in lists, tables, and document context. We instantiate these tasks into three specific applications: recipe generation, dialogue modeling, and coreference based language models.\n• We develop the first neural model of reference that goes being copying and can model (conditional on context) how to form the mention.\n• We perform comprehensive evaluation of our models on the three data sets and verify our proposed models perform better than strong baselines."
    }, {
      "heading" : "2 Reference-aware language models",
      "text" : "Here we propose a general framework for reference-aware language models.\nWe denote each document as a series of tokens x1, . . . , xL, where L is the number of tokens. Our goal is to maximize p(xi | ci), the probability of each word xi given its previous context ci = x1, . . . , xi−1. In contrast to traditional neural language models, we introduce a variable zi at each position, which controls the decision on which source xi is generated from. Then the conditional probability is given by:\np(xi, zi | ci) = p(xi | zi, ci)p(zi | ci), (1)\nwhere zi has different meanings in different contexts. If xi is from a reference list or a database, then zi is one dimensional and zi = 1 denotes xi is generated as a reference. zi can also model more complex decisions. In coreference based language model, zi denotes a series of sequential decisions, such as whether xi is an entity, if yes, which entity xi refers to. When zi is not observed, we will train our model to maximize the marginal probability over zi, i.e., p(xi|ci) = ∑ zi p(xi|zi, ci)p(zi|ci)."
    }, {
      "heading" : "2.1 Reference to lists",
      "text" : "We begin to instantiate the framework by considering reference to a list of items. Referring to a list of items has broad applications, such as generating documents based on summaries etc. Here we specifically consider the application of recipe generation conditioning on the ingredient lists. Table. 1 illustrates the ingredient list and recipe for Spinach and Banana Power Smoothie. We can see that the ingredients soy milk, spinach leaves, and banana occur in the recipe.\nLet the ingredients of a recipe be X = {xi}Ti=1 and each ingredient contains L tokens xi =\n{xij}Lj=1. The corresponding recipe is y = {yv}Kv=1. We would like to model p(y|X) = Πvp(yv|X, y<v).\nWe first use a LSTM (Hochreiter and Schmidhuber, 1997) to encode each ingredient: hi,j = LSTME(WExij , hi,j−1) ∀i. Then, we sum the resulting final state of each ingredient to obtain the starting LSTM state of the decoder. We use an attention based decoder:\nsv = LSTMD([WEyv−1, dv−1], sv−1),\npcopyv = ATTN({{hi,j}Ti=1}Lj=1, sv), dv = ∑ ij pv,i,jhi,j ,\np(zv|sv) = sigmoid(W [sv, dv]), pvocabv = softmax(W [sv, dv]),\nwhere ATTN(h, q) is the attention function that returns the probability distribution over the set of vectors h, conditioned on any input representation q. A full description of this operation is described in (Bahdanau et al., 2014). The decision to copy from the ingredient list or generate a new word from the softmax is performed using a switch, denoted as p(zv|sv). We can obtain a probability distribution of copying each of the words in the ingredients by computing pcopyv = ATTN({{hi,j}Ti=1}Lj=1, sv) in the attention mechanism. Objective: We can obtain the value of zv through a string match of tokens in recipes with tokens in ingredients. If a token appears in the ingredients, we set zv = 1 and zv = 0 otherwise. We can train the model in a fully supervised fashion, i.e., we can obtain the probability of yv as p(yv, zv|sv) = pcopyv (yv)p(1|sv) if zv = 1 and pvocabv (yv)(1− p(1|si,v)) otherwise.\nHowever, it may be not be accurate. In many cases, the tokens that appear in the ingredients do not specifically refer to ingredients tokens. For examples, the recipe may start with “Prepare a cup of water”. The token “cup” does not refer to the “cup” in the ingredient list “1 cup plain soy milk”.\nTo solve this problem, we treat zi as a latent variable, we wish to maximize the marginal probability of yv over all possible values of zv. In this way, the model can automatically learn when to refer to tokens in the ingredients. Thus, the probability of generating token yv is defined as:\np(yv|sv) = pvocabv (yv)p(0|sv) + pcopyv (yv)p(1|sv) = pvocabv (yv)(1− p(1|sv)) + pcopyv (yv)p(1|sv).\nIf no string match is found for yv, we simply set p copy v (yv) = 0 in the above objective."
    }, {
      "heading" : "2.2 Reference to databases",
      "text" : "We then consider the more complicated task of reference to database entries. Referring to databases is quite common in question answering and dialogue systems, in which databases are external knowledge and they are resorted to reply users’ query. In our paper, we consider the application of task-oriented dialogue systems in the domain of restaurant recommendations. Different from lists that are one dimensional, databases are twodimensional and referring to table entries requires sophisticated model design.\nTo better understand the model, we first make a brief introduction of the data set. We use dialogues from the second Dialogue State Tracking Challenge (DSTC2) (Henderson et al., 2014). Table. 3 is one example dialogue from this dataset.\nWe can observe from this example, users get recommendations of restaurants based on queries that specify the area, price and food type of the restaurant. We can support the system’s decisions by incorporating a mechanism that allows the model to query the database to find restaurants that satisfy the users’ queries. A sample of our database (refer to data preparation part on how we construct the database) is shown in Table 2. We can observe that each restaurant contains 6 attributes that are generally referred in the dialogue dataset. As such, if the user requests a restaurant that serves “indian” food, we wish to train a model that can search for entries whose “food”\ncolumn contains “indian”. Now, we describe how we deploy a model that fulfills these requirements. We first introduce the basic dialogue framework in which we incorporates the table reference module. Basic Dialogue Framework: We build a basic dialogue model based on the hierarchical RNN model described in (Serban et al., 2016), as in dialogues, the generation of the response is not only dependent on the previous sentence, but on all sentences leading to the response. We assume that a dialogue is alternated between a machine and a user. An illustration of the model is shown in Figure 3.\nConsider a dialogue with T turns, the utterances from a user and a machines are denoted as X = {xi}Ti=1 and Y = {yi}Ti=1 respectively, where i is the i-th utterance. We define xi = {xij}|xi|j=1, yi = {yiv} |yi| v=1, where xij (yiv) denotes the j-th (v-th) token in the i-th utterance from the user (the machines). The dialogue sequence\nstarts with a machine utterance and is given by {y1, x1, y2, x2, . . . , yT , xT }. We would like to model the utterances from the machine\np(y1, y2, . . . , yT |x1, x2, . . . , xT ) =∏ i p(yi|y<i, x<i) = ∏ i,v p(yi,v|yi,<v, y<i, x<i).\nWe encode y<i and x<i into continuous space in a hierarchical way with LSTM: Sentence Encoder: For a given utterance xi, We encode it as hxi,j = LSTME(WExi,j , h x i,j−1). The representation of xi is given by the hxi = h x i,|xi|. The same process is applied to obtain the machine utterance representation hyi = h y i,|yi|. Turn Encoder: We further encode the sequence {hy1, hx1 , ..., h y i , h x i } with another LSTM encoder. We shall refer the last hidden state as ui, which can be seen as the hierarchical encoding of the previous i utterances. Decoder: We use ui−1 as the initial state of decoder LSTM and decode each token in yi. We can express the decoder as:\nsyi,v = LSTMD(WEyi,v−1, si,v−1), pyi,v = softmax(Ws y i,v).\nWe can also incoroprate the attetionn mechanism in the decoder. As shown in Figure. 3, we use the attention mechanism over the utterance in the previous turn. Due to space limit, we don’t present the attention based decoder mathmatically and readers can refer to (Bahdanau et al., 2014) for details."
    }, {
      "heading" : "2.2.1 Incorporating Table Reference",
      "text" : "We now extend the decoder in order to allow the model to condition the generation on a database. Pointer Switch: We use zi,v ∈ {0, 1} to denote the decision of whether to copy one cell from the table. We compute this probability as follows:\np(zi,v|si,v) = sigmoid(Wsi,v).\nThus, if zi,v = 1, the next token yi,v is generated from the database, whereas if zi,v = 0, then the following token is generated from a softmax. We now describe how we generate tokens from the database.\nWe denote a table with R rows and C columns as {tr,c}, r ∈ [1, R], c ∈ [1, C], where tr,c is the cell in row r and column c. The attribute of each column is denoted as sc, where c is the c-th attribute. tr,c and sc are one-hot vector.\nTable Encoding: To encode the table, we first build an attribute vector and then an encoding vector for each cell. The attribute vector is simply an embedding lookup gc = WEsc. For the encoding of each cell, we first concatenate embedding lookup of the cell with the corresponding attribute vector gc and then feed it through a one-layer MLP as follows: then er,c = tanh(W [WEtr,c, gc]).\nTable Pointer: The detailed process of calculating the probability distribution over the table is shown in Figure 4. The attention over cells in the table is conditioned on a given vector q, similarly to the attention model for sequences. However, rather than a sequence of vectors, we now operate over a table. Step 1: Attention over the attributes to find out the attributes that a user asks about, pa = ATTN({gc}, q). Suppose a user says cheap, then we should focus on the price attribute. Step 2: Conditional row representation calculation, er = ∑ c p a cer,c ∀r. So that er contains the price information of the restaurant in row r. Step 3: Attention over er to find out the restaurants that satisfy users’ query, pr = ATTN({er}, q). Restaurants with cheap price will be picked. Step 4: Using the probabilities pr, we compute the weighted average over the all rows ec =∑\nr p r rer,c. {er} contains the information of cheap restaurant. Step 5: Attention over columns {er} to compute the probabilities of copying each column pc = ATTN({ec}, q).\nStep 6: To get the probability matrix of copying each cell, we simply compute the outer product pcopy = pr ⊗ pc. The overall process is as follows:\npa = ATTN({gc}, q), er = ∑ c pacer,c ∀r, pr = ATTN({er}, q),\nec = ∑ r prrer,c ∀c,\npc = ATTN({ec}, q), pcopy = pr ⊗ pc.\nIf zi,v = 1, we embed the above attention process in the decoder by replacing the conditioned state q with the current decoder state syi,v. Objective: As in previous task, we can train the model in a fully supervised fashion, or we can treat the decision as a latent variable. We can get p(yi,v|si,v) in a similar way."
    }, {
      "heading" : "2.3 Reference to document context",
      "text" : "Finally, we address the references that happen in a document itself and build a language model that uses coreference links to point to previous entities. Before generating a word, we first make the decision on whether it is an entity mention. If so, we decide which entity this mention belongs to, then we generate the word based on that entity. Denote the document as X = {xi}Li=1, and the entities are E = {ei}Ni=1, each entity has Mi mentions, ei = {mij}Mij=1, such that {xmij} Mi j=1 refer to the same entity. We use a LSTM to model the document, the hidden state of each token is hi = LSTM(WExi, hi−1). We use a set he = {he0, he1, ..., heM} to keep track of the entity states, where hej is the state of entity j. Word generation: At each time step before generating the next word, we predict whether the word is an entity mention:\npcoref(vi|hi−1, he) = ATTN(he, hi−1), di = ∑ vi p(vi)h e vi ,\np(zi|hi−1) = sigmoid(W [hi−1, di]),\nwhere zi denotes whether the next word is an entity and if yes vi denotes which entity the next word corefers to. If the next word is an entity mention, then p(xi|vi, hi−1, he) =\num and [I]1 think that is whats - Go ahead [Linda]2. Well and thanks goes to [you]1 and to [the media]3 to help [us]4...So [our]4 hat is off to all of [you]5...\nsoftmax(W1 tanh(W2[hi−1, hevi ])) else p(xi|hi−1) = softmax(W1hi−1). Hence, p(xi|x<i) = p(xi|hi−1)p(zi|hi−1, he) if zi = 0. p(xi|vi, hi−1, he)× pcoref(vi|hi−1, he)p(zi|hi−1, he) if zi = 1.\nEntity state update: Since there are multiple mentions for each entity and the mentions appear dynamically, we need to keep track of the entity state in order to use coreference information in entity mention prediction. We update the entity state he at each time step. In the beginning, he = {he0}, he0 denotes the state of an virtual empty entity and is a learnable variable. If zi = 1 and vi = 0, then it indicates the next word is a new entity mention, then in the next step, we append hi to he, i.e., he = {he, hi}, if zi = 1 and vi > 0, then we update the corresponding entity state with the new hidden state, he[vi] = hi. Another way to update the entity state is to use one LSTM to encode the mention states and get the new entity state. Here we use the latest entity mention state as the new entity state for simplicity. The detailed update process is shown in Figure 5.\nNote that the stochastic decisions in this task are more complicated than previous two tasks. We need to make two sequential decisions: whether the next word is an entity mention, and if yes, which entity the mention corefers to. It is intractable to marginalize these decisions, so we train this model in a supervised fashion (refer to data preparation part on how we get coreference annotations)."
    }, {
      "heading" : "3 Experiments",
      "text" : ""
    }, {
      "heading" : "3.1 Data sets and preprocessing",
      "text" : "Recipes: We crawled all recipes from www. allrecipes.com. There are about 31, 000\nrecipes in total, and every recipe has an ingredient list and a corresponding recipe. We exclude the recipes that have less than 10 tokens or more than 500 tokens, those recipes take about 0.1% of all data set. On average each recipe has 118 tokens and 9 ingredients. We random shuffle the whole data set and take 80% as training and 10% for validation and test. We use a vocabulary size of 10,000 in the model. Dialogue: We use the DSTC2 data set. We only use the dialogue transcripts from the data set. There are about 3,200 dialogues in total. The table is not available from DSTC2. To reconstruct the table, we crawled TripAdvisor for restaurants in the Cambridge area, where the dialog dataset was collected. Then, we remove restaurants that do not appear in the data set and create a database with 109 restaurants and their attributes (e.g. food type). Since this is a small data set, we use 5- fold cross validation and report the average result over the 5 partitions. There may be multiple tokens in each table cell, for example in Table. 2, the name, address, post code and phone number have multiple tokens, we replace them with one special token. For the name, address, post code and phone number of the j-th row, we replace the tokens in each cell with NAME j, ADDR j, POSTCODE j, PHONE j. If a table cell is empty, we replace it with an empty token EMPTY. We do a string match in the transcript and replace the corresponding tokens in transcripts from the table with the special tokens. Each dialogue on average has 8 turns (16 sentences). We use a vocabulary size of 900, including about 400 table tokens and 500 words. Coref LM: We use the Xinhua News data set from Gigaword Fifth Edition and sample 100,000 documents that has length in range from 100 to 500. Each document has on average 234 tokens, so there are 23 million tokens in total. We process\nthe documents to get coreference annotations and use the annotations, i.e., zi, vi, in training. We take 80% as training and 10% as validation and test respectively. We ignore the entities that have only one mention and for the mentions that have multiple tokens, we take the token that is most frequent in the all the mentions for this entity. After preprocessing, tokens that are entity mentions take about 10% of all tokens. We use a vocabulary size of 50,000 in the model."
    }, {
      "heading" : "3.2 Baselines, model training and evaluation",
      "text" : "We compare our model with baselines that do not model reference explicitly. For recipe generation and dialogue modeling, we compare our model with basic seq2seq and attention model. We also apply attention mechanism over the table for dialogue modeling as a baseline. For coreference based language model, we compare our model with simple RNN language model.\nWe train all models with simple stochastic gradient descent with gradient clipping. We use a one-layer LSTM for all RNN components. Hyperparameters are selected using grid search based on the validation set.\nEvaluation of our model is challenging since it involves three rather different applications. We focus on evaluating the accuracy of predicting the reference tokens, which is the goal of our model. Specifically, we report the perplexity of all words, words that can be generated from reference and non-reference words. The perplexity is calculated by multiplying the probability of decision at each step all together. Note that for non-reference words, they also appear in the vocabulary. So it is a fair comparison to models that do not model reference explicitly. For the recipe task, we also generate the recipes using beam size of 10 and evaluate the generated recipes with BLEU. We didn’t use BLEU for dialogue generation since the database entries take only a very small part of all tokens in utterances."
    }, {
      "heading" : "3.3 Results and analysis",
      "text" : "The results for recipe generation, dialogue and coref based language model are shown in Table 4, 5, and 6 respectively. The recipe results in Table 4 verifies that modeling reference explicitly improves performance. Latent and Pointer perform better than Seq2Seq and Attn model. The Latent model performs better than the Pointer model since tokens in ingredients that match with recipes\ndo not necessarily come from the ingredients. Imposing a supervised signal gives wrong information to the model and hence makes the result worse. With latent decision, the model learns to when to copy and when to generate it from the vocabulary.\nThe findings for dialogue basically follow that of recipe generation, as shown in Table 5. Conditioning table performs better in predicting table tokens in general. Table Pointer has the lowest perplexity for tokens in the table. Since the table tokens appear rarely in the dialogue transcripts, the overall perplexity does not differ much and the non-table token perplexity are similar. With attention mechanism over the table, the perplexity of table token improves over basic Seq2Seq model, but still not as good as directly pointing to cells in the table, which shows the advantage of modeling reference explicitly. As expected, using sentence attention improves significantly over models without sentence attention. Surprisingly, Table Latent performs much worse than Table Pointer. We also measure the perplexity of table tokens that appear only in test set. For models other than Table Pointer, because the tokens never appear in the training set, the perplexity is quite high, while Table Pointer can predict these tokens much more accurately. This verifies our conjecture that our model can learn reasoning over databases.\nThe coref based LM results are shown in Table 6. We find that coref based LM performs much better on the entity perplexity, but is a little bit worse for non-entity words. We found it was an optimization problem and the model was stuck in a local optimum. So we initialize the Pointer model with the weights learned from LM, the Pointer model performs better than LM both for entity perplexity and non-entity words perplexity.\nIn Appendix A, we also visualize the heat map of table reference and list items reference. The visualization shows that our model can correctly predict when to refer to which entries according to context."
    }, {
      "heading" : "4 Related Work",
      "text" : "In terms of methodology, our work is closely related to previous works that incorporate copying mechanism with neural models (Gülçehre et al., 2016; Gu et al., 2016; Ling et al., 2016; Vinyals et al., 2015). Our models are similar to models proposed in (Ahn et al., 2016; Merity et al., 2016),\nModel val testAll Entity Word All Entity Word LM 33.08 44.52 32.04 33.08 43.86 32.10 Pointer 32.57 32.07 32.62 32.62 32.07 32.69 Pointer + init 30.43 28.56 30.63 30.42 28.56 30.66\nTable 6: Coreference based LM. Pointer + init means we initialize the model with the LM weights.\nwhere the generation of each word can be conditioned on a particular entry in knowledge lists and previous words. In our work, we describe a model with broader applications, allowing us to condition, on databases, lists and dynamic lists.\nIn terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al., 2015; Bordes and Weston, 2016; Williams and Zweig, 2016; Wen et al., 2016). Most of previous works on task oriented dialogues embed the seq2seq model in traditional dialogue systems, in which the table query part is not differentiable, while our model queries the database directly. Recipe generation was proposed in (Kiddon et al., 2016). They use attention mechanism over the checklists, whereas our work models ex-\nplicit references to them. Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text. There are also lots of works on coreference resolution (Haghighi and Klein, 2010; Wiseman et al., 2016). We are the first to combine coreference with language modeling, to the best of our knowledge."
    }, {
      "heading" : "5 Conclusion",
      "text" : "We introduce reference-aware language models which explicitly model the decision of from where to generate the token at each step. Our model can also learns the decision by treating it as a latent variable. We demonstrate on three applications, table based dialogue modeling, recipe generation and coref based LM, that our model performs better than attention based model, which does not incorporate this decision explicitly. There are several directions to explore further based on our framework. The current evaluation method is based on perplexity and BLEU. In task oriented dialogues, we can also try human evaluation to see if the model can reply users’ query accurately. It is also interesting to use reinforcement learning to learn the actions in each step in coref based LM."
    } ],
    "references" : [ {
      "title" : "A neural knowledge language model",
      "author" : [ "References Sungjin Ahn", "Heeyoul Choi", "Tanel Pärnamaa", "Yoshua Bengio." ],
      "venue" : "CoRR, abs/1608.00318.",
      "citeRegEx" : "Ahn et al\\.,? 2016",
      "shortCiteRegEx" : "Ahn et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural machine translation by jointly learning to align and translate",
      "author" : [ "Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio." ],
      "venue" : "CoRR, abs/1409.0473.",
      "citeRegEx" : "Bahdanau et al\\.,? 2014",
      "shortCiteRegEx" : "Bahdanau et al\\.",
      "year" : 2014
    }, {
      "title" : "Learning end-to-end goal-oriented dialog",
      "author" : [ "Antoine Bordes", "Jason Weston." ],
      "venue" : "arXiv preprint arXiv:1605.07683.",
      "citeRegEx" : "Bordes and Weston.,? 2016",
      "shortCiteRegEx" : "Bordes and Weston.",
      "year" : 2016
    }, {
      "title" : "Incorporating copying mechanism in sequence-to-sequence learning",
      "author" : [ "Jiatao Gu", "Zhengdong Lu", "Hang Li", "Victor O.K. Li." ],
      "venue" : "CoRR, abs/1603.06393.",
      "citeRegEx" : "Gu et al\\.,? 2016",
      "shortCiteRegEx" : "Gu et al\\.",
      "year" : 2016
    }, {
      "title" : "Pointing the unknown words",
      "author" : [ "Çaglar Gülçehre", "Sungjin Ahn", "Ramesh Nallapati", "Bowen Zhou", "Yoshua Bengio." ],
      "venue" : "CoRR, abs/1603.08148.",
      "citeRegEx" : "Gülçehre et al\\.,? 2016",
      "shortCiteRegEx" : "Gülçehre et al\\.",
      "year" : 2016
    }, {
      "title" : "Coreference resolution in a modular, entity-centered model",
      "author" : [ "Aria Haghighi", "Dan Klein." ],
      "venue" : "Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages",
      "citeRegEx" : "Haghighi and Klein.,? 2010",
      "shortCiteRegEx" : "Haghighi and Klein.",
      "year" : 2010
    }, {
      "title" : "Dialog state tracking challenge",
      "author" : [ "Matthew Henderson", "Blaise Thomson", "Jason Williams" ],
      "venue" : null,
      "citeRegEx" : "Henderson et al\\.,? \\Q2014\\E",
      "shortCiteRegEx" : "Henderson et al\\.",
      "year" : 2014
    }, {
      "title" : "Long short-term memory",
      "author" : [ "Sepp Hochreiter", "Jürgen Schmidhuber." ],
      "venue" : "Neural computation, 9(8):1735–1780.",
      "citeRegEx" : "Hochreiter and Schmidhuber.,? 1997",
      "shortCiteRegEx" : "Hochreiter and Schmidhuber.",
      "year" : 1997
    }, {
      "title" : "Document context language models",
      "author" : [ "Yangfeng Ji", "Trevor Cohn", "Lingpeng Kong", "Chris Dyer", "Jacob Eisenstein." ],
      "venue" : "arXiv preprint arXiv:1511.03962.",
      "citeRegEx" : "Ji et al\\.,? 2015",
      "shortCiteRegEx" : "Ji et al\\.",
      "year" : 2015
    }, {
      "title" : "Exploring the limits of language modeling",
      "author" : [ "Rafal Jozefowicz", "Oriol Vinyals", "Mike Schuster", "Noam Shazeer", "Yonghui Wu." ],
      "venue" : "arXiv preprint arXiv:1602.02410.",
      "citeRegEx" : "Jozefowicz et al\\.,? 2016",
      "shortCiteRegEx" : "Jozefowicz et al\\.",
      "year" : 2016
    }, {
      "title" : "Globally coherent text generation with neural checklist models",
      "author" : [ "Chloé Kiddon", "Luke Zettlemoyer", "Yejin Choi." ],
      "venue" : "Proc. EMNLP.",
      "citeRegEx" : "Kiddon et al\\.,? 2016",
      "shortCiteRegEx" : "Kiddon et al\\.",
      "year" : 2016
    }, {
      "title" : "Deep reinforcement learning for dialogue generation",
      "author" : [ "Jiwei Li", "Will Monroe", "Alan Ritter", "Michel Galley", "Jianfeng Gao", "Dan Jurafsky." ],
      "venue" : "Proc. EMNLP.",
      "citeRegEx" : "Li et al\\.,? 2016",
      "shortCiteRegEx" : "Li et al\\.",
      "year" : 2016
    }, {
      "title" : "Latent predictor networks for code generation",
      "author" : [ "Wang Ling", "Edward Grefenstette", "Karl Moritz Hermann", "Tomáš Kočiský", "Andrew Senior", "Fumin Wang", "Phil Blunsom." ],
      "venue" : "Proc. ACL.",
      "citeRegEx" : "Ling et al\\.,? 2016",
      "shortCiteRegEx" : "Ling et al\\.",
      "year" : 2016
    }, {
      "title" : "Addressing the rare word problem in neural machine translation",
      "author" : [ "Thang Luong", "Ilya Sutskever", "Quoc V. Le", "Oriol Vinyals", "Wojciech Zaremba." ],
      "venue" : "Proceedings of the 53rd Annual Meeting of the",
      "citeRegEx" : "Luong et al\\.,? 2015",
      "shortCiteRegEx" : "Luong et al\\.",
      "year" : 2015
    }, {
      "title" : "Pointer sentinel mixture models. arXiv preprint arXiv:1609.07843",
      "author" : [ "Stephen Merity", "Caiming Xiong", "James Bradbury", "Richard Socher" ],
      "venue" : null,
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 2016
    }, {
      "title" : "Recurrent neural network based language model",
      "author" : [ "Tomas Mikolov", "Martin Karafiát", "Lukas Burget", "Jan Cernockỳ", "Sanjeev Khudanpur." ],
      "venue" : "Interspeech, volume 2, page 3.",
      "citeRegEx" : "Mikolov et al\\.,? 2010",
      "shortCiteRegEx" : "Mikolov et al\\.",
      "year" : 2010
    }, {
      "title" : "Building end-to-end dialogue systems using generative hierarchical neural network models",
      "author" : [ "Iulian V Serban", "Alessandro Sordoni", "Yoshua Bengio", "Aaron Courville", "Joelle Pineau." ],
      "venue" : "Proceedings of the 30th AAAI Conference on Artificial Intelligence",
      "citeRegEx" : "Serban et al\\.,? 2016",
      "shortCiteRegEx" : "Serban et al\\.",
      "year" : 2016
    }, {
      "title" : "Neural responding machine for short-text conversation",
      "author" : [ "Lifeng Shang", "Zhengdong Lu", "Hang Li." ],
      "venue" : "arXiv preprint arXiv:1503.02364.",
      "citeRegEx" : "Shang et al\\.,? 2015",
      "shortCiteRegEx" : "Shang et al\\.",
      "year" : 2015
    }, {
      "title" : "A neural network approach to context-sensitive generation of conversational responses",
      "author" : [ "Alessandro Sordoni", "Michel Galley", "Michael Auli", "Chris Brockett", "Yangfeng Ji", "Meg Mitchell", "Jian-Yun Nie", "Jianfeng Gao", "Bill Dolan." ],
      "venue" : "Proc. NAACL.",
      "citeRegEx" : "Sordoni et al\\.,? 2015",
      "shortCiteRegEx" : "Sordoni et al\\.",
      "year" : 2015
    }, {
      "title" : "Pointer networks",
      "author" : [ "Oriol Vinyals", "Meire Fortunato", "Navdeep Jaitly." ],
      "venue" : "Proc. NIPS.",
      "citeRegEx" : "Vinyals et al\\.,? 2015",
      "shortCiteRegEx" : "Vinyals et al\\.",
      "year" : 2015
    }, {
      "title" : "A neural conversational model",
      "author" : [ "Oriol Vinyals", "Quoc V. Le." ],
      "venue" : "Proc. ICML Deep Learning Workshop.",
      "citeRegEx" : "Vinyals and Le.,? 2015",
      "shortCiteRegEx" : "Vinyals and Le.",
      "year" : 2015
    }, {
      "title" : "Largercontext language modelling",
      "author" : [ "Tian Wang", "Kyunghyun Cho." ],
      "venue" : "arXiv preprint arXiv:1511.03729.",
      "citeRegEx" : "Wang and Cho.,? 2015",
      "shortCiteRegEx" : "Wang and Cho.",
      "year" : 2015
    }, {
      "title" : "A networkbased end-to-end trainable task-oriented dialogue system",
      "author" : [ "Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Lina M Rojas-Barahona", "Pei-Hao Su", "Stefan Ultes", "David Vandyke", "Steve Young." ],
      "venue" : "arXiv preprint arXiv:1604.04562.",
      "citeRegEx" : "Wen et al\\.,? 2016",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2016
    }, {
      "title" : "Semantically conditioned LSTM-based natural language generation for spoken dialogue systems",
      "author" : [ "Tsung-Hsien Wen", "Milica Gasic", "Nikola Mrksic", "Peihao Su", "David Vandyke", "Steve J. Young." ],
      "venue" : "Proc. EMNLP.",
      "citeRegEx" : "Wen et al\\.,? 2015",
      "shortCiteRegEx" : "Wen et al\\.",
      "year" : 2015
    }, {
      "title" : "Endto-end lstm-based dialog control optimized with supervised and reinforcement learning",
      "author" : [ "Jason D Williams", "Geoffrey Zweig." ],
      "venue" : "arXiv preprint arXiv:1606.01269.",
      "citeRegEx" : "Williams and Zweig.,? 2016",
      "shortCiteRegEx" : "Williams and Zweig.",
      "year" : 2016
    }, {
      "title" : "Learning global features for coreference resolution",
      "author" : [ "Sam Wiseman", "Alexander M Rush", "Stuart M Shieber." ],
      "venue" : "arXiv preprint arXiv:1604.03035.",
      "citeRegEx" : "Wiseman et al\\.,? 2016",
      "shortCiteRegEx" : "Wiseman et al\\.",
      "year" : 2016
    }, {
      "title" : "Pomdp-based statistical spoken dialog systems: A review",
      "author" : [ "Steve Young", "Milica Gašić", "Blaise Thomson", "Jason D Williams." ],
      "venue" : "Proceedings of the IEEE, 101(5):1160–1179.",
      "citeRegEx" : "Young et al\\.,? 2013",
      "shortCiteRegEx" : "Young et al\\.",
      "year" : 2013
    } ],
    "referenceMentions" : [ {
      "referenceID" : 23,
      "context" : "While REs are common in natural language, most previous work does not model them explicitly, either treating REs as ordinary words in the model or replacing them with special tokens that are filled in with a post processing step (Wen et al., 2015; Luong et al., 2015).",
      "startOffset" : 229,
      "endOffset" : 267
    }, {
      "referenceID" : 13,
      "context" : "While REs are common in natural language, most previous work does not model them explicitly, either treating REs as ordinary words in the model or replacing them with special tokens that are filled in with a post processing step (Wen et al., 2015; Luong et al., 2015).",
      "startOffset" : 229,
      "endOffset" : 267
    }, {
      "referenceID" : 10,
      "context" : "First, many models need to refer to a list of items (Kiddon et al., 2016; Wen et al., 2015).",
      "startOffset" : 52,
      "endOffset" : 91
    }, {
      "referenceID" : 23,
      "context" : "First, many models need to refer to a list of items (Kiddon et al., 2016; Wen et al., 2015).",
      "startOffset" : 52,
      "endOffset" : 91
    }, {
      "referenceID" : 10,
      "context" : "In the task of recipe generation from a list of ingredients (Kiddon et al., 2016), the generation of the recipe will frequently refer to these items.",
      "startOffset" : 60,
      "endOffset" : 81
    }, {
      "referenceID" : 26,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 11,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 20,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 23,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 18,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 16,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 2,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 24,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 17,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 22,
      "context" : "One example is in task oriented dialogue where access to a database is necessary to answer a user’s query (Young et al., 2013; Li et al., 2016; Vinyals and Le, 2015; Wen et al., 2015; Sordoni et al., 2015; Serban et al., 2016; Bordes and Weston, 2016; Williams and Zweig, 2016; Shang et al., 2015; Wen et al., 2016).",
      "startOffset" : 106,
      "endOffset" : 315
    }, {
      "referenceID" : 15,
      "context" : "Finally, we address references within a document (Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015), as the generation of words will often refer to previously generated words.",
      "startOffset" : 49,
      "endOffset" : 108
    }, {
      "referenceID" : 8,
      "context" : "Finally, we address references within a document (Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015), as the generation of words will often refer to previously generated words.",
      "startOffset" : 49,
      "endOffset" : 108
    }, {
      "referenceID" : 21,
      "context" : "Finally, we address references within a document (Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015), as the generation of words will often refer to previously generated words.",
      "startOffset" : 49,
      "endOffset" : 108
    }, {
      "referenceID" : 1,
      "context" : "Selecting an entity in context is similar to familiar models of attention (Bahdanau et al., 2014), but rather than being a soft decision that reweights representations of elements in the context, it is treated as a hard decision over contextual elements which are stochastically selected and then copied or, if the task warrants it, transformed (e.",
      "startOffset" : 74,
      "endOffset" : 97
    }, {
      "referenceID" : 7,
      "context" : "We first use a LSTM (Hochreiter and Schmidhuber, 1997) to encode each ingredient: hi,j = LSTME(WExij , hi,j−1) ∀i.",
      "startOffset" : 20,
      "endOffset" : 54
    }, {
      "referenceID" : 1,
      "context" : "A full description of this operation is described in (Bahdanau et al., 2014).",
      "startOffset" : 53,
      "endOffset" : 76
    }, {
      "referenceID" : 6,
      "context" : "We use dialogues from the second Dialogue State Tracking Challenge (DSTC2) (Henderson et al., 2014).",
      "startOffset" : 75,
      "endOffset" : 99
    }, {
      "referenceID" : 16,
      "context" : "Basic Dialogue Framework: We build a basic dialogue model based on the hierarchical RNN model described in (Serban et al., 2016), as in dialogues, the generation of the response is not only dependent on the previous sentence, but on all sentences leading to the response.",
      "startOffset" : 107,
      "endOffset" : 128
    }, {
      "referenceID" : 1,
      "context" : "Due to space limit, we don’t present the attention based decoder mathmatically and readers can refer to (Bahdanau et al., 2014) for details.",
      "startOffset" : 104,
      "endOffset" : 127
    }, {
      "referenceID" : 4,
      "context" : "In terms of methodology, our work is closely related to previous works that incorporate copying mechanism with neural models (Gülçehre et al., 2016; Gu et al., 2016; Ling et al., 2016; Vinyals et al., 2015).",
      "startOffset" : 125,
      "endOffset" : 206
    }, {
      "referenceID" : 3,
      "context" : "In terms of methodology, our work is closely related to previous works that incorporate copying mechanism with neural models (Gülçehre et al., 2016; Gu et al., 2016; Ling et al., 2016; Vinyals et al., 2015).",
      "startOffset" : 125,
      "endOffset" : 206
    }, {
      "referenceID" : 12,
      "context" : "In terms of methodology, our work is closely related to previous works that incorporate copying mechanism with neural models (Gülçehre et al., 2016; Gu et al., 2016; Ling et al., 2016; Vinyals et al., 2015).",
      "startOffset" : 125,
      "endOffset" : 206
    }, {
      "referenceID" : 19,
      "context" : "In terms of methodology, our work is closely related to previous works that incorporate copying mechanism with neural models (Gülçehre et al., 2016; Gu et al., 2016; Ling et al., 2016; Vinyals et al., 2015).",
      "startOffset" : 125,
      "endOffset" : 206
    }, {
      "referenceID" : 0,
      "context" : "Our models are similar to models proposed in (Ahn et al., 2016; Merity et al., 2016),",
      "startOffset" : 45,
      "endOffset" : 84
    }, {
      "referenceID" : 11,
      "context" : "In terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al.",
      "startOffset" : 68,
      "endOffset" : 170
    }, {
      "referenceID" : 20,
      "context" : "In terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al.",
      "startOffset" : 68,
      "endOffset" : 170
    }, {
      "referenceID" : 18,
      "context" : "In terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al.",
      "startOffset" : 68,
      "endOffset" : 170
    }, {
      "referenceID" : 16,
      "context" : "In terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al.",
      "startOffset" : 68,
      "endOffset" : 170
    }, {
      "referenceID" : 17,
      "context" : "In terms of applications, our work is related to chit-chat dialogue (Li et al., 2016; Vinyals and Le, 2015; Sordoni et al., 2015; Serban et al., 2016; Shang et al., 2015) and task oriented dialogue (Wen et al.",
      "startOffset" : 68,
      "endOffset" : 170
    }, {
      "referenceID" : 23,
      "context" : ", 2015) and task oriented dialogue (Wen et al., 2015; Bordes and Weston, 2016; Williams and Zweig, 2016; Wen et al., 2016).",
      "startOffset" : 35,
      "endOffset" : 122
    }, {
      "referenceID" : 2,
      "context" : ", 2015) and task oriented dialogue (Wen et al., 2015; Bordes and Weston, 2016; Williams and Zweig, 2016; Wen et al., 2016).",
      "startOffset" : 35,
      "endOffset" : 122
    }, {
      "referenceID" : 24,
      "context" : ", 2015) and task oriented dialogue (Wen et al., 2015; Bordes and Weston, 2016; Williams and Zweig, 2016; Wen et al., 2016).",
      "startOffset" : 35,
      "endOffset" : 122
    }, {
      "referenceID" : 22,
      "context" : ", 2015) and task oriented dialogue (Wen et al., 2015; Bordes and Weston, 2016; Williams and Zweig, 2016; Wen et al., 2016).",
      "startOffset" : 35,
      "endOffset" : 122
    }, {
      "referenceID" : 10,
      "context" : "Recipe generation was proposed in (Kiddon et al., 2016).",
      "startOffset" : 34,
      "endOffset" : 55
    }, {
      "referenceID" : 15,
      "context" : "Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text.",
      "startOffset" : 34,
      "endOffset" : 140
    }, {
      "referenceID" : 9,
      "context" : "Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text.",
      "startOffset" : 34,
      "endOffset" : 140
    }, {
      "referenceID" : 15,
      "context" : "Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text.",
      "startOffset" : 34,
      "endOffset" : 140
    }, {
      "referenceID" : 8,
      "context" : "Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text.",
      "startOffset" : 34,
      "endOffset" : 140
    }, {
      "referenceID" : 21,
      "context" : "Context dependent language models (Mikolov et al., 2010; Jozefowicz et al., 2016; Mikolov et al., 2010; Ji et al., 2015; Wang and Cho, 2015) are proposed to capture long term dependency of text.",
      "startOffset" : 34,
      "endOffset" : 140
    }, {
      "referenceID" : 5,
      "context" : "There are also lots of works on coreference resolution (Haghighi and Klein, 2010; Wiseman et al., 2016).",
      "startOffset" : 55,
      "endOffset" : 103
    }, {
      "referenceID" : 25,
      "context" : "There are also lots of works on coreference resolution (Haghighi and Klein, 2010; Wiseman et al., 2016).",
      "startOffset" : 55,
      "endOffset" : 103
    } ],
    "year" : 2017,
    "abstractText" : "We propose a general class of language models that treat reference as discrete stochastic latent variables. This decision allows for the creation of entity mentions by accessing external databases of referents (required by, e.g., dialogue generation) or past internal state (required to explicitly model coreferentiality). Beyond simple copying, our coreference model can additionally refer to a referent using varied mention forms (e.g., a reference to “Jane” can be realized as “she”), a characteristic feature of reference in natural languages. Experiments on three representative applications show our model variants outperform models based on deterministic attention and standard language modeling baselines.",
    "creator" : "TeX"
  }
}