{
  "name" : "1-s2.0-S0004370209000460-main.pdf",
  "metadata" : {
    "source" : "META",
    "title" : "The learnability of voting rules",
    "authors" : [ "Ariel D. Procaccia", "Aviv Zohar", "Yoni Peleg", "Jeffrey S. Rosenschein" ],
    "emails" : [ ],
    "sections" : [ {
      "heading" : null,
      "text" : "Contents lists available at ScienceDirect\nArtificial Intelligence\nwww.elsevier.com/locate/artint\nThe learnability of voting rules ✩\nAriel D. Procaccia a,∗,1, Aviv Zohar b,a, Yoni Peleg b, Jeffrey S. Rosenschein b a Microsoft Israel R&D Center, 13 Shenkar Street, Herzeliya 46725, Israel b School of Computer Science and Engineering, The Hebrew University of Jerusalem, Jerusalem 91904, Israel\na r t i c l e i n f o a b s t r a c t\nArticle history: Received 16 May 2008 Received in revised form 25 March 2009 Accepted 27 March 2009 Available online 9 April 2009\nKeywords: Computational social choice Computational learning theory Multiagent systems\nScoring rules and voting trees are two broad and concisely-representable classes of voting rules; scoring rules award points to alternatives according to their position in the preferences of the voters, while voting trees are iterative procedures that select an alternative based on pairwise comparisons. In this paper, we investigate the PAClearnability of these classes of rules. We demonstrate that the class of scoring rules, as functions from preferences into alternatives, is efficiently learnable in the PAC model. With respect to voting trees, while in general a learning algorithm would require an exponential number of samples, we show that if the number of leaves is polynomial in the size of the set of alternatives, then a polynomial training set suffices. We apply these results in an emerging theory: automated design of voting rules by learning.\n© 2009 Elsevier B.V. All rights reserved."
    }, {
      "heading" : "1. Introduction",
      "text" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].\nIn an election, n voters express their preferences over a set of m alternatives. To be precise, each voter is assumed to reveal linear preferences—a ranking of the alternatives. The outcome of the election is determined according to a voting rule. In this paper we will consider two families of voting rules: scoring rules and voting trees.\nScoring rules. The predominant—ubiquitous, even—voting rule in real-life elections is the Plurality rule. Under Plurality, each voter awards one point to the alternative it ranks first, i.e., its most preferred alternative. The alternative that accumulated the most points, summed over all voters, wins the election. Another example of a voting rule is the Veto rule: each voter “vetoes” a single alternative; the alternative that was vetoed by the fewest voters wins the election. Yet a third example is the Borda rule: every voter awards m − 1 points to its top-ranked alternative, m − 2 points to its second choice, and so forth—the least preferred alternative is not awarded any points. Once again, the alternative with the most points is elected.\nThe above-mentioned three voting rules all belong to an important family of voting rules known as scoring rules. A scoring rule can be expressed by a vector of parameters α = 〈α1,α2, . . . ,αm〉, where each αl is a real number and α1 α2 · · · αm . Each voter awards α1 points to its most-preferred alternative, α2 to its second-most-preferred alternative, etc. Predictably, the alternative with the most points wins. Under this unified framework, we can express our three rules as:\n✩ This paper subsumes two earlier conference papers [A.D. Procaccia, A. Zohar, Y. Peleg, J.S. Rosenschein, Learning voting trees, in: Proceedings of the 22nd AAAI Conference on AI (AAAI), 2007, pp. 110–115; A.D. Procaccia, A. Zohar, J.S. Rosenschein, Automated design of scoring rules by learning from examples, in: Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS), 2008, pp. 951–958].\n* Corresponding author. E-mail addresses: arielpro@gmail.com (A.D. Procaccia), avivz@cs.huji.ac.il (A. Zohar), jonip@cs.huji.ac.il (Y. Peleg), jeff@cs.huji.ac.il (J.S. Rosenschein). 1 The author was supported in this work by the Adams Fellowship Program of the Israel Academy of Sciences and Humanities.\n0004-3702/$ – see front matter © 2009 Elsevier B.V. All rights reserved. doi:10.1016/j.artint.2009.03.003\n• Plurality: α = 〈1,0, . . . ,0〉. • Borda: α = 〈m − 1,m − 2, . . . ,0〉. • Veto: α = 〈1, . . . ,1,0〉.\nA good indication of the importance of scoring rules is given by the fact that they are exactly the family of voting rules that are anonymous (indifferent to the identities of the voters), neutral (indifferent to the identities of the alternatives), and consistent (an alternative that is elected by two separate sets of voters is elected overall) [26].\nVoting trees. Some voting rules rely on the concept of pairwise elections: alternative a beats alternative b in the pairwise election between a and b if the majority2 of voters prefers a to b. Ideally, we would like to select an alternative that beats every other alternative in a pairwise election, but such an alternative (called a Condorcet winner) does not always exist.\nHowever, there are other prominent voting rules that rely on the concept of pairwise elections, which select an alternative in a sense “close” to the Condorcet winner. In the Copeland rule, for example, the score of an alternative is the number of alternatives it beats in a pairwise election; the alternative with the highest score wins. In the Maximin rule, the score of an alternative is the number of votes it gets in its worst pairwise election (the least number of voters that prefer it to some alternative), and, predictably, the winner is the alternative that scores highest.\nWhen discussing such voting rules, it is possible to consider a more abstract setting. A tournament T over A is a complete binary asymmetric relation over A (that is, for any two alternatives a and b, aT b or bT a, but not both). Clearly, the aforementioned majority relation induces a tournament (a beats b in the pairwise election iff aT b). More generally, this relation can reflect a reality that goes beyond a strict voting scenario. For example, the tournament can represent a basketball league, where aT b if team a is expected to beat team b in a game. We denote the set of all tournaments over A by T = T (A).\nSo, for the moment let us look at (pairwise) voting rules as simply functions f : T → A. The most prominent class of such functions is the class of binary voting trees. Each function in the class is represented by a binary tree, with the leaves labeled by alternatives. At each node, the alternatives at the two children compete; the winner ascends to the node (so if a and b compete and aT b, a ascends). The winner-determination procedure starts at the leaves and proceeds upwards towards the root; the alternative that survives to the root is the winner of the election.\nFor example, assume that the alternatives are a, b, and c, and bT a, cT b, and aT c. In the tree given in Fig. 1, b beats a and is subsequently beaten by c in the right subtree, while a beats c in the left subtree. a and c ultimately compete at the root, making a the winner of the election.\nNotice that we allow an alternative to appear in multiple leaves; further, some alternatives may not appear at all (so, for example, a singleton tree is a constant function).\nMotivation and setting. We consider the following setting: an entity, which we refer to as the designer, has in mind a voting rule (which may reflect the ethics of a society). We assume that the designer is able, for each constellation of voters’ preferences with which it is presented, to designate a winning alternative (perhaps with considerable computational effort). In particular, one can think of the designer’s representation of the voting rule as a black box that matches preference profiles to winning alternatives. This setting is relevant, for example, when a designer has in mind different properties it wants its rule to satisfy; in this case, given a preference profile, the designer can specify a winning alternative that is compatible with these properties.\nWe would like to find a concise and easily understandable representation of the voting rule the designer has in mind. We refer to this process as automated design of voting rules: given a specification of properties, or, indeed, of societal ethics, find an elegant voting rule that implements the specification. In this paper, we do so by learning from examples. The designer is presented with different preference profiles, drawn according to a fixed distribution. For each profile, the designer answers with the winning alternative. The number of queries presented to the designer must intuitively be as small as possible: the computations the designer has to carry out in order to handle each query might be complex, and communication might be costly.\n2 We will assume, for simplicity, an odd number of voters.\nNow, we further assume that the “target” voting rule the designer has in mind, i.e., the one given as a black box, is known to belong to some family R of voting rules. We would like to produce a voting rule from R that is as “close” as possible to the target rule.\nBy “close,” we mean close with respect to the fixed distribution over preference profiles. More precisely, we would like to construct an algorithm that receives pairs of the form (preferences, winner) drawn according to a fixed distribution D over preferences, and outputs a rule from R, such that the probability according to D that our rule and the target rule agree is as high as possible. We wish, in fact, to learn rules from R in the framework of the formal PAC (Probably Approximately Correct) learning model; a concise introduction to this model is given in Section 2.\nIn this paper, we look at two options for the choice of R: the family of scoring rules, and the family of voting trees. These are natural choices, since both are broad classes of rules, and both have concise representations. Choosing R as above, the designer could in principle translate the possibly cumbersome, unknown representation of a voting rule into a succinct one that can be easily understood and computed.\nFurther justification for our agenda is given by noting that it might be difficult to compute a voting rule on all instances, but it might be sufficient to simply calculate the election’s result on typical instances. The distribution D can be chosen, by the designer, to concentrate on such instances.\nOur results. The dimension of a function class is a combinatorial measure of the richness of the class; this dimension is closely related to the number of examples needed to learn the class. We give almost tight bounds on the dimension of the class of scoring rules, providing an upper bound of m, and a lower bound of m −3, where m is the number of alternatives in an election. In addition, we show that, given a set of examples, one can efficiently construct a scoring rule that is consistent with the examples, if one exists. Combined, these results imply the following theorem:\nTheorem 3.1. The class of scoring rules over n voters and m alternatives is efficiently learnable for all values of n and m.\nIn other words, given a combination of properties that is satisfied by some scoring rule, it is possible to construct a “close” scoring rule in polynomial time.\nThe situation with respect to the learnability of voting trees is two-fold: in general, due to the expressiveness and possible complexity of binary trees, the number of examples required is exponential in m. However, if we assume that the number of leaves is polynomial in m, then the required number of examples is also polynomial in m. In addition, we investigate the computational complexity of problems associated with the learning process.\nIt is also worthwhile to ask whether it is possible to extend this approach. Specifically, we pose the question: given a class of voting rules R, if the designer has some general voting rule in mind (rather than a voting rule that is known to belong to R), is it possible to learn a “close” rule from R? We prove, for a natural definition of approximation:\nTheorem 5.3. Let Rnm be a family of voting rules of size exponential in n and m. Let , δ > 0. For large enough values of n and m, at least a (1 − δ)-fraction of the voting rules f : Ln → {x1, . . . , xm} satisfy the following property: no voting rule in Rnm is a (1/2 + )- approximation of f .\nIn particular, we show that the theorem holds for scoring rules and small voting trees, thus answering the question posed above in the negative with respect to these classes.\nRelated work. Currently there exists a small body of work on learning in economic settings. Kalai [16] explores the learnability (in the PAC model) of rationalizable choice functions. These are functions which, given a set of alternatives, choose the element that is maximal with respect to some linear order. Similarly, PAC learning has very recently been applied to computing utility functions that are rationalizations of given sequences of prices and demands [2].\nAnother prominent example is the paper by Lahaie and Parkes [17], which considers preference elicitation in combinatorial auctions. The authors show that preference elicitation algorithms can be constructed on the basis of existing learning algorithms. The learning model used, exact learning, differs from ours (PAC learning).\nConitzer and Sandholm [3] have studied automated mechanism design, in the more restricted setting where agents have numerical valuations for different alternatives. They propose automatically designing a truthful mechanism for every preference aggregation setting. However, they find that, under two solution concepts, even determining whether there exists a deterministic mechanism that guarantees a certain social welfare is an N P -complete problem. The authors also show that the problem is tractable when designing a randomized mechanism. In more recent work [5], Conitzer and Sandholm put forward an efficient algorithm for designing deterministic mechanisms, which works only in very limited scenarios. In short, our setting, goals, and methods are completely different—in the general voting context, even framing computational complexity questions is problematic, since the goal cannot be specified with reference to expected social welfare.\nSome authors have studied the computational properties of scoring rules. For instance, Conitzer et al. [6] have investigated the computational complexity of the coalitional manipulation problem in several scoring rules; Procaccia and Rosenschein [21] generalized their results, and finally, Hemaspaandra and Hemaspaandra [14] gave a full characterization. Many other papers deal with the complexity of manipulation and control in elections, and, inter alia, discuss scoring rules (see, e.g., [1,4,8,15,22,27]).\nThe computational properties of voting trees have also been investigated. One prominent example is the work of Lang et al. [18], which studied the computational complexity of selecting different types of winners in elections governed by voting trees. Fischer et al. [10] investigated the power of voting trees in approximating the maximum degree in a tournament.\nStructure of the paper. In Section 2 we give an introduction to the PAC model. In Section 3, we present our results with respect to scoring rules. In Section 4, we investigate voting trees. In Section 5, we discuss a possible extension of our approach. We conclude in Section 6."
    }, {
      "heading" : "2. Preliminaries",
      "text" : "In this section we give a very short introduction to the PAC model and the generalized dimension of a function class. A more comprehensive (and slightly more formal) overview of the model, and results concerning the dimension, can be found in [20].\nIn the PAC model, the learner is attempting to learn a function f : Z → Y , which belongs to a class F of functions from Z to Y . The learner is given a training set—a set {z1, z2, . . . , zt} of points in Z , which are sampled i.i.d. (independently and identically distributed) according to a distribution D over the sample space Z . D is unknown, but is fixed throughout the learning process. In this paper, we assume the “realizable” case, where a target function f ∗(z) exists, and the given training examples are in fact labeled by the target function: {(zk, f ∗(zk))}tk=1. The error of a function f ∈ F is defined as\nerr( f ) = Pr z∼D\n[ f (z) = f ∗(z)]. (1)\n> 0 is a parameter given to the learner that defines the accuracy of the learning process: we would like to achieve err(h) . Notice that err( f ∗) = 0. The learner is also given a confidence parameter δ > 0, that provides an upper bound on the probability that err(h) > :\nPr [ err(h) > ] < δ. (2)\nWe now formalize the discussion above:\nDefinition 2.1. (See [20].)\n1. A learning algorithm L is a function from the set of all training examples to F with the following property: given , δ ∈ (0,1) there exists an integer s( , δ)—the sample complexity—such that for any distribution D on X , if Z is a sample of size at least s where the samples are drawn i.i.d. according to D , then with probability at least 1 − δ it holds that err(L(Z)) . 2. L is an efficient learning algorithm if it always runs in time polynomial in 1/ , 1/δ, and the size of the representations of the target function, of elements in X , and of elements in Y . 3. A function class F is (efficiently) PAC-learnable if there is an (efficient) learning algorithm for F .\nThe sample complexity of a learning algorithm for F is closely related to a measure of the class’s combinatorial richness known as the generalized dimension.\nDefinition 2.2. (See [20].) Let F be a class of functions from Z to Y . We say F shatters S ⊆ Z if there exist two functions f , g ∈ F such that\n1. For all z ∈ S , f (z) = g(z). 2. For all S1 ⊆ S , there exists h ∈ F such that for all z ∈ S1, h(z) = f (z), and for all z ∈ S \\ S1, h(z) = g(z).\nDefinition 2.3. (See [20].) Let F be a class of functions from a set Z to a set Y . The generalized dimension of F , denoted by DG(F ), is the greatest integer d such that there exists a set of cardinality d that is shattered by F .\nLemma 2.4. (See [20, Lemma 5.1].) Let Z and Y be two finite sets and let F be a set of total functions from Z to Y . If d = DG(F ), then 2d |F |.\nA function’s generalized dimension provides both upper and lower bounds on the sample complexity of algorithms.\nTheorem 2.5. (See [20, Theorem 5.1].) Let F be a class of functions from Z to Y of generalized dimension d. Let L be an algorithm such that, when given a set of t labeled examples {(zk, f ∗(zk))}k of some f ∗ ∈ F , sampled i.i.d. according to some fixed but unknown distribution over the instance space X, produces an output f ∈ F that is consistent with the training set. Then L is an ( , δ)-learning algorithm for F provided that the sample size obeys:\ns 1 ( (σ1 + σ2 + 3)d ln 2 + ln ( 1\nδ\n)) (3)\nwhere σ1 and σ2 are the sizes of the representation of elements in Z and Y , respectively.\nTheorem 2.6. (See [20, Theorem 5.2].) Let F be a function class of generalized dimension d 8. Then any ( , δ)-learning algorithm for F , where 1/8 and δ < 1/4, must use sample size s d16 ."
    }, {
      "heading" : "3. Learnability of scoring rules",
      "text" : "Before diving in, we introduce some notation. Let N = {1,2, . . . ,n} be the set of voters, and let A = {x1, x2, . . . , xm} be the set of alternatives; we also denote alternatives by {a,b, c, . . .}. Let L = L(A) be the set of linear preferences3 over A; each voter has preferences i ∈ L. We denote the preference profile, consisting of the voters’ preferences, by N = 〈 1, 2 , . . . , n〉. A voting rule is a function f : LN → A, that maps preference profiles to winning alternatives.\nLet α be a vector of m nonnegative real numbers such that αl αl+1 for all l = 1, . . . ,m − 1. Let f α : LN → C be the scoring rule defined by the vector α, i.e., each voter awards αl points to the alternative it ranks in the lth place, and the rule elects the alternative with the most points.\nSince several alternatives may have maximal scores in an election, we must adopt some method of tie-breaking. Our method works as follows. Ties are broken in favor of the alternative that was ranked first by more voters; if several alternatives have maximal scores and were ranked first by the same number of voters, the tie is broken in favor of the alternative that was ranked second by more voters; and so on.4\nLet S nm be the class of scoring rules with n voters and m alternatives. Our goal is to learn, in the PAC model, some target function f α∗ ∈ S nm . To this end, the learner receives a training set {( Nk , f α∗ ( Nk )}k , where each Nk is drawn from a fixed distribution over LN ; let x jk = f α∗ ( Nk ). For the profile Nk , we denote by πkj,l the number of voters that ranked alternative x j in place l. Notice that alternative x j ’s score under the preference profile Nk is ∑ l π k j,lαl ."
    }, {
      "heading" : "3.1. Efficient learnability of S nm",
      "text" : "Our main goal in this section is to prove the following theorem.\nTheorem 3.1. For all n,m ∈ N, the class S nm is efficiently PAC-learnable.\nBy Theorem 2.5, in order to prove Theorem 3.1 it is sufficient to validate the following two claims: 1) that there exists an algorithm which, for any training set, runs in time polynomial in n, m, and the size of the training set, and outputs a scoring rule which is consistent with the training set (assuming one exists); and 2) that the generalized dimension of the class S nm is polynomial in n and m.\nRemark 3.2. It is possible to prove Theorem 3.1 by using a transformation between scoring rules and sets of linear threshold functions. Indeed, it is well known that the VC dimension (the restriction of the generalized dimension to boolean-valued functions) of linear threshold functions over Rd is d + 1. In principle, it is possible to transform a scoring rule into a linear threshold function that receives (generally speaking) vectors of rankings of alternatives as input. Given a training set of profiles, we could transform it into a training set of rankings and use a learning algorithm.\nHowever, we are interested in producing an accurate scoring rule according to a distribution D on preference profiles, which represents typical profiles. It is possible to consider a many-to-one mapping between distributions over profiles and distributions over the above-mentioned vectors of rankings. Unfortunately, when this procedure is used, it is nontrivial to guarantee that the learned voting rule succeeds according to the original distribution D . Moreover, this procedure seems to require an increase in sample complexity compared to the analysis given below. Therefore, we proceed with the more “direct” agenda outlined above and detailed below.\nIt is rather straightforward to construct an efficient algorithm that outputs consistent scoring rules. Given a training set, we must choose the parameters of our scoring rule in a way that, for any example, the score of the designated winner is at least as large as the scores of other alternatives. Moreover, if ties between the winner and a loser would be broken in favor of the loser, then the winner’s score must be strictly higher than the loser’s. Our algorithm, given as Algorithm 1, simply formulates all the constraints as linear inequalities, and solves the resulting linear program. The first part of the algorithm is meant to handle tie-breaking. Recall that x jk = f α∗ ( Nk ).\nA linear program can be solved in time that is polynomial in the number of variables and inequalities [24]; it follows that Algorithm 1’s running time is polynomial in n, m, and the size of the training set.\nRemark 3.3. Notice that any vector α with a “standard” representation, that is with rational coordinates such that both numerator and denominator are integers represented by a polynomial number of bits, can be scaled to an equivalent vector\n3 A binary relation which is antisymmetric, transitive, and total. 4 In case several alternatives have maximal scores and identical rankings everywhere, break ties arbitrarily—say, in favor of the alternative with the\nsmallest index.\nfor k ← 1 . . . s do Xk ← ∅ for all x j = x jk do x jk is the winner in example k\nπ ← πkjk − πkj l0 ← min{l: π l = 0} if π l0 < 0 then Ties are broken in favor of x j\nXk ← Xk ∪ {x j} end if\nend for end for return a feasible solution α to the following linear program:\n∀k, ∀x j ∈ Xk,∑l πkjk ,lαl ∑ l π k j,lαl + 1\n∀k, ∀x j /∈ Xk,∑l πkjk ,lαl ∑ l π k j,lαl ∀l = 1, . . . ,m − 1 αl αl+1 ∀l, αl 0\nAlgorithm 1. Given a training set of size s, the algorithm returns a scoring rule which is consistent with the given examples, if one exists.\nof integers which is also polynomially representable. In this case, the scores are always integral. Thus, instead of using a strict inequality in the LP’s first set of constraints, we can use a weak inequality with an additive term of 1.\nRemark 3.4. Although the transformation between learning scoring rules and learning linear threshold functions mentioned in Remark 3.2 has some drawbacks as a learning method, we conjecture that results on the computational complexity of learning linear threshold functions can be leveraged to obtain computational efficiency. Indeed, well-known algorithms such as Winnow [19] might suit this purpose.\nRemark 3.5. Algorithm 1 can also be used to check, with high probability, if the voting rule the designer has in mind is indeed a scoring rule, as described (in a different context) by Kalai [16] (we omit the details here). This further justifies the setting in which the voting rule the designer has in mind is known to be a scoring rule.\nSo, it remains to demonstrate that the generalized dimension of S nm is polynomial in n and m. The following lemma shows this.\nLemma 3.6. The generalized dimension of the class S nm is at most m: DG ( S nm ) m.\nProof. According to Definition 2.3, we need to show that any set of cardinality m + 1 cannot be shattered by S nm . Let S = { Nk }m+1k=1 be such a set, and let h, g be the two social choice functions that disagree on all preference profiles in S . We shall construct a subset S1 ⊆ S such that there is no scoring rule f α that agrees with h on S1 and agrees with g on S \\ S1.\nLet us look at the first preference profile from our set, N1 . We shall assume without loss of generality that h( N1 ) = x1, while g( N1 ) = x2, and that in N1 ties between x1 and x2 are broken in favor of x1. Let α be some parameter vector. If we are to have h( N1 ) = f α( N1 ), it must hold that\nm∑ l=1 π11,l · αl m∑ l=1 π12,l · αl, (4)\nwhereas if we wanted f α to agree with g we would want the opposite: m∑\nl=1 π11,l · αl < m∑ l=1 π12,l · αl. (5)\nMore generally, we define, with respect to the profile Nk , the vector πk as the vector whose lth coordinate is the difference between the number of times the winner under h and the winner under g were ranked in the lth place:5\nπk = πkh( k) − πkg( k). (6) Now we can concisely write necessary conditions for f α agreeing on Nk with h or g , respectively, by writing:6\n5 There is some abuse of notation here; if h( Nk ) = xl then by πkh( k) we mean πkl . 6 In all profiles except N1 , we are indifferent to the direction in which ties are broken.\nπk · α 0, (7) πk · α 0. (8)\nNotice that each vector πk has exactly m coordinates. Since we have m + 1 such vectors (corresponding to the m + 1 profiles in S), there must be a subset of vectors that is linearly dependent. We can therefore express one of the vectors as a linear combination of the others. Without loss of generality, we assume that the first profile’s vector can be written as a combination of the others with parameters βk , not all 0:\nπ1 = m+1∑ k=2 βk · πk . (9)\nNow, we shall construct our subset S1 of preference profiles as follows:\nS1 = { k ∈ {2, . . . ,m + 1}: βk 0 } . (10)\nSuppose, by way of contradiction, that f α agrees with h on Nk for k ∈ S1, and with g on the rest. We shall examine the value of π1 · α:\nπ1 · α = m+1∑ k=2 βk · πk · α = ∑ k∈S1 βk · πk · α + ∑ k/∈S1∪{1} βk · πk · α 0. (11)\nThe last inequality is due to the construction of S1—whenever βk is negative, the sign of πk · α is nonpositive ( f α agrees with g), and whenever βk is positive, the sign of πk · α is nonnegative (agreement with h).\nTherefore, by Eq. (5), we have that f ( N1 ) = x2 = g( N1 ). However, it holds that 1 /∈ S1, and we assumed that f α agrees with g outside S1—this is a contradiction.\nTheorem 3.1 is thus proven. The upper bound on the generalized dimension of Snm is quite tight: in the next subsection we show a lower bound of m − 3."
    }, {
      "heading" : "3.2. Lower bound for the generalized dimension of S nm",
      "text" : "Theorem 2.6 implies that a lower bound on the generalized dimension of a function class is directly connected to the complexity of learning it. In particular, a tight bound on the dimension gives us an almost exact idea of the number of examples required to learn a scoring rule. Therefore, we wish to bound DG(S nm) from below as well.\nTheorem 3.7. For all n 4, m 4, DG(S nm) m − 3.\nProof. We shall produce an example set of size m − 3 which is shattered by S nm . Define a preference profile Nl , for l = 3, . . . ,m − 1, as follows. For all l, the voters 1, . . . ,n − 1 rank alternative x j in place j, i.e., they vote x1 il x2 il · · · il xm . The preferences nl (the preferences of voter n in profile Nl ) are defined as follows: alternative x2 is ranked in place l, alternative x1 is ranked in place l + 1; the other alternatives are ranked arbitrarily by voter n. For example, if m = 5, n = 6, the preference profile N3 is:\n13 23 33 43 53 63 x1 x1 x1 x1 x1 x3 x2 x2 x2 x2 x2 x4 x3 x3 x3 x3 x3 x2 x4 x4 x4 x4 x4 x1 x5 x5 x5 x5 x5 x5\nLemma 3.8. For any scoring rule f α with α1 = α2 2α3 it holds that:\nf α ( Nl ) = { x1 αl = αl+1, x2 αl > αl+1.\nProof. We shall first verify that x2 has maximal score. x2’s score is at least (n − 1)α2 = (n − 1)α1. Let j 3; x j ’s score is at most (n − 1)α3 + α1. Thus, the difference is at least (n − 1)(α1 − α3) − α1. Since α1 = α2 2α3, this is at least (n − 1)(α1/2) − α1 > 0, where the last inequality holds for n 4.\nNow, under preference profile Nl , x1’s score is (n − 1)α1 + αl+1 and x2’s score is (n − 1)α1 + αl . If αl = αl+1, the two alternatives have identical scores, but x1 was ranked first by more voters (in fact, by n − 1 voters), and thus the winner is x1. If αl > αl+1, then x2’s score is strictly higher—hence in this case x2 is the winner.\nArmed with Lemma 3.8, we will now prove that the set { Nl }m−1l=3 is shattered by S nm . Let α1 be such that α11 = α12 2α13 = 2α14 = · · · = 2α1m , and α2 be such that α11 = α12 2α13 > 2α14 > · · · > 2α1m . By the lemma, for all l = 3, . . . ,m − 1, f α1 ( Nl ) = x1, and f α2 ( Nl ) = x2.\nLet T ⊆ {3,4, . . . ,m − 1}. We must show that there exists α such that f α( Nl ) = x1 for all l ∈ T , and f α( Nl ) = x2 for all l /∈ T . Indeed, configure the parameters such that α1 = α2 > 2α3, and αl = αl+1 iff l ∈ T . The result follows directly from Lemma 3.8."
    }, {
      "heading" : "4. Learnability of voting trees",
      "text" : "Recall that we are dealing with a set of alternatives A = {x1, . . . , xm}; as before, we will also denote alternatives by a,b, c ∈ A. A tournament is a complete binary irreflexive relation T over A; we denote the set of all possible tournaments by T = T (A).\nA binary voting tree is a binary tree with leaves labeled by alternatives. To determine the winner of the election with respect to a tournament T , one must iteratively select two siblings, label their parent by the winner according to T , and remove the siblings from the tree. This process is repeated until the root is labeled, and its label is the winner of the election.\nA preference profile N of a set of voters N induces a tournament T ∈ T (A) as follows: aT b (i.e., a dominates b) if and only if a majority of voters prefer a to b. Thus, a voting tree is in particular a voting rule, as defined in Section 3. However, for the purposes of this section it is sufficient to regard voting trees as functions f : T (A) → A, that is, we will disregard the set of voters and simply consider the dominance relation T on A. We shall hereinafter refer to functions f : T (A) → A as pairwise voting rules.\nLet us therefore denote the class of voting trees over m alternatives by Vm; we emphasize the class depends only on m. We would like to know what the sample complexity of learning functions in Vm is. To elaborate a bit, since we think of voting trees as functions from T to A, the sample space is T ."
    }, {
      "heading" : "4.1. Large voting trees",
      "text" : "In this section, we will show that in general, the answer to the above question is that the complexity is exponential in m. We will prove this by relying on Theorem 2.6; the theorem implies that in order to prove such a claim, it is sufficient to demonstrate that the generalized dimension of Vm is at least exponential in m. This is the task we presently turn to.\nTheorem 4.1. DG(Vm) is exponential in m.\nProof. Without loss of generality, we let m = 2k + 2. We will associate every distinct binary vector v = 〈v1, . . . , vk〉 ∈ {0,1}k with a distinct example in our set of tournaments S ⊆ T . To prove the theorem, we will show that Vm shatters this set S of size 2k .\nLet the set of alternatives be:\nA = {a,b, x01, x11, x02, x12, . . . , x0k , x1k}. For every vector v ∈ {0,1}k , define a tournament T v as follows: for i = 1, . . . ,k, if vi = 0, we let x0i T vbT v x1i ; otherwise, if vi = 1, then x1i T vbT v x0i . In addition, for all tournaments T v , and all i = 1, . . . ,k, j = 0,1, a beats x ji , but a loses to b. We denote by S the set of these 2k tournaments.7 Let f be the constant function b, i.e., a voting tree which consists of only the node b; let g be the constant function a. We must prove that for every S1 ⊆ S , there is a voting tree such that b wins for every tournament in S1 (in other words, the tree agrees with f ), and a wins for every tournament in S \\ S1 (the tree agrees with g). Consider the tree in Fig. 2, which we refer to as the ith 2-gadget.\n7 The relations described above are not complete, but the way they are completed is of no consequence.\nWith respect to this tree, b wins a tournament T v ∈ S iff vi = j. Indeed, if vi = j, then x ji T vbT v x1− ji , and in particular b beats x1− ji ; if vi = j, then x1− ji T vbT v x ji , so b loses to x1− ji .\nLet v ∈ {0,1}k . We will now use the 2-gadget to build a tree where b wins only the tournament T v ∈ S , and loses every other tournament in S . Consider a balanced tree such that the deepest nodes in the tree are in fact 2-gadgets (as in Fig. 3). As before, b wins in the ith 2-gadget iff vi = j. We will refer to this tree as a v-gadget.\nNow, notice that if b wins in each of the 2-gadgets (and this is the case in the tournament T v ), then b is the winner of the entire election. On the other hand, let v ′ = v , i.e., there exists i ∈ {1, . . . ,k} such that w.l.o.g. 0 = v ′i = vi = 1. Then it holds that x0i T v ′bT v ′ x 1 i ; this implies that x 0 i wins in the ith 2-gadget. x 0 i proceeds to win the entire election, unless it is beaten in some stage by some other alternative x jl —but this must be also an alternative that beats b, as it survived the lth 2-gadget. In any case, b cannot win the election.\nConsider the small extension, in Fig. 4, of the v-gadget, which (for lack of a better name) we call the v-gadget∗ . Recall that, in every tournament in S , a beats any alternative xij but loses to b. Therefore, by our discussion regarding the v-gadget, b wins the election described by the v-gadget∗ only in the tournament T v ; for any other tournament in S , alternative a wins the election.\nWe now present a tree and prove that it is as required, i.e., in any tournament in S1, b is the winner, and in any tournament in S \\ S1, a prevails. Let us enumerate the tournaments in S1:\nS1 = {T v1 , . . . , T vr }. We construct a balanced tree, as in Fig. 5, where the bottom levels consist of the vl-gadgets*, for l = 1, . . . , r.\nLet T vl ∈ S1. What is the result of this tournament in the election described by this tree? First, note that b prevails in the vl-gadget∗ . The only alternatives that can reach any level above the gadgets are a and b, and b always beats a. Therefore, b proceeds to win the election. Conversely, let T v ∈ S \\ S1. Then a survives in every vl-gadget∗ , for l = 1, . . . , r. a surely proceeds to win the entire election.\nWe have shown that Vm shatters S , thus completing the proof. Remark 4.2. Even if we restrict our attention to the class of balanced voting trees (corresponding to a playoff schedule), the dimension of the class is still exponential in m. Indeed, any unbalanced tree can be transformed to an identical (as a voting rule) balanced tree. If the tree’s height is h, this can be done by replacing every leaf at depth d < h, labeled by an alternative a, by a balanced subtree of height d − h in which all the leaves are labeled by a. This implies that the class of balanced trees can shatter any sample which is shattered by Vm .\nRemark 4.3. The proof we have just completed, along with Lemma 2.4, imply that the number of different pairwise voting rules that can be represented by trees is double exponential in m, which highlights the high expressiveness of voting trees.\nTheorem 4.1, coupled with Theorem 2.6, implies that the sample complexity of learning arbitrary voting trees is exponential in n and m."
    }, {
      "heading" : "4.2. Small voting trees",
      "text" : "In the previous section, we have seen that in general, a large number of examples is needed in order to learn voting trees in the PAC model. This result relied on the number of leaves in the trees being exponential in the number of alternatives. However, in many realistic settings one can expect the voting tree to be compactly represented, and in particular one can usually expect the number of leaves to be at most polynomial in m. Let us denote by V (k)m the class of voting trees over m alternatives, with at most k leaves. Our goal in this section is to prove the following theorem.\nTheorem 4.4. DG(V (k)m ) = O(k log m).\nThis theorem implies, in particular, that if the number of leaves k is polynomial in m, then the dimension of V (k)m is polynomial in m. In turn, this implies by Lemma 2.5 that the sample complexity of V (k)m is only polynomial in m. In other words, there is a polynomial p(m,1/ ,1/δ) such that, given a training set of size p(m,1/ ,1/δ), any algorithm that returns some tree consistent with the training set is an ( , δ)-learning algorithm for V (k)m .\nTo prove the theorem, we require the following straightforward lemma.\nLemma 4.5. |V (k)m | k · mk · Ck−1 , where Ck is the kth Catalan number, given by\nCk = 1k + 1 ( 2k k ) .\nProof. The number of voting trees with exactly k leaves is at most the number of binary tree structures multiplied by the number of possible assignments of alternatives to leaves. The number of assignments is clearly bounded by mk . Moreover, it is well known that the number of rooted ordered binary trees with k leaves is the (k − 1) Catalan number. So, the total number of voting trees with exactly k leaves is bounded by mk · Ck−1, and the number of voting trees with at most k leaves is at most k · mk · Ck−1.\nWe are now ready to prove Theorem 4.4.\nProof of Theorem 4.4. By Lemma 4.5, we have that∣∣V (k)m ∣∣ k · mk · Ck−1. Therefore, by Lemma 2.4:\nDG ( V (k)m ) log ∣∣V (k)m ∣∣ = O(k log m)."
    }, {
      "heading" : "4.3. Computational complexity",
      "text" : "In the previous section, we restricted our attention to voting trees where the number of leaves is polynomial in k. We have demonstrated that the dimension of this class is polynomial in m, which implies that the sample complexity of the\nclass is polynomial in m. Therefore, any algorithm that is consistent with a training set of polynomial size is a suitable learning algorithm (Theorem 2.5).\nIt seems that the significant bottleneck, especially in the setting of automated voting rule design (finding a compact representation for a voting rule that the designer has in mind), is the number of queries posed to the designer, so in this regard we are satisfied that realistic voting trees are learnable. Nonetheless, in some contexts we may also be interested in computational complexity: given a training set of polynomial size, how computationally hard is it to find a voting tree which is consistent with the training set?\nIn this section we explore the above question. We will assume hereinafter that the structure of the voting tree is known a priori. This is an assumption that we did not make before, but observe that, at least for balanced trees, Theorems 4.1 and 4.4 hold regardless. We shall try to determine how hard it is to find an assignment to the leaves which is consistent with the training set. We will refer to the computational problem as Tree-SAT (pun intended).\nDefinition 4.6. In the Tree-SAT problem, we are given a binary tree, where some of the leaves are already labeled by alternatives, and a training set that consists of pairs (T j ,xi j ), where T j ∈ T and xi j ∈ A. We are asked whether there exists an assignment of alternatives to the rest of the leaves which is consistent with the training set, i.e., for all j, the winner in T j with respect to the tree is xi j .\nNotice that in our formulation of the problem, some of the leaves are already labeled. However, it is reasonable to expect any efficient algorithm that finds a consistent tree, given that one exists, to be able to solve the Tree-SAT problem. Hence, an N P -hardness result implies that such an algorithm is not likely to exist.\nTheorem 4.7. Tree-Sat is N P -complete.\nProof. It is obvious that Tree-SAT is in N P . In order to show N P -hardness, we present a reduction from 3SAT. In this problem, one is given a conjunction of clauses, where each clause is a disjunction of three literals. One is asked whether the given formula has a satisfying assignment. It is known that 3SAT is N P -complete [11].\nGiven an instance of 3SAT with variables {x1, . . . , xm}, and clauses {l j1 ∨ l j2 ∨ l j3}kj=1, we construct an instance of Tree-Sat as follows: the set of alternatives is\nA = {a,b, x1,¬x1, c1, x2,¬x2, c2, . . . , xm,¬xm, cm}. For each clause j, we define a tournament T j as some tournament that satisfies the following restrictions:\n1. l j1, l j 2 and l j 3 beat any other alternative among the alternatives xi,¬xi , possibly excluding their own negations. 2. a loses to l j1, l j 2 and l j 3, but beats any other alternative among the alternatives xi,¬xi .\nIn addition, all tournaments in our instance of Tree-SAT satisfy the following conditions:\n1. b beats any alternative which corresponds to a literal, but loses to a. 2. For all i = 1, . . . ,m, ¬xi beats xi . 3. ci loses to xi and ¬xi , and beats any other literal and the alternatives a and b. The tournaments are arbitrarily defined\nwith respect to competitions between ci and ck , i = k.\nFinally, for each tournament, we require the winner to be alternative b. We now proceed to construct the given (partially assigned) tree. We start, as in the proof of Theorem 4.1, by defining a gadget which we call an i-gadget, illustrated in Fig. 6.\nIn this subtree, two leaves are already assigned with xi and ci . Now, with respect to any of the tournaments we defined, if we assign ¬xi to the last leaf, then ¬xi proceeds to beat ci , and subsequently beats xi . If we assign xi to the third leaf, then xi beats ci and wins the election. If we assign any other alternative that is not ck for some k = 1, . . . ,m, then that alternative is defeated by ci , which in turn is beaten by xi . Finally, if ck is assigned, it either loses to ci and then xi is the winner, or it beats ci and proceeds to beat xi . To conclude the point, either xi , ¬xi , or ck for some k = i survive the i-gadget.\nUsing the i-gadgets, we design a tree that will complete the construction of our Tree-SAT instance; the tree is described in Fig. 7.\nWe now prove that this is indeed a reduction. We first have to show that if the given 3SAT instance is satisfiable, there is an assignment to the leaves of our tree (in particular, choices of xi or ¬xi ) such that, for each of the m tournaments, the winner is b. Consider some satisfying assignment to the 3SAT instance. For every literal li that is assigned a truth value, we assign the label li to the unlabeled leaf of the i-gadget, i.e., we make li survive the i-gadget. Now, consider some tournament T j . At least one of the literals l j 1, l j 2 or l j 3 must be true; as these three literals beat all other literals in the tournament T j , one of these three literals reaches the competition versus a, and wins; subsequently, this literal loses to alternative b. Therefore, b is the winner of the election. Since this is true for any j = 1, . . . ,m, we have that the assignment is consistent with the given tournaments.\nIn the other direction, consider an instance of 3SAT which is not satisfiable, and fix some assignment to the leaves of the tree. A first case that we consider is that under this assignment, ck survives some i-gadget, i = k. ck cannot be beaten on the way to the root of the tree, except by another c alternative. Hence, b does not win in any of the constructed tournaments.\nA second case to consider is that for each i-gadget, either xi or ¬xi survives. The corresponding assignment to the 3SAT instance is not satisfying. Therefore, there is some j such that l j1, l j 2, and l j 3 are all false. This implies that in T j some other literal other than these three reaches the top of the tree to compete against a, and loses. Subsequently, a competes against b and wins, making a the winner of the election with respect to tournament T j . Hence, this is not an assignment which is consistent with all tournaments—but this is true with respect to any such assignment.\nDespite Theorem 4.7, it seems that in practice, solving the Tree-Sat problem is sometimes possible; we shall empirically demonstrate this.\nOur simulations were carried out as follows. Given a fixed tree structure, we randomly assigned alternatives (out of a pool of 32 alternatives) to the leaves of the tree. We then used this tree to determine the winners in 20 random tournaments over our 32 alternatives. Next, we measured the time it took to find some assignment to the leaves of the tree (not necessarily the original one) which is consistent with the training set of 20 tournaments. We repeated this procedure 10 times for each number of leaves in {4,8,16,32,64}, and took the average of all ten runs.\nThe problem of finding a consistent tree can easily be represented as a constraint satisfaction problem, or in particular as a SAT problem. Indeed, for every node, one simply has to add one constraint per tournament which involves the node and its two children. To find a satisfying assignment, we used the SAT solver zChaff. The simulations were carried out on a PC with a Pentium D (dual core) CPU, running Linux, with 2 GB of RAM and a 2.8 GHz clock speed.\nWe experimented with two different tree structures. The first is seemingly the simplest—a binary tree which is as close to a chain as possible, i.e., every node is either a leaf, or the parent of a leaf; we refer to these trees as caterpillars. The second is intuitively the most complicated: a balanced tree. Notice that, given that the number of leaves is k, the number of nodes in both cases is 2k − 1. The simulation results are shown in Fig. 8.\nIn the case of balanced trees, it is indeed hard to find a consistent tree. Adding more sample tournaments would add even more constraints and make the task harder. However, in most elections the number of alternatives is usually not above several dozen, and the problem may still be solvable. Furthermore, the problem is far easier with respect to caterpillars (even though the reduction in Theorem 4.7 builds trees that are “almost caterpillars”). Therefore, we surmise that for many tree structures, it may be practically possible (in terms of the computational effort) to find a consistent assignment, even when the input is relatively large, while for others the problem is quite computationally hard even in practice."
    }, {
      "heading" : "5. On learning voting rules “close” to target rules",
      "text" : "Heretofore, we have concentrated on learning voting rules that are known to be either scoring rules or voting trees. In particular, we have assumed that there is a scoring rule or a voting tree that is consistent with the given training set.\nIn this section, we push the envelope by asking the following question: given examples that are consistent with some general voting rule, is it possible to learn a scoring rule or a small voting tree that is “close” to the target rule?\nMathematically we are actually asking whether there exist target voting rules f ∗ such that min f α∈S nm err( f α), or min f ∈V ∗m err( f ), is large. This of course depends on the underlying distribution D . In the rest of this section, the implicit assumption is that D is the simplest nontrivial distribution over profiles, namely the uniform distribution. Nevertheless, the uniform distribution usually does not reflect real preferences of voters; this is an assumption we are making for the sake of analysis. In light of this discussion, the definition of distance between voting rules is going to be the fraction of preference profiles on which the two rules disagree.\nDefinition 5.1. A voting rule f : LN → A is a c-approximation of a voting rule g iff f and g agree on a c-fraction of the possible preference profiles:∣∣{ N∈ LN : f ( N) = g( N)}∣∣ c · (m!)n.\nIn other words, the question is: given a training set {( Nk , f ( Nj )}k , where f : LN → A is some voting rule, how hard is it to learn a scoring rule or a voting tree that c-approximates f , for c that is close to 1?\nIt turns out that the answer is: it is impossible. We shall first give an extreme example for the case of scoring rules. Indeed, there are voting rules that disagree with any scoring rule on almost all of the preference profiles; if the target rule f is such a rule, it is impossible to find, and of course impossible to learn, a scoring rule that is “close” to f .\nIn order to see this, consider the following voting rule that we call flipped veto: each voter awards one point to the alternative it ranks last; the winner is the alternative with the most points. In addition, ties are broken according to the lexicographic order on alternative names. This rule is of course not reasonable as a preference aggregation method, but still—it is a valid voting rule.\nProposition 5.2. Let f α be a scoring rule that is a c-approximation of flipped veto. Then c 1/m.\nProof. Let N be a preference profile such that f α( N ) = flipped veto( N) = x∗ , for some x∗ ∈ A. Define a set B N ⊆ LN as follows: each profile in the set is obtained by switching the place of an alternative x ∈ A, x = x∗ , with the place of x∗ , in the ordering of each voter that did not rank x∗ last.8 For a preference profile N1 ∈ B N that was obtained by switching x with x∗ , it holds that the winner under flipped veto is x∗ , since its score did not decrease as a result of the switches, while its situation in terms of tie-breaking remained the same (that is, its name did not change). In addition, under f α the situation of x in N1 , with respect to score and tie-breaking, is at least as good as the situation of x∗ in N (voters that have not switched the two alternatives are ones that rank x∗ last, and the score of the other alternatives remains unchanged).\n8 It cannot be the case that all voters ranked x∗ last, by our tie-breaking assumption with respect to f α .\nNote that it might be the case that x and x∗ have the same score under N1 ; however, since flipped veto( N ) = x∗ it holds that x∗ is ranked last by at least one voter in N , and hence in f α( N1 ) ties between x and x∗ are broken in favor of x. It follows that f α( N1 ) = x. Therefore, for any preference profile in B N , f α and flipped veto do not agree.\nWe claim that for any two preference profiles N1 and N2 on which f α and flipped veto agree, it holds that B N1 ∩ B N2 = ∅. Indeed, assume that there exists N∈ B N1 ∩ B N2 . Assume first that the winner in both profiles is x ∗ . It cannot be the case that the same alternative was switched with x∗ in order to obtain N from both N1 and N2 —that would imply N1 and N2 are identical. Therefore, assume w.l.o.g. that x1 was switched with x∗ in N1 (only in the rankings of voters that did not rank x∗ last), and x2 was switched with x∗ in N2 . But this means that both x1 and x2 are winners in N under f α (by the fact that x∗ was a winner in both N1 and N2 )—a contradiction.\nIn addition, in any two preference profiles N1 and N2 such that f α\n( N1 ) = flipped veto( N1 ) = x∗, and\nf α ( N2 ) = flipped veto( N2 ) = x∗∗,\nit holds that B N1 ∩ B N2 = ∅, as flipped veto elects x ∗ in all profiles in B N1 , but elects x ∗∗ in all profiles in B N2 . It follows that for every preference profile on which f α and flipped veto agree, there are at least m − 1 distinct profiles on which the two voting rules disagree; this proves the proposition. We shall now formulate our main result for this section. The theorem states that almost every voting rule cannot be approximated by a factor better than 12 by any small family of voting rules. We shall subsequently see that the theorem holds for small voting trees as well as scoring rules.\nTheorem 5.3. Let Rnm be a family of voting rules of size exponential in n and m, and let , δ > 0. For large enough values of n and m, at least a (1 − δ)-fraction of the voting rules f : Ln → {x1, . . . , xm} satisfy the following property: no voting rule in Rnm is a (1/2 + )- approximation of f .\nProof. We will surround each voting rule f ∈ Rnm with a “ball” B( f ), which contains all the voting rules for which f is a (1/2 + )-approximation. We will then show that the union of all these balls covers at most a δ-fraction of the set of the space of voting rules. This implies that for at least a (1 − δ)-fraction of the voting rules, no scoring rule is a (1/2 + )- approximation.\nFor a given f , what is the size of B( f )? As there are (m!)n possible preference profiles, the ball contains rules that do not agree with f on at most (1/2 − )(m!)n preference profiles. For a profile on which there is disagreement, there are m options to set the image under the disagreeing rule.9 Therefore,\n∣∣B( f )∣∣ (\n(m!)n (1/2 − )(m!)n\n) m(1/2− )(m!)n . (12)\nHow large is this expression? Let B ′( f ) be the set of all voting rules that disagree with f on exactly (1/2 + )(m!)n preference profiles. It holds that\n∣∣B ′( f )∣∣ = (\n(m!)n (1/2 + )(m!)n\n) (m − 1)(1/2+ )(m!)n\n= (\n(m!)n (1/2 − )(m!)n\n)( (m − 1)1+2 )1/2(m!)n\n(\n(m!)n (1/2 − )(m!)n\n) m1/2(m!)n , (13)\nwhere the last inequality holds for a large enough m. But since the total number of voting rules, m(m!)n , is greater than the number of rules in B ′( f ), we have:\nm(m!)n\nB( f ) B ′( f ) B( f )\n(\n(m!)n (1/2− )(m!)n ) m1/2(m!)n(\n(m!)n (1/2− )(m!)n\n) m(1/2− )(m!)n = m (m!)n . (14)\nTherefore\nB( f ) m (m!)n\nm (m!)n = m(1− )(m!)n . (15)\n9 This reasoning also takes into account voting rules that agree with f on more than (1/2 + )(m!)n profiles.\nIf the union of balls is to cover at least a δ-fraction of the set of voting rules, we must have |Rnm| ·m(1− )(m!)n δ ·m(m!)n ; equivalently, it must hold that |Rnm| δ · m (m!)n . However, by the assumption |Rnm| is only exponential in n and m (rather than double exponential), so for large enough values of n and m, the above condition does not hold.\nNotice that the number of distinct voting trees with at most k leaves, as voting rules f : LN → A where |A| = m, is bounded from above for any number of voters n by the expression given in Lemma 4.5, namely k · mk · Ck−1. Therefore, we have as a corollary from Theorem 5.3:\nCorollary 5.4. For large enough values of n and m, almost all voting rules cannot be approximated by V (k)m , k polynomial in m, to a factor better than 12 .\nIn order to obtain a similar corollary regarding scoring rules, we require the following lemma, which may be of independent interest.\nLemma 5.5. There exists a polynomial p(n,m) such that for all n,m ∈ N, |S nm| 2p(n,m) .\nProof. It is true that there are an infinite number of ways to choose the vector α that defines a scoring rule. Nevertheless, what we are really interested in is the number of distinct scoring rules. For instance, if α1 = 2 α2, then f α1 ≡ f α2 , i.e., the two vectors define the same voting rule.\nIt is clear that two scoring rules f α1 and f α2 are distinct only if the following condition holds: there exist two alternatives x j1 , x j2 ∈ C , and a preference profile N , such that f α1 ( N ) = x j1 and f α2 ( N ) = x j2 . This holds only if there exist two alternatives x j1 and x j2 and a preference profile N such that under α1, x j1 ’s score is strictly greater than x j2 ’s, and under α2, either x j2 ’s score is greater or the two alternatives are tied, and the tie is broken in favor of x j2 .\nNow, assume N induces rankings π j1 and π j2 . The conditions above can be written as∑ l π j1,lα 1 l > ∑ l π j2,lα 1 l , (16)\n∑ l π j1,lα 2 l ∑ l π j2,lα 2 l , (17)\nwhere the inequality is an equality only if ties are broken in favor of x j2 , i.e., if l0 = min{l: π j1,l = π j2,l}, then π j1,l < π j2,l .10 Let π = π j1 − π j2 . As in the proof of Lemma 3.6, Eqs. (16) and (17) can be concisely rewritten as\nπ · α1 > 0 π · α2, (18) where the inequality is an equality only if the first nonzero position in π is negative.\nIn order to continue, we opt to reinterpret the above discussion geometrically. Each point in Rm corresponds to a possible choice of parameters α. Now, each possible choice of π is the normal to a hyperplane. These hyperplanes partition the space into cells: the vectors in the interior of each cell agree on the signs of dot products with all vectors π . More formally, if α1 and α2 are two points in the interior of a cell, then for any vector π , π · α1 > 0 ⇔ π · α2 > 0. By Eq. (18), this implies that any two scoring rules f α1 and f α2 , where α1 and α2 are in the interior of the same cell, are identical.\nWhat about points residing in the intersection of several cells? These vectors always agree with the vectors in one of the cells, as ties are broken according to rankings induced by the preference profile, i.e., according to the parameters that define our hyperplanes. Therefore, the points in the intersection can be conceptually annexed to one of the cells.\nSo, we have reached the conclusion that the number of distinct scoring rules is at most the number of cells. Hence, it is enough to bound the number of cells; we claim this number is exponential in n and m. Indeed, each π is an m-vector, in which every coordinate is an integer in the set {−n,−n +1, . . . ,n −1,n}. It follows that there are at most (2n +1)m possible hyperplanes. It is known [7] that given k hyperplanes in d-dimensional space, the number of cells is at most O (kd). In our case, k (2n + 1)m and d = m, so we have obtained a bound of:\n( (2n + 1)m)m (3n)m2 = (2log 3n)m2 = 2m2 log 3n. (19)\nRemark 5.6. This lemma implies, according to Lemma 2.4, that there exists a polynomial p(n,m) such that for all n,m ∈ N, DG(S nm) p(n,m). However, we have already obtained a tighter upper bound of m.\nFinally, using Theorem 5.3 and Lemma 5.5 we obtain:\n10 W.l.o.g. we disregard the case where π j1 = π j2 ; the reader can verify that taking this case into account multiplies the final result by an exponential factor at most.\nCorollary 5.7. For large enough values of n and m, almost all voting rules cannot be approximated by S nm to a factor better than 12 .\nRemark 5.8. Proposition 5.2 can seemingly be circumvented by removing the requirement that in a scoring rule defined by a vector α, αl αl+1 for all l. Indeed, flipped veto is essentially a scoring rule with αm = 1 and αl = 0 for all l = m. However, the constant voting rule which always elects the same alternative has the same inapproximability ratio, even when this property of scoring rules is not taken into account. Moreover, Corollary 5.7 also holds when scoring rules are not assumed to satisfy this property."
    }, {
      "heading" : "6. Discussion",
      "text" : "We have demonstrated the possibility of learning scoring rules and small voting trees. We have argued that, given a black box specification of the choice criteria of the society, learning from examples allows one to efficiently (albeit approximately) design such rules. The black box reflects some ideal voting rule the designer has in mind, which satisfies, for instance, different desirable properties. The designer thus essentially translates a cumbersome representation of a voting rule (hidden within the black box) to a concisely represented voting rule which is easy to understand and apply.\nIn Section 5 we have explored the possibility of extending our approach to the setting where the designer has in mind some general voting rule, rather than a scoring rule or a voting tree, and we would like to find a scoring rule or voting tree that is as close as possible. Technically, our learning-theoretic results basically hold (up to polynomial factors in the sample complexity) in this setting, although the situation is more difficult in terms of computational complexity.\nUnfortunately, it turns out (Corollaries 5.4 and 5.7) that many voting rules cannot be approximated, neither by using scoring rules nor by small voting trees. However, this negative result relied implicitly on assuming a uniform distribution over profiles. More importantly, it might be the case that some of the important families of voting rules can be approximated by scoring rules or small voting trees. Therefore, we do not rule out at this point the application of our approach to designing general voting rules by directly learning scoring rules or small voting trees that approximate them.\nCriticisms of our approach. A possible concern, given Corollaries 5.4 and 5.7, is with our general motivation. Indeed, if we assume that the designer has in mind, say, a scoring rule, it can be argued that the designer must be aware of this fact, and must have knowledge of the parameters of the rule. However, recall that the class of scoring rules is exactly the class of anonymous, neutral, and consistent voting rules [26]. Hence, if the designer selects winners in any way that satisfies these three desiderata, a scoring rule with unknown parameters would be obtained.\nA similar case can be made for voting trees. The underlying assumption behind the literature on implementation by voting trees (see, e.g., [10] and the references therein) is that voting trees are an abstract model of decision making, and that many voting rules can in fact be represented as voting trees, even if this transformation is not obvious. For example, the Copeland rule, that selects an alternative that beats the largest number of alternatives in pairwise elections, can be represented as an elaborate voting tree if there are up to seven alternatives [23]. Hence, the designer might be using a voting rule that can be represented as a voting tree, but might be unaware of the exact representation.\nLet us discuss two additional possible criticisms regarding our general setting. First, notice that in multiagent environments, the number of alternatives m can be large; for example, if the agents are voting on joint plans [9], then the number of alternatives might be significantly larger than the number of agents. Hence, complexity results that depend on the number of alternatives are meaningful.\nSecond, it has been suggested that the designer might find it easier to express the ethical properties that are considered mandatory, rather than express the voting rule by examples. We argue that this is rarely the case. Indeed, it is very difficult to concisely represent properties in computational settings; a universal, agreed-upon language would have to be used, and it is hard to imagine how one would go about creating such a language. On the other hand, specifying a voting rule by (a polynomial number of) examples provides a concise description of the voting rule, and, as we have shown, can lead to a close approximation.\nFuture work. We mention two directions for future research. First, imagine the following scenario: the designer has in mind a huge voting tree, and would like to know whether there exists a smaller voting tree that implements the same voting rule. The same goes for scoring rules, e.g., the designer might have in mind a scoring rule with huge values for components of the vector α. This is a setting closely related to ours, but our results do not hold in the alternative setting.\nSecond, it might prove interesting to study the learnability of larger families of voting rules that have a concise representation. One compelling example is the class of generalized scoring rules recently proposed by Xia and Conitzer [25]."
    }, {
      "heading" : "Acknowledgements",
      "text" : "The authors wish to thank anonymous AIJ, AAAI, and AAMAS reviewers, for their very helpful comments. This work was partially supported by Israel Science Foundation grant #898/05."
    } ],
    "references" : [ {
      "title" : "How hard is it to control an election",
      "author" : [ "J. Bartholdi", "C.A. Tovey", "M.A. Trick" ],
      "venue" : "Mathematical and Computer Modelling",
      "citeRegEx" : "1",
      "shortCiteRegEx" : "1",
      "year" : 1992
    }, {
      "title" : "Learning from revealed preference",
      "author" : [ "E. Beigman", "R. Vohra" ],
      "venue" : "in: Proceedings of the 7th ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "2",
      "shortCiteRegEx" : "2",
      "year" : 2006
    }, {
      "title" : "Complexity of mechanism",
      "author" : [ "V. Conitzer", "T. Sandholm" ],
      "venue" : "Proceedings of the 18th Annual Conference on Uncertainty in Artificial Intelligence (UAI),",
      "citeRegEx" : "3",
      "shortCiteRegEx" : "3",
      "year" : 2002
    }, {
      "title" : "Universal voting protocol tweaks to make manipulation hard",
      "author" : [ "V. Conitzer", "T. Sandholm" ],
      "venue" : "in: Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "4",
      "shortCiteRegEx" : "4",
      "year" : 2003
    }, {
      "title" : "An algorithm for automatically designing deterministic mechanisms without payments",
      "author" : [ "V. Conitzer", "T. Sandholm" ],
      "venue" : "in: Proceedings of the 3rd International Joint Conference on Autonomous Agents and Multiagent Systems (AAMAS),",
      "citeRegEx" : "5",
      "shortCiteRegEx" : "5",
      "year" : 2004
    }, {
      "title" : "When are elections with few candidates hard to manipulate",
      "author" : [ "V. Conitzer", "T. Sandholm", "J. Lang" ],
      "venue" : "Journal of the ACM",
      "citeRegEx" : "6",
      "shortCiteRegEx" : "6",
      "year" : 2007
    }, {
      "title" : "Algorithms in Combinatorial Geometry",
      "author" : [ "H. Edelsbrunner" ],
      "venue" : "EATCS Monographs on Theoretical Computer Science,",
      "citeRegEx" : "7",
      "shortCiteRegEx" : "7",
      "year" : 1987
    }, {
      "title" : "Small coalitions cannot manipulate voting",
      "author" : [ "E. Elkind", "H. Lipmaa" ],
      "venue" : "in: Proceedings of the Annual Conference on Financial Cryptography (FC),",
      "citeRegEx" : "8",
      "shortCiteRegEx" : "8",
      "year" : 2005
    }, {
      "title" : "A heuristic technique for multiagent planning",
      "author" : [ "E. Ephrati", "J.S. Rosenschein" ],
      "venue" : "Annals of Mathematics and Artificial Intelligence",
      "citeRegEx" : "9",
      "shortCiteRegEx" : "9",
      "year" : 1997
    }, {
      "title" : "A new perspective on implementation by voting",
      "author" : [ "F. Fischer", "A.D. Procaccia", "A. Samorodnitsky" ],
      "venue" : null,
      "citeRegEx" : "10",
      "shortCiteRegEx" : "10",
      "year" : 2008
    }, {
      "title" : "Computers and Intractability: A Guide to the Theory of NP-Completeness, W.H",
      "author" : [ "M.R. Garey", "D.S. Johnson" ],
      "venue" : null,
      "citeRegEx" : "11",
      "shortCiteRegEx" : "11",
      "year" : 1979
    }, {
      "title" : "Voting for movies: The anatomy of a recommender system",
      "author" : [ "S. Ghosh", "M. Mundhe", "K. Hernandez", "S. Sen" ],
      "venue" : "in: Proceedings of the 3rd Annual Conference on Autonomous Agents (AGENTS),",
      "citeRegEx" : "12",
      "shortCiteRegEx" : "12",
      "year" : 1999
    }, {
      "title" : "An automated meeting scheduling system that utilizes user preferences",
      "author" : [ "T. Haynes", "S. Sen", "N. Arora", "R. Nadella" ],
      "venue" : "in: Proceedings of the 1st Annual Conference on Autonomous Agents (AGENTS),",
      "citeRegEx" : "13",
      "shortCiteRegEx" : "13",
      "year" : 1997
    }, {
      "title" : "Dichotomy for voting systems",
      "author" : [ "E. Hemaspaandra", "L. Hemaspaandra" ],
      "venue" : "Journal of Computer and System Sciences",
      "citeRegEx" : "14",
      "shortCiteRegEx" : "14",
      "year" : 2007
    }, {
      "title" : "Anyone but him: The complexity of precluding an alternative",
      "author" : [ "E. Hemaspaandra", "L.A. Hemaspaandra", "J. Rothe" ],
      "venue" : "Artificial Intelligence",
      "citeRegEx" : "15",
      "shortCiteRegEx" : "15",
      "year" : 2007
    }, {
      "title" : "Learnability and rationality of choice",
      "author" : [ "G. Kalai" ],
      "venue" : "Journal of Economic Theory",
      "citeRegEx" : "16",
      "shortCiteRegEx" : "16",
      "year" : 2003
    }, {
      "title" : "Applying learning algorithms to preference elicitation",
      "author" : [ "S. Lahaie", "D.C. Parkes" ],
      "venue" : "in: Proceedings of the 5th ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "17",
      "shortCiteRegEx" : "17",
      "year" : 2004
    }, {
      "title" : "Winner determination in sequential majority voting",
      "author" : [ "J. Lang", "M.-S. Pini", "F. Rossi", "K.B. Venable", "T. Walsh" ],
      "venue" : "in: Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "18",
      "shortCiteRegEx" : "18",
      "year" : 2007
    }, {
      "title" : "Learning quickly when irrelevant attributes abound: A new linear-threshold algorithm",
      "author" : [ "N. Littlestone" ],
      "venue" : "Machine Learning",
      "citeRegEx" : "19",
      "shortCiteRegEx" : "19",
      "year" : 1988
    }, {
      "title" : "Machine Learning: A Theoretical Approach",
      "author" : [ "B.K. Natarajan" ],
      "venue" : null,
      "citeRegEx" : "20",
      "shortCiteRegEx" : "20",
      "year" : 1991
    }, {
      "title" : "Rosenschein, Junta distributions and the average-case complexity of manipulating elections",
      "author" : [ "J.S.A.D. Procaccia" ],
      "venue" : "Journal of Artificial Intelligence Research",
      "citeRegEx" : "21",
      "shortCiteRegEx" : "21",
      "year" : 2007
    }, {
      "title" : "Multi-winner elections: Complexity of manipulation, control and winner-determination",
      "author" : [ "A.D. Procaccia", "J.S. Rosenschein", "A. Zohar" ],
      "venue" : "in: Proceedings of the 20th International Joint Conference on Artificial Intelligence (IJCAI),",
      "citeRegEx" : "22",
      "shortCiteRegEx" : "22",
      "year" : 2007
    }, {
      "title" : "Sophisticated voting rules: The case of two tournaments",
      "author" : [ "S. Srivastava", "M.A. Trick" ],
      "venue" : "Social Choice and Welfare",
      "citeRegEx" : "23",
      "shortCiteRegEx" : "23",
      "year" : 1996
    }, {
      "title" : "Generalized scoring rules and the frequency of coalitional manipulability",
      "author" : [ "L. Xia", "V. Conitzer" ],
      "venue" : "in: Proceedings of the 9th ACM Conference on Electronic Commerce (ACM-EC),",
      "citeRegEx" : "25",
      "shortCiteRegEx" : "25",
      "year" : 2008
    }, {
      "title" : "Social choice scoring functions",
      "author" : [ "H.P. Young" ],
      "venue" : "SIAM Journal of Applied Mathematics",
      "citeRegEx" : "26",
      "shortCiteRegEx" : "26",
      "year" : 1975
    }, {
      "title" : "Algorithms for the coalitional manipulation",
      "author" : [ "M. Zuckerman", "A.D. Procaccia", "J.S. Rosenschein" ],
      "venue" : "The 19th ACM–SIAM Symposium on Discrete Algorithms (SODA),",
      "citeRegEx" : "27",
      "shortCiteRegEx" : "27",
      "year" : 2008
    } ],
    "referenceMentions" : [ {
      "referenceID" : 5,
      "context" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].",
      "startOffset" : 136,
      "endOffset" : 142
    }, {
      "referenceID" : 20,
      "context" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].",
      "startOffset" : 136,
      "endOffset" : 142
    }, {
      "referenceID" : 8,
      "context" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].",
      "startOffset" : 210,
      "endOffset" : 219
    }, {
      "referenceID" : 11,
      "context" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].",
      "startOffset" : 210,
      "endOffset" : 219
    }, {
      "referenceID" : 12,
      "context" : "Voting is a well-studied method of preference aggregation, in terms of its theoretical properties, as well as its computational aspects [6,21]; various practical, implemented applications that use voting exist [9,12,13].",
      "startOffset" : 210,
      "endOffset" : 219
    }, {
      "referenceID" : 24,
      "context" : "A good indication of the importance of scoring rules is given by the fact that they are exactly the family of voting rules that are anonymous (indifferent to the identities of the voters), neutral (indifferent to the identities of the alternatives), and consistent (an alternative that is elected by two separate sets of voters is elected overall) [26].",
      "startOffset" : 348,
      "endOffset" : 352
    }, {
      "referenceID" : 15,
      "context" : "Kalai [16] explores the learnability (in the PAC model) of rationalizable choice functions.",
      "startOffset" : 6,
      "endOffset" : 10
    }, {
      "referenceID" : 1,
      "context" : "Similarly, PAC learning has very recently been applied to computing utility functions that are rationalizations of given sequences of prices and demands [2].",
      "startOffset" : 153,
      "endOffset" : 156
    }, {
      "referenceID" : 16,
      "context" : "Another prominent example is the paper by Lahaie and Parkes [17], which considers preference elicitation in combinatorial auctions.",
      "startOffset" : 60,
      "endOffset" : 64
    }, {
      "referenceID" : 2,
      "context" : "Conitzer and Sandholm [3] have studied automated mechanism design, in the more restricted setting where agents have numerical valuations for different alternatives.",
      "startOffset" : 22,
      "endOffset" : 25
    }, {
      "referenceID" : 4,
      "context" : "In more recent work [5], Conitzer and Sandholm put forward an efficient algorithm for designing deterministic mechanisms, which works only in very limited scenarios.",
      "startOffset" : 20,
      "endOffset" : 23
    }, {
      "referenceID" : 5,
      "context" : "[6] have investigated the computational complexity of the coalitional manipulation problem in several scoring rules; Procaccia and Rosenschein [21] generalized their results, and finally, Hemaspaandra and Hemaspaandra [14] gave a full characterization.",
      "startOffset" : 0,
      "endOffset" : 3
    }, {
      "referenceID" : 20,
      "context" : "[6] have investigated the computational complexity of the coalitional manipulation problem in several scoring rules; Procaccia and Rosenschein [21] generalized their results, and finally, Hemaspaandra and Hemaspaandra [14] gave a full characterization.",
      "startOffset" : 143,
      "endOffset" : 147
    }, {
      "referenceID" : 13,
      "context" : "[6] have investigated the computational complexity of the coalitional manipulation problem in several scoring rules; Procaccia and Rosenschein [21] generalized their results, and finally, Hemaspaandra and Hemaspaandra [14] gave a full characterization.",
      "startOffset" : 218,
      "endOffset" : 222
    }, {
      "referenceID" : 17,
      "context" : "[18], which studied the computational complexity of selecting different types of winners in elections governed by voting trees.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 9,
      "context" : "[10] investigated the power of voting trees in approximating the maximum degree in a tournament.",
      "startOffset" : 0,
      "endOffset" : 4
    }, {
      "referenceID" : 19,
      "context" : "A more comprehensive (and slightly more formal) overview of the model, and results concerning the dimension, can be found in [20].",
      "startOffset" : 125,
      "endOffset" : 129
    }, {
      "referenceID" : 18,
      "context" : "Indeed, well-known algorithms such as Winnow [19] might suit this purpose.",
      "startOffset" : 45,
      "endOffset" : 49
    }, {
      "referenceID" : 15,
      "context" : "Algorithm 1 can also be used to check, with high probability, if the voting rule the designer has in mind is indeed a scoring rule, as described (in a different context) by Kalai [16] (we omit the details here).",
      "startOffset" : 179,
      "endOffset" : 183
    }, {
      "referenceID" : 10,
      "context" : "It is known that 3SAT is N P -complete [11].",
      "startOffset" : 39,
      "endOffset" : 43
    }, {
      "referenceID" : 6,
      "context" : "It is known [7] that given k hyperplanes in d-dimensional space, the number of cells is at most O (kd).",
      "startOffset" : 12,
      "endOffset" : 15
    }, {
      "referenceID" : 24,
      "context" : "However, recall that the class of scoring rules is exactly the class of anonymous, neutral, and consistent voting rules [26].",
      "startOffset" : 120,
      "endOffset" : 124
    }, {
      "referenceID" : 9,
      "context" : ", [10] and the references therein) is that voting trees are an abstract model of decision making, and that many voting rules can in fact be represented as voting trees, even if this transformation is not obvious.",
      "startOffset" : 2,
      "endOffset" : 6
    }, {
      "referenceID" : 22,
      "context" : "For example, the Copeland rule, that selects an alternative that beats the largest number of alternatives in pairwise elections, can be represented as an elaborate voting tree if there are up to seven alternatives [23].",
      "startOffset" : 214,
      "endOffset" : 218
    }, {
      "referenceID" : 8,
      "context" : "First, notice that in multiagent environments, the number of alternatives m can be large; for example, if the agents are voting on joint plans [9], then the number of alternatives might be significantly larger than the number of agents.",
      "startOffset" : 143,
      "endOffset" : 146
    }, {
      "referenceID" : 23,
      "context" : "One compelling example is the class of generalized scoring rules recently proposed by Xia and Conitzer [25].",
      "startOffset" : 103,
      "endOffset" : 107
    } ],
    "year" : 2009,
    "abstractText" : "Article history: Received 16 May 2008 Received in revised form 25 March 2009 Accepted 27 March 2009 Available online 9 April 2009",
    "creator" : "Elsevier"
  }
}